{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VMIE_RNP_Parcial1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKGgRTCjBgneUYETDwjf5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-ibarra/RNP_Diabetes_dataset/blob/main/VMIE_RNP_Parcial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNRUa7SEE8i"
      },
      "source": [
        "# Clasificación de datos estructurados por medio de una red neuronal profunda  \r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "## Selección de la muestra  \r\n",
        "\r\n",
        "\r\n",
        "> En formato de datos estructurados (.csv) \r\n",
        "\r\n",
        ">  Pueden ser de algún tema de investigación propio o puede ser tomado de algún repositorio de datos (por ejemplo, Kaggle).  \r\n",
        "\r\n",
        ">  Debe contener una cantidad mínima de datos (>500 entradas)  \r\n",
        "\r\n",
        ">  Debe contener una cantidad mínima de variables (>5 )  \r\n",
        "\r\n",
        ">  El problema a resolver tiene que ser de clasificación (2 o más categorías) \r\n",
        "\r\n",
        "## Preprocesamiento de datos  \r\n",
        "\r\n",
        ">   Eliminar columnas que no sean relevantes para el entrenamiento (columnas con un porcentaje de datos nulos > 30%, columnas que no son de utilidad para la red neuronal)  \r\n",
        "\r\n",
        ">   En caso de que sea necesario a convertir a formato numérico hacer el respectivo mapeo, por ejemplo, en formato de fechas, o columnas que contengan caracteres y sea necesario convertirlo a clasificación (ejemplo “YES” ->1  “NO”-> 0)  \r\n",
        "\r\n",
        ">  Ya que los datos están listos para la red neuronal separar la muestra en un porcentaje para entrenamiento (75%) y validación (25%) \r\n",
        "\r\n",
        ">  Para un mejor desempeño de la red neuronal normalizar los valores de las columnas para un valor entre 0 y 1  \r\n",
        "\r\n",
        "## Definición de la red neuronal e hiperparametros  \r\n",
        "\r\n",
        "> Definir la configuración inicial de la red neuronal (como recomendación empezar con una configuración básica e ir cambiando dependiendo del desempeño)  \r\n",
        "\r\n",
        "> Seleccionar claramente los hiperparametros (factor de aprendizaje, funciones de activación, función de error, etc....) \r\n",
        "\r\n",
        "## Entrenamiento de la red neuronal  \r\n",
        "\r\n",
        "> Realizar el entrenamiento de la red neuronal con keras \r\n",
        "\r\n",
        "> Dependiendo de los resultados ajustar los hiperparametros para optimizar la red neuronal \r\n",
        "\r\n",
        "> En caso de observar co-adaptacion de la red neuronal (overfitting) realizar un proceso de dropout   \r\n",
        "\r\n",
        "> Guardar el modelo (formato .h5) \r\n",
        "\r\n",
        "## Análisis de resultados y presentacion \r\n",
        "\r\n",
        ">  Presentar los graficos finales de aprendizaje (error vs iteraciones,  accuracy vs iteraciones)  \r\n",
        "\r\n",
        " > Presentar los resultados en forma vistosa y facil de interpretar para el lector (libreta jupyter formateada con imágenes y texto descriptivo,  o algun medio para presentación de trabajo tipo blog como medium) recordar que gran parte de un trabajo es saber presentarlo y defenderlo     \r\n",
        "\r\n",
        "## Conclusiones  \r\n",
        "\r\n",
        "> Interpretar los resultados de la red neuronal    \r\n",
        "\r\n",
        "> Discutir de que manera podria ser implementado en una aplicación  \r\n",
        "\r\n",
        "> Discutir cuales serian las limitaciones de la red neuronal y de los resultados obtenidos.\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eA9lh8nEBhu"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\r\n",
        "import tensorflow as tf\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.core import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "#from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdtiY7gEbL1I"
      },
      "source": [
        "# **Análisis de datos para clasificación de personas femeninas, mayores a 21 años con Dx de Diabetes**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab3AafaKbWzy"
      },
      "source": [
        "## Análisis Exploratorio de Datos (EDA)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AMtUZN8kBdg"
      },
      "source": [
        "Siempre es necesario importar los datos y realizar un \"Análisis Exploratorio de Datos\", ésto es con la finalidad de conocer la información con la que se va a trabajar, la manera en que se relacionan las variables, anomalías en el dataset, entre otras cosas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "u55nMvehY0M0",
        "outputId": "8fb57d97-70a0-411d-b2f7-31006fc3b6bd"
      },
      "source": [
        "df = pd.read_csv('diabetes.csv')\r\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeprXwgXki9K"
      },
      "source": [
        "Buscamos valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMlBo3D2ZQt8",
        "outputId": "a706e230-6492-47a3-ce02-da1c75390e24"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCC5D7VzkmNK"
      },
      "source": [
        "Formato de datos en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hYlFDnhZUr0",
        "outputId": "ee91d8eb-74af-4806-e9ef-69b18e1fb396"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ9ZjSebktuk"
      },
      "source": [
        "Verificamos la forma de nuestra base de datos."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZupeVhulbi7n",
        "outputId": "c5fe5be6-fc1a-42bc-ab21-815c1db23e93"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "yjs54mi0bqvl",
        "outputId": "d204e1fc-726e-420c-98ae-9887823a77ee"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>768.0</td>\n",
              "      <td>3.845052</td>\n",
              "      <td>3.369578</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>6.00000</td>\n",
              "      <td>17.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>768.0</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>0.000</td>\n",
              "      <td>99.00000</td>\n",
              "      <td>117.0000</td>\n",
              "      <td>140.25000</td>\n",
              "      <td>199.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>768.0</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>0.000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>72.0000</td>\n",
              "      <td>80.00000</td>\n",
              "      <td>122.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>768.0</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>23.0000</td>\n",
              "      <td>32.00000</td>\n",
              "      <td>99.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>768.0</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>127.25000</td>\n",
              "      <td>846.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>768.0</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.30000</td>\n",
              "      <td>32.0000</td>\n",
              "      <td>36.60000</td>\n",
              "      <td>67.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>768.0</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.24375</td>\n",
              "      <td>0.3725</td>\n",
              "      <td>0.62625</td>\n",
              "      <td>2.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>768.0</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>21.000</td>\n",
              "      <td>24.00000</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>41.00000</td>\n",
              "      <td>81.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>768.0</td>\n",
              "      <td>0.348958</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          count        mean  ...        75%     max\n",
              "Pregnancies               768.0    3.845052  ...    6.00000   17.00\n",
              "Glucose                   768.0  120.894531  ...  140.25000  199.00\n",
              "BloodPressure             768.0   69.105469  ...   80.00000  122.00\n",
              "SkinThickness             768.0   20.536458  ...   32.00000   99.00\n",
              "Insulin                   768.0   79.799479  ...  127.25000  846.00\n",
              "BMI                       768.0   31.992578  ...   36.60000   67.10\n",
              "DiabetesPedigreeFunction  768.0    0.471876  ...    0.62625    2.42\n",
              "Age                       768.0   33.240885  ...   41.00000   81.00\n",
              "Outcome                   768.0    0.348958  ...    1.00000    1.00\n",
              "\n",
              "[9 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c--cO6slrGI",
        "outputId": "4ee2508d-69fa-44c1-9960-de7618f29c17"
      },
      "source": [
        "df['Pregnancies'].value_counts()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     135\n",
              "0     111\n",
              "2     103\n",
              "3      75\n",
              "4      68\n",
              "5      57\n",
              "6      50\n",
              "7      45\n",
              "8      38\n",
              "9      28\n",
              "10     24\n",
              "11     11\n",
              "13     10\n",
              "12      9\n",
              "14      2\n",
              "15      1\n",
              "17      1\n",
              "Name: Pregnancies, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw27ulp-mIK4"
      },
      "source": [
        "Parece extraño el número de embarazos con 17, sin embargo es posible, según la presente base de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO_m8SnecHx8",
        "outputId": "93fce7e5-7740-4102-8e4d-3629585b9b1e"
      },
      "source": [
        "df.Outcome.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    268\n",
              "Name: Outcome, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0oSBiSSmuD9"
      },
      "source": [
        "Realizamos una matriz de correlación entre los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Ewom6MCJcQaH",
        "outputId": "0662b6fe-160e-4e30-e1cb-6f169500fe33"
      },
      "source": [
        "plt.figure(figsize=(8,5))\r\n",
        "sns.heatmap(df.corr(), cmap='Reds',annot=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0a97565d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejz8YlxunEgw"
      },
      "source": [
        "Para el presente ejercicio, y para no reducir más nuestro dataset, continuaremos con la misma información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_yY1J5Wm2Oc"
      },
      "source": [
        "La relación entre las variables no está muy clara y parecen ser independientes unas de otras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcb9XscYnOsz"
      },
      "source": [
        "A continuación presentamos las variables y su frecuencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "GyUSKjdCnGkE",
        "outputId": "621a8a1f-354f-49cc-8ecf-3e9c12caefcd"
      },
      "source": [
        "df.hist(figsize = (13,13))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc0a10d08d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f873ed0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f835590>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f7eac10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f7ac2d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f760a50>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f78cb10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f6d9550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fc09f6d9590>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x936 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7uWBfoGRI_g"
      },
      "source": [
        "## Procesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0nSlNKSj3C2"
      },
      "source": [
        "Vamos a preparar nuestros datos, para separar la información en 2 datasets:\r\n",
        "\r\n",
        "\r\n",
        "> Variables\r\n",
        "  * Columnas de nuestros datos.\r\n",
        "\r\n",
        "> Categoría\r\n",
        "* Para el presente set de datos es 0 para pacientes sin diabetes; 1 para pacientes con diabetes diagnosticada.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpO3JPk7PlGZ",
        "outputId": "e3662757-1520-49b8-aabd-a5a4b49c4ba1"
      },
      "source": [
        "X_df = df\r\n",
        "X_df = X_df.drop(['Outcome'], axis=1)\r\n",
        "print(X_df)\r\n",
        "y_df = df['Outcome']\r\n",
        "print(y_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
            "0              6      148             72  ...  33.6                     0.627   50\n",
            "1              1       85             66  ...  26.6                     0.351   31\n",
            "2              8      183             64  ...  23.3                     0.672   32\n",
            "3              1       89             66  ...  28.1                     0.167   21\n",
            "4              0      137             40  ...  43.1                     2.288   33\n",
            "..           ...      ...            ...  ...   ...                       ...  ...\n",
            "763           10      101             76  ...  32.9                     0.171   63\n",
            "764            2      122             70  ...  36.8                     0.340   27\n",
            "765            5      121             72  ...  26.2                     0.245   30\n",
            "766            1      126             60  ...  30.1                     0.349   47\n",
            "767            1       93             70  ...  30.4                     0.315   23\n",
            "\n",
            "[768 rows x 8 columns]\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "763    0\n",
            "764    0\n",
            "765    0\n",
            "766    1\n",
            "767    0\n",
            "Name: Outcome, Length: 768, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_FsPyzdQz_8",
        "outputId": "9723c735-5089-4e3b-8372-668c202b27e5"
      },
      "source": [
        "print(X_df.shape)\r\n",
        "print(y_df.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8)\n",
            "(768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiJfi7_-pN4r"
      },
      "source": [
        "Nuestro siguiente paso es establecer nuestros 2 grupos de datos:\r\n",
        "> **Train**\r\n",
        ">> Set de entrenamiento con las variables de entrada y la categoría.\r\n",
        "\r\n",
        ">> *x_tr* y *y_tr*\r\n",
        "\r\n",
        "> **Test**\r\n",
        ">> Set de prueba con las variables de entrada y la categoría.\r\n",
        "\r\n",
        ">> *x_ts* y *y_ts*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfbRVc_kRAZj",
        "outputId": "fd38659b-8190-48b1-c896-2fc29a964f61"
      },
      "source": [
        "x_tr, x_ts, y_tr, y_ts = train_test_split(X_df, y_df, test_size = 0.25, random_state = 10)\r\n",
        "\r\n",
        "y_tr = np.asarray(y_tr, dtype = np.int)\r\n",
        "y_ts = np.asarray(y_ts, dtype = np.int)\r\n",
        "\r\n",
        "y_tr = np.reshape(y_tr, [576,1])\r\n",
        "y_ts = np.reshape(y_ts, [192,1])\r\n",
        "\r\n",
        "print(x_ts.shape, 'x_ts')\r\n",
        "print(x_tr.shape, 'x_tr')\r\n",
        "print(y_ts.shape, 'y_ts')\r\n",
        "print(y_tr.shape, 'y_tr')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(192, 8) x_ts\n",
            "(576, 8) x_tr\n",
            "(192, 1) y_ts\n",
            "(576, 1) y_tr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZeW4Oj1RyfN",
        "outputId": "73dae423-392d-4a71-dfba-bbbfedc4c7a5"
      },
      "source": [
        "# Training Data\r\n",
        "x_tr = MinMaxScaler().fit_transform(x_tr)\r\n",
        "print(\"Training Data :\", x_tr.shape)\r\n",
        "\r\n",
        "# Testing Data\r\n",
        "x_ts = MinMaxScaler().fit_transform(x_ts)\r\n",
        "print(\"Testing Data :\", x_ts.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data : (576, 8)\n",
            "Testing Data : (192, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhAamI0QlXCX"
      },
      "source": [
        "## Normalización de valores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBcrLAdaiTXU"
      },
      "source": [
        "Normalizaremos los valores de nuestro dataset, para evitar tener rangos de valores muy grandes, y poder trabajar en nuestro modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epl-KYgOTDm8",
        "outputId": "529bf71c-71cd-4c55-9911-2dd4fcfb84de"
      },
      "source": [
        "# Training Data\r\n",
        "x_tr = MinMaxScaler().fit_transform(x_tr)\r\n",
        "print(\"Training Data :\", x_tr.shape)\r\n",
        "\r\n",
        "# Testing Data\r\n",
        "x_ts = MinMaxScaler().fit_transform(x_ts)\r\n",
        "print(\"Testing Data :\", x_ts.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data : (576, 8)\n",
            "Testing Data : (192, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsLJuzBjlzib"
      },
      "source": [
        "## Red Neuronal e Hyperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Nod5uth_lq"
      },
      "source": [
        "A continuación se muestran algunos de los modelos realizados con distintos parámetros.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32G7skz8qVkB"
      },
      "source": [
        "No todos los modelos realizados son presentados en la presente libreta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iff4tnB0l9dj",
        "outputId": "98203822-0def-4f04-a7eb-cbb83da30b45"
      },
      "source": [
        "# Hyperparameters\r\n",
        "training_epochs = 1000 # Total number of training epochs\r\n",
        "learning_rate = 0.01 # The learning rate\r\n",
        "\r\n",
        "\r\n",
        "# create a model\r\n",
        "def create_model():\r\n",
        "    model = tf.keras.Sequential()\r\n",
        "    # Hidden layer\r\n",
        "    model.add(tf.keras.layers.Dense(20, input_dim=8,activation='relu'))\r\n",
        "    # Hidden layer 2\r\n",
        "    #model.add(tf.keras.layers.Dense(20, input_dim=8,activation='sigmoid'))\r\n",
        "    # Output layer\r\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    # Compile a model\r\n",
        "    model.compile(loss='binary_crossentropy', \r\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    return model\r\n",
        "\r\n",
        "model = create_model()\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "results = model.fit(\r\n",
        "    x_tr, y_tr,\r\n",
        "    epochs= training_epochs,\r\n",
        "    validation_data = (x_ts, y_ts),\r\n",
        "    verbose = 1\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Evaluating on training set...\")\r\n",
        "(loss, accuracy) = model.evaluate(x_tr, y_tr, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "print(\"Evaluating on testing set...\")\r\n",
        "(loss, accuracy) = model.evaluate(x_ts, y_ts, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(results.history['accuracy'])\r\n",
        "plt.plot(results.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(results.history['loss'])\r\n",
        "plt.plot(results.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "max_loss = np.max(results.history['loss'])\r\n",
        "min_loss = np.min(results.history['loss'])\r\n",
        "print(\"Maximum Loss : {:.4f}\".format(max_loss))\r\n",
        "print(\"\")\r\n",
        "print(\"Minimum Loss : {:.4f}\".format(min_loss))\r\n",
        "print(\"\")\r\n",
        "print(\"Loss difference : {:.4f}\".format((max_loss - min_loss)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 20)                180       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 201\n",
            "Trainable params: 201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 26ms/step - loss: 0.6942 - accuracy: 0.5259 - val_loss: 0.6853 - val_accuracy: 0.6094\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6195 - val_loss: 0.6798 - val_accuracy: 0.6302\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6550 - val_loss: 0.6765 - val_accuracy: 0.6302\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6831 - val_loss: 0.6744 - val_accuracy: 0.6302\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6172 - val_loss: 0.6730 - val_accuracy: 0.6302\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6474 - val_loss: 0.6721 - val_accuracy: 0.6302\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.6469 - val_loss: 0.6715 - val_accuracy: 0.6302\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6443 - val_loss: 0.6711 - val_accuracy: 0.6302\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6734 - val_loss: 0.6707 - val_accuracy: 0.6302\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6903 - val_loss: 0.6704 - val_accuracy: 0.6302\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6591 - val_loss: 0.6700 - val_accuracy: 0.6302\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6858 - val_loss: 0.6696 - val_accuracy: 0.6302\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6436 - val_loss: 0.6693 - val_accuracy: 0.6302\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6621 - val_loss: 0.6689 - val_accuracy: 0.6302\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7131 - val_loss: 0.6684 - val_accuracy: 0.6302\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6519 - val_loss: 0.6680 - val_accuracy: 0.6302\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6689 - val_loss: 0.6676 - val_accuracy: 0.6302\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6819 - val_loss: 0.6671 - val_accuracy: 0.6302\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6393 - val_loss: 0.6667 - val_accuracy: 0.6302\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6581 - val_loss: 0.6663 - val_accuracy: 0.6302\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6716 - val_loss: 0.6658 - val_accuracy: 0.6302\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.6547 - val_loss: 0.6654 - val_accuracy: 0.6302\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6656 - val_loss: 0.6649 - val_accuracy: 0.6302\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6297 - val_loss: 0.6644 - val_accuracy: 0.6302\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.6248 - val_loss: 0.6640 - val_accuracy: 0.6302\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6501 - val_loss: 0.6635 - val_accuracy: 0.6302\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6475 - val_loss: 0.6631 - val_accuracy: 0.6302\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6847 - val_loss: 0.6625 - val_accuracy: 0.6302\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6374 - val_loss: 0.6621 - val_accuracy: 0.6302\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6584 - val_loss: 0.6616 - val_accuracy: 0.6302\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6630 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6454 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6658 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6765 - val_loss: 0.6596 - val_accuracy: 0.6302\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7241 - val_loss: 0.6590 - val_accuracy: 0.6302\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6485 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6731 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6650 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6597 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.6691 - val_loss: 0.6566 - val_accuracy: 0.6302\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6222 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6530 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6572 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.6331 - val_loss: 0.6548 - val_accuracy: 0.6302\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6642 - val_loss: 0.6544 - val_accuracy: 0.6302\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6537 - val_loss: 0.6539 - val_accuracy: 0.6302\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6733 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6585 - val_loss: 0.6530 - val_accuracy: 0.6302\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6175 - val_loss: 0.6526 - val_accuracy: 0.6302\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6489 - val_loss: 0.6522 - val_accuracy: 0.6302\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6328 - val_loss: 0.6518 - val_accuracy: 0.6302\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6683 - val_loss: 0.6513 - val_accuracy: 0.6302\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6479 - val_loss: 0.6509 - val_accuracy: 0.6302\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6657 - val_loss: 0.6504 - val_accuracy: 0.6302\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6603 - val_loss: 0.6499 - val_accuracy: 0.6302\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6859 - val_loss: 0.6494 - val_accuracy: 0.6302\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6351 - val_loss: 0.6490 - val_accuracy: 0.6302\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6911 - val_loss: 0.6485 - val_accuracy: 0.6302\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6474 - val_loss: 0.6481 - val_accuracy: 0.6302\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6431 - val_loss: 0.6476 - val_accuracy: 0.6302\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6506 - val_loss: 0.6472 - val_accuracy: 0.6302\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6566 - val_loss: 0.6467 - val_accuracy: 0.6302\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6605 - val_loss: 0.6462 - val_accuracy: 0.6302\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6784 - val_loss: 0.6457 - val_accuracy: 0.6302\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6566 - val_loss: 0.6453 - val_accuracy: 0.6302\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6661 - val_loss: 0.6448 - val_accuracy: 0.6302\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6551 - val_loss: 0.6443 - val_accuracy: 0.6302\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6498 - val_loss: 0.6438 - val_accuracy: 0.6302\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6366 - val_loss: 0.6434 - val_accuracy: 0.6302\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6562 - val_loss: 0.6429 - val_accuracy: 0.6302\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6681 - val_loss: 0.6424 - val_accuracy: 0.6302\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6626 - val_loss: 0.6419 - val_accuracy: 0.6302\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6896 - val_loss: 0.6414 - val_accuracy: 0.6302\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6721 - val_loss: 0.6409 - val_accuracy: 0.6302\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6632 - val_loss: 0.6404 - val_accuracy: 0.6302\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6426 - val_loss: 0.6400 - val_accuracy: 0.6302\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6318 - val_loss: 0.6395 - val_accuracy: 0.6302\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6491 - val_loss: 0.6390 - val_accuracy: 0.6302\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6658 - val_loss: 0.6385 - val_accuracy: 0.6302\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6674 - val_loss: 0.6380 - val_accuracy: 0.6302\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6550 - val_loss: 0.6375 - val_accuracy: 0.6302\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6611 - val_loss: 0.6370 - val_accuracy: 0.6302\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.6666 - val_loss: 0.6365 - val_accuracy: 0.6302\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6703 - val_loss: 0.6360 - val_accuracy: 0.6302\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6488 - val_loss: 0.6356 - val_accuracy: 0.6302\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6295 - val_loss: 0.6352 - val_accuracy: 0.6302\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6840 - val_loss: 0.6346 - val_accuracy: 0.6302\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6380 - val_loss: 0.6341 - val_accuracy: 0.6302\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6634 - val_loss: 0.6336 - val_accuracy: 0.6302\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6569 - val_loss: 0.6331 - val_accuracy: 0.6302\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6392 - val_loss: 0.6326 - val_accuracy: 0.6302\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6522 - val_loss: 0.6321 - val_accuracy: 0.6302\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.6670 - val_loss: 0.6316 - val_accuracy: 0.6302\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6643 - val_loss: 0.6311 - val_accuracy: 0.6354\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6456 - val_loss: 0.6306 - val_accuracy: 0.6354\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6758 - val_loss: 0.6301 - val_accuracy: 0.6354\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.6724 - val_loss: 0.6296 - val_accuracy: 0.6354\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6700 - val_loss: 0.6291 - val_accuracy: 0.6354\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.6497 - val_loss: 0.6286 - val_accuracy: 0.6354\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6497 - val_loss: 0.6281 - val_accuracy: 0.6406\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.6870 - val_loss: 0.6276 - val_accuracy: 0.6406\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6750 - val_loss: 0.6271 - val_accuracy: 0.6406\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6868 - val_loss: 0.6266 - val_accuracy: 0.6406\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6611 - val_loss: 0.6260 - val_accuracy: 0.6354\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6831 - val_loss: 0.6255 - val_accuracy: 0.6354\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6538 - val_loss: 0.6251 - val_accuracy: 0.6354\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6618 - val_loss: 0.6246 - val_accuracy: 0.6354\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.6751 - val_loss: 0.6241 - val_accuracy: 0.6354\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6443 - val_loss: 0.6236 - val_accuracy: 0.6354\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6675 - val_loss: 0.6231 - val_accuracy: 0.6354\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6894 - val_loss: 0.6226 - val_accuracy: 0.6354\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6632 - val_loss: 0.6221 - val_accuracy: 0.6354\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6628 - val_loss: 0.6216 - val_accuracy: 0.6354\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6463 - val_loss: 0.6211 - val_accuracy: 0.6458\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6729 - val_loss: 0.6206 - val_accuracy: 0.6458\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6858 - val_loss: 0.6201 - val_accuracy: 0.6458\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.6920 - val_loss: 0.6196 - val_accuracy: 0.6458\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6666 - val_loss: 0.6191 - val_accuracy: 0.6458\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6678 - val_loss: 0.6186 - val_accuracy: 0.6406\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.6786 - val_loss: 0.6181 - val_accuracy: 0.6406\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.6607 - val_loss: 0.6176 - val_accuracy: 0.6458\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6641 - val_loss: 0.6172 - val_accuracy: 0.6458\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6706 - val_loss: 0.6167 - val_accuracy: 0.6458\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6618 - val_loss: 0.6162 - val_accuracy: 0.6458\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.6826 - val_loss: 0.6157 - val_accuracy: 0.6562\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.6867 - val_loss: 0.6152 - val_accuracy: 0.6562\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.6945 - val_loss: 0.6147 - val_accuracy: 0.6562\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.6853 - val_loss: 0.6142 - val_accuracy: 0.6562\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7040 - val_loss: 0.6138 - val_accuracy: 0.6615\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7011 - val_loss: 0.6133 - val_accuracy: 0.6615\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6873 - val_loss: 0.6128 - val_accuracy: 0.6615\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6883 - val_loss: 0.6123 - val_accuracy: 0.6615\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6970 - val_loss: 0.6119 - val_accuracy: 0.6562\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6890 - val_loss: 0.6114 - val_accuracy: 0.6562\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7035 - val_loss: 0.6109 - val_accuracy: 0.6562\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6638 - val_loss: 0.6105 - val_accuracy: 0.6562\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7250 - val_loss: 0.6100 - val_accuracy: 0.6562\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6928 - val_loss: 0.6095 - val_accuracy: 0.6510\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7045 - val_loss: 0.6091 - val_accuracy: 0.6458\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.6781 - val_loss: 0.6086 - val_accuracy: 0.6458\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7010 - val_loss: 0.6081 - val_accuracy: 0.6458\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6837 - val_loss: 0.6077 - val_accuracy: 0.6458\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7150 - val_loss: 0.6072 - val_accuracy: 0.6458\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.6719 - val_loss: 0.6068 - val_accuracy: 0.6458\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7082 - val_loss: 0.6063 - val_accuracy: 0.6458\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6913 - val_loss: 0.6059 - val_accuracy: 0.6458\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7052 - val_loss: 0.6054 - val_accuracy: 0.6458\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6802 - val_loss: 0.6050 - val_accuracy: 0.6458\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.6892 - val_loss: 0.6046 - val_accuracy: 0.6458\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6884 - val_loss: 0.6041 - val_accuracy: 0.6458\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6996 - val_loss: 0.6037 - val_accuracy: 0.6354\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.6992 - val_loss: 0.6033 - val_accuracy: 0.6354\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.6900 - val_loss: 0.6028 - val_accuracy: 0.6354\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7015 - val_loss: 0.6024 - val_accuracy: 0.6354\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.6909 - val_loss: 0.6020 - val_accuracy: 0.6354\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7199 - val_loss: 0.6016 - val_accuracy: 0.6406\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7146 - val_loss: 0.6012 - val_accuracy: 0.6406\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.6908 - val_loss: 0.6007 - val_accuracy: 0.6406\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7021 - val_loss: 0.6003 - val_accuracy: 0.6458\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7198 - val_loss: 0.5999 - val_accuracy: 0.6510\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.6928 - val_loss: 0.5995 - val_accuracy: 0.6510\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7096 - val_loss: 0.5991 - val_accuracy: 0.6510\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.6969 - val_loss: 0.5987 - val_accuracy: 0.6510\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7178 - val_loss: 0.5983 - val_accuracy: 0.6510\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7204 - val_loss: 0.5979 - val_accuracy: 0.6510\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7525 - val_loss: 0.5975 - val_accuracy: 0.6562\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7199 - val_loss: 0.5971 - val_accuracy: 0.6562\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7243 - val_loss: 0.5968 - val_accuracy: 0.6562\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.6917 - val_loss: 0.5964 - val_accuracy: 0.6615\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7380 - val_loss: 0.5960 - val_accuracy: 0.6615\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7133 - val_loss: 0.5956 - val_accuracy: 0.6615\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7236 - val_loss: 0.5952 - val_accuracy: 0.6615\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7103 - val_loss: 0.5948 - val_accuracy: 0.6615\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7452 - val_loss: 0.5944 - val_accuracy: 0.6562\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7125 - val_loss: 0.5940 - val_accuracy: 0.6562\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7252 - val_loss: 0.5937 - val_accuracy: 0.6615\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7264 - val_loss: 0.5933 - val_accuracy: 0.6615\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7249 - val_loss: 0.5929 - val_accuracy: 0.6562\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7520 - val_loss: 0.5926 - val_accuracy: 0.6562\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7156 - val_loss: 0.5922 - val_accuracy: 0.6615\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7469 - val_loss: 0.5919 - val_accuracy: 0.6667\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7210 - val_loss: 0.5915 - val_accuracy: 0.6667\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7269 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7356 - val_loss: 0.5908 - val_accuracy: 0.6615\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7288 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7545 - val_loss: 0.5902 - val_accuracy: 0.6458\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7245 - val_loss: 0.5899 - val_accuracy: 0.6406\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7268 - val_loss: 0.5895 - val_accuracy: 0.6458\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7266 - val_loss: 0.5892 - val_accuracy: 0.6458\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7373 - val_loss: 0.5890 - val_accuracy: 0.6406\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7389 - val_loss: 0.5887 - val_accuracy: 0.6458\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7591 - val_loss: 0.5884 - val_accuracy: 0.6458\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7224 - val_loss: 0.5880 - val_accuracy: 0.6458\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7467 - val_loss: 0.5878 - val_accuracy: 0.6458\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7693 - val_loss: 0.5874 - val_accuracy: 0.6458\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7301 - val_loss: 0.5870 - val_accuracy: 0.6458\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7405 - val_loss: 0.5867 - val_accuracy: 0.6458\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7335 - val_loss: 0.5864 - val_accuracy: 0.6510\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7385 - val_loss: 0.5862 - val_accuracy: 0.6510\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7456 - val_loss: 0.5859 - val_accuracy: 0.6458\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7509 - val_loss: 0.5856 - val_accuracy: 0.6458\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7611 - val_loss: 0.5853 - val_accuracy: 0.6458\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7563 - val_loss: 0.5851 - val_accuracy: 0.6458\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7452 - val_loss: 0.5847 - val_accuracy: 0.6458\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7452 - val_loss: 0.5845 - val_accuracy: 0.6458\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7601 - val_loss: 0.5841 - val_accuracy: 0.6510\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7315 - val_loss: 0.5838 - val_accuracy: 0.6510\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7574 - val_loss: 0.5836 - val_accuracy: 0.6510\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7706 - val_loss: 0.5834 - val_accuracy: 0.6510\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7182 - val_loss: 0.5831 - val_accuracy: 0.6510\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7202 - val_loss: 0.5828 - val_accuracy: 0.6510\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7547 - val_loss: 0.5827 - val_accuracy: 0.6510\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7638 - val_loss: 0.5824 - val_accuracy: 0.6510\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7428 - val_loss: 0.5820 - val_accuracy: 0.6510\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7408 - val_loss: 0.5820 - val_accuracy: 0.6562\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7607 - val_loss: 0.5816 - val_accuracy: 0.6562\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7368 - val_loss: 0.5813 - val_accuracy: 0.6562\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7408 - val_loss: 0.5810 - val_accuracy: 0.6562\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7884 - val_loss: 0.5808 - val_accuracy: 0.6562\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7405 - val_loss: 0.5805 - val_accuracy: 0.6615\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7422 - val_loss: 0.5804 - val_accuracy: 0.6667\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7443 - val_loss: 0.5803 - val_accuracy: 0.6719\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7755 - val_loss: 0.5803 - val_accuracy: 0.6771\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7460 - val_loss: 0.5800 - val_accuracy: 0.6771\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7644 - val_loss: 0.5799 - val_accuracy: 0.6771\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7624 - val_loss: 0.5794 - val_accuracy: 0.6771\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7639 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7777 - val_loss: 0.5791 - val_accuracy: 0.6771\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7496 - val_loss: 0.5787 - val_accuracy: 0.6771\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7689 - val_loss: 0.5785 - val_accuracy: 0.6771\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7747 - val_loss: 0.5785 - val_accuracy: 0.6771\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7600 - val_loss: 0.5784 - val_accuracy: 0.6823\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7727 - val_loss: 0.5781 - val_accuracy: 0.6823\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7482 - val_loss: 0.5777 - val_accuracy: 0.6823\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7463 - val_loss: 0.5775 - val_accuracy: 0.6823\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7663 - val_loss: 0.5772 - val_accuracy: 0.6823\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7766 - val_loss: 0.5771 - val_accuracy: 0.6823\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7408 - val_loss: 0.5767 - val_accuracy: 0.6823\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7573 - val_loss: 0.5767 - val_accuracy: 0.6771\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7275 - val_loss: 0.5764 - val_accuracy: 0.6771\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7437 - val_loss: 0.5761 - val_accuracy: 0.6823\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7934 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7358 - val_loss: 0.5758 - val_accuracy: 0.6823\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7578 - val_loss: 0.5757 - val_accuracy: 0.6823\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7624 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7539 - val_loss: 0.5755 - val_accuracy: 0.6875\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7672 - val_loss: 0.5753 - val_accuracy: 0.6875\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7532 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7437 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7353 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7516 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7610 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7530 - val_loss: 0.5744 - val_accuracy: 0.6875\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7606 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7396 - val_loss: 0.5740 - val_accuracy: 0.6875\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7386 - val_loss: 0.5738 - val_accuracy: 0.6875\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7546 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7482 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7419 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7595 - val_loss: 0.5734 - val_accuracy: 0.6823\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7514 - val_loss: 0.5731 - val_accuracy: 0.6875\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7553 - val_loss: 0.5729 - val_accuracy: 0.6875\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7355 - val_loss: 0.5728 - val_accuracy: 0.6875\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7613 - val_loss: 0.5727 - val_accuracy: 0.6875\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7545 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7786 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7438 - val_loss: 0.5724 - val_accuracy: 0.6927\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7730 - val_loss: 0.5722 - val_accuracy: 0.6927\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7537 - val_loss: 0.5722 - val_accuracy: 0.6927\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7589 - val_loss: 0.5722 - val_accuracy: 0.6927\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7430 - val_loss: 0.5720 - val_accuracy: 0.6927\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7686 - val_loss: 0.5721 - val_accuracy: 0.6927\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7808 - val_loss: 0.5717 - val_accuracy: 0.6927\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7428 - val_loss: 0.5716 - val_accuracy: 0.6927\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7539 - val_loss: 0.5711 - val_accuracy: 0.6927\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7713 - val_loss: 0.5709 - val_accuracy: 0.6927\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7729 - val_loss: 0.5707 - val_accuracy: 0.6927\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7443 - val_loss: 0.5708 - val_accuracy: 0.6927\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7780 - val_loss: 0.5708 - val_accuracy: 0.6979\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7509 - val_loss: 0.5714 - val_accuracy: 0.7031\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7710 - val_loss: 0.5710 - val_accuracy: 0.7031\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7541 - val_loss: 0.5705 - val_accuracy: 0.7031\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7521 - val_loss: 0.5705 - val_accuracy: 0.7031\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7594 - val_loss: 0.5704 - val_accuracy: 0.7031\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7585 - val_loss: 0.5699 - val_accuracy: 0.7031\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7563 - val_loss: 0.5700 - val_accuracy: 0.7031\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7627 - val_loss: 0.5699 - val_accuracy: 0.7031\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7610 - val_loss: 0.5700 - val_accuracy: 0.7083\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7241 - val_loss: 0.5697 - val_accuracy: 0.7083\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7617 - val_loss: 0.5704 - val_accuracy: 0.7083\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7847 - val_loss: 0.5696 - val_accuracy: 0.7135\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7672 - val_loss: 0.5701 - val_accuracy: 0.7083\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7568 - val_loss: 0.5700 - val_accuracy: 0.7135\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7253 - val_loss: 0.5698 - val_accuracy: 0.7135\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7747 - val_loss: 0.5694 - val_accuracy: 0.7135\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7595 - val_loss: 0.5692 - val_accuracy: 0.7135\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7762 - val_loss: 0.5700 - val_accuracy: 0.7083\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7772 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7423 - val_loss: 0.5690 - val_accuracy: 0.7083\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7736 - val_loss: 0.5695 - val_accuracy: 0.7083\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7631 - val_loss: 0.5689 - val_accuracy: 0.7083\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7627 - val_loss: 0.5691 - val_accuracy: 0.7083\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7917 - val_loss: 0.5691 - val_accuracy: 0.7031\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7670 - val_loss: 0.5687 - val_accuracy: 0.7031\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8076 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7525 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7881 - val_loss: 0.5685 - val_accuracy: 0.6979\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5687 - val_accuracy: 0.6927\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7435 - val_loss: 0.5680 - val_accuracy: 0.6979\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7556 - val_loss: 0.5678 - val_accuracy: 0.6979\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7736 - val_loss: 0.5678 - val_accuracy: 0.6979\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7603 - val_loss: 0.5679 - val_accuracy: 0.6979\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7787 - val_loss: 0.5678 - val_accuracy: 0.6927\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7625 - val_loss: 0.5675 - val_accuracy: 0.6979\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7608 - val_loss: 0.5672 - val_accuracy: 0.6979\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7552 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7779 - val_loss: 0.5669 - val_accuracy: 0.6979\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.6927\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7638 - val_loss: 0.5678 - val_accuracy: 0.6875\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7875 - val_loss: 0.5681 - val_accuracy: 0.6875\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7822 - val_loss: 0.5680 - val_accuracy: 0.6875\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7572 - val_loss: 0.5678 - val_accuracy: 0.6875\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7559 - val_loss: 0.5677 - val_accuracy: 0.6875\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.8097 - val_loss: 0.5672 - val_accuracy: 0.6875\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7898 - val_loss: 0.5671 - val_accuracy: 0.6875\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7612 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7543 - val_loss: 0.5661 - val_accuracy: 0.6927\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7426 - val_loss: 0.5673 - val_accuracy: 0.6875\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7540 - val_loss: 0.5680 - val_accuracy: 0.6875\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7462 - val_loss: 0.5671 - val_accuracy: 0.6875\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7647 - val_loss: 0.5679 - val_accuracy: 0.6875\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7571 - val_loss: 0.5671 - val_accuracy: 0.6875\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7866 - val_loss: 0.5672 - val_accuracy: 0.6875\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7541 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7690 - val_loss: 0.5658 - val_accuracy: 0.6875\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7904 - val_loss: 0.5665 - val_accuracy: 0.6875\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7798 - val_loss: 0.5672 - val_accuracy: 0.6823\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7647 - val_loss: 0.5678 - val_accuracy: 0.6823\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7827 - val_loss: 0.5673 - val_accuracy: 0.6823\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7787 - val_loss: 0.5674 - val_accuracy: 0.6823\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7886 - val_loss: 0.5676 - val_accuracy: 0.6823\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7669 - val_loss: 0.5660 - val_accuracy: 0.6823\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7682 - val_loss: 0.5656 - val_accuracy: 0.6875\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7860 - val_loss: 0.5661 - val_accuracy: 0.6823\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7718 - val_loss: 0.5662 - val_accuracy: 0.6823\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7570 - val_loss: 0.5658 - val_accuracy: 0.6823\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7874 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7766 - val_loss: 0.5669 - val_accuracy: 0.6875\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7859 - val_loss: 0.5669 - val_accuracy: 0.6875\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7868 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7775 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.5662 - val_accuracy: 0.6875\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7802 - val_loss: 0.5669 - val_accuracy: 0.6875\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7689 - val_loss: 0.5669 - val_accuracy: 0.6875\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7735 - val_loss: 0.5661 - val_accuracy: 0.6875\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7826 - val_loss: 0.5668 - val_accuracy: 0.6875\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7493 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7799 - val_loss: 0.5662 - val_accuracy: 0.6875\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7531 - val_loss: 0.5662 - val_accuracy: 0.6875\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7958 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7734 - val_loss: 0.5667 - val_accuracy: 0.6927\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7628 - val_loss: 0.5661 - val_accuracy: 0.6875\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7660 - val_loss: 0.5661 - val_accuracy: 0.6875\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7667 - val_loss: 0.5656 - val_accuracy: 0.6875\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7979 - val_loss: 0.5658 - val_accuracy: 0.6927\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7690 - val_loss: 0.5650 - val_accuracy: 0.6875\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7849 - val_loss: 0.5651 - val_accuracy: 0.6875\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7638 - val_loss: 0.5654 - val_accuracy: 0.6927\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7582 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7640 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7742 - val_loss: 0.5654 - val_accuracy: 0.6979\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7714 - val_loss: 0.5646 - val_accuracy: 0.6875\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7783 - val_loss: 0.5648 - val_accuracy: 0.6979\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7575 - val_loss: 0.5649 - val_accuracy: 0.6979\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7623 - val_loss: 0.5636 - val_accuracy: 0.6875\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7660 - val_loss: 0.5646 - val_accuracy: 0.6979\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7765 - val_loss: 0.5651 - val_accuracy: 0.6979\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7924 - val_loss: 0.5652 - val_accuracy: 0.6979\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7582 - val_loss: 0.5652 - val_accuracy: 0.6979\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7738 - val_loss: 0.5648 - val_accuracy: 0.6979\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.5651 - val_accuracy: 0.6927\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7706 - val_loss: 0.5645 - val_accuracy: 0.6979\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7905 - val_loss: 0.5643 - val_accuracy: 0.6979\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7712 - val_loss: 0.5642 - val_accuracy: 0.6979\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7648 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7575 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7717 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7733 - val_loss: 0.5641 - val_accuracy: 0.6927\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7575 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7870 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7836 - val_loss: 0.5651 - val_accuracy: 0.6979\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7828 - val_loss: 0.5660 - val_accuracy: 0.7083\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7872 - val_loss: 0.5661 - val_accuracy: 0.7083\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7863 - val_loss: 0.5655 - val_accuracy: 0.7083\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7750 - val_loss: 0.5645 - val_accuracy: 0.7031\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7751 - val_loss: 0.5638 - val_accuracy: 0.6979\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7746 - val_loss: 0.5642 - val_accuracy: 0.7031\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7776 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7760 - val_loss: 0.5646 - val_accuracy: 0.7083\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7585 - val_loss: 0.5648 - val_accuracy: 0.7083\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7595 - val_loss: 0.5646 - val_accuracy: 0.7083\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7787 - val_loss: 0.5652 - val_accuracy: 0.7083\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7771 - val_loss: 0.5637 - val_accuracy: 0.7083\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7949 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7581 - val_loss: 0.5643 - val_accuracy: 0.7083\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7975 - val_loss: 0.5638 - val_accuracy: 0.7083\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7777 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7350 - val_loss: 0.5627 - val_accuracy: 0.7083\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7784 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8074 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7977 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7854 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7495 - val_loss: 0.5637 - val_accuracy: 0.7083\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7870 - val_loss: 0.5639 - val_accuracy: 0.7083\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7810 - val_loss: 0.5630 - val_accuracy: 0.7083\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7855 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7911 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7851 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7903 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7913 - val_loss: 0.5653 - val_accuracy: 0.7083\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7710 - val_loss: 0.5633 - val_accuracy: 0.7083\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7716 - val_loss: 0.5634 - val_accuracy: 0.7083\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7832 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8089 - val_loss: 0.5634 - val_accuracy: 0.7083\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7840 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.7135\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7617 - val_loss: 0.5639 - val_accuracy: 0.7083\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7670 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7727 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7822 - val_loss: 0.5638 - val_accuracy: 0.7135\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7662 - val_loss: 0.5636 - val_accuracy: 0.7083\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7758 - val_loss: 0.5637 - val_accuracy: 0.7135\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7767 - val_loss: 0.5634 - val_accuracy: 0.7135\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8025 - val_loss: 0.5639 - val_accuracy: 0.7135\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7623 - val_loss: 0.5655 - val_accuracy: 0.7135\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7738 - val_loss: 0.5649 - val_accuracy: 0.7135\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7903 - val_loss: 0.5638 - val_accuracy: 0.7135\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7659 - val_loss: 0.5624 - val_accuracy: 0.7083\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7783 - val_loss: 0.5617 - val_accuracy: 0.7083\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7767 - val_loss: 0.5634 - val_accuracy: 0.7135\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.7135\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7733 - val_loss: 0.5640 - val_accuracy: 0.7135\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7819 - val_loss: 0.5640 - val_accuracy: 0.7188\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7927 - val_loss: 0.5636 - val_accuracy: 0.7135\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7884 - val_loss: 0.5628 - val_accuracy: 0.7135\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8140 - val_loss: 0.5631 - val_accuracy: 0.7188\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7896 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7719 - val_loss: 0.5623 - val_accuracy: 0.7135\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7662 - val_loss: 0.5622 - val_accuracy: 0.7188\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7826 - val_loss: 0.5613 - val_accuracy: 0.7135\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7678 - val_loss: 0.5625 - val_accuracy: 0.7188\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8080 - val_loss: 0.5640 - val_accuracy: 0.7188\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8052 - val_loss: 0.5642 - val_accuracy: 0.7188\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7981 - val_loss: 0.5642 - val_accuracy: 0.7188\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7467 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7809 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7705 - val_loss: 0.5607 - val_accuracy: 0.7188\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8179 - val_loss: 0.5613 - val_accuracy: 0.7188\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7875 - val_loss: 0.5633 - val_accuracy: 0.7135\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7802 - val_loss: 0.5628 - val_accuracy: 0.7188\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7920 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7874 - val_loss: 0.5630 - val_accuracy: 0.7188\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7668 - val_loss: 0.5622 - val_accuracy: 0.7135\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7790 - val_loss: 0.5621 - val_accuracy: 0.7135\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7780 - val_loss: 0.5616 - val_accuracy: 0.7135\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7913 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7714 - val_loss: 0.5620 - val_accuracy: 0.7188\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7805 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8145 - val_loss: 0.5631 - val_accuracy: 0.7188\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7664 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7929 - val_loss: 0.5627 - val_accuracy: 0.7188\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7540 - val_loss: 0.5623 - val_accuracy: 0.7188\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7822 - val_loss: 0.5616 - val_accuracy: 0.7188\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8221 - val_loss: 0.5637 - val_accuracy: 0.7240\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7807 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7839 - val_loss: 0.5607 - val_accuracy: 0.7188\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.8025 - val_loss: 0.5613 - val_accuracy: 0.7188\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7917 - val_loss: 0.5610 - val_accuracy: 0.7188\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7930 - val_loss: 0.5624 - val_accuracy: 0.7240\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7755 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8042 - val_loss: 0.5616 - val_accuracy: 0.7240\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7812 - val_loss: 0.5589 - val_accuracy: 0.7135\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7933 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7892 - val_loss: 0.5610 - val_accuracy: 0.7240\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7876 - val_loss: 0.5597 - val_accuracy: 0.7188\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7842 - val_loss: 0.5612 - val_accuracy: 0.7240\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7654 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7698 - val_loss: 0.5591 - val_accuracy: 0.7135\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7950 - val_loss: 0.5594 - val_accuracy: 0.7188\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7873 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7930 - val_loss: 0.5609 - val_accuracy: 0.7240\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7797 - val_loss: 0.5616 - val_accuracy: 0.7240\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8036 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7946 - val_loss: 0.5616 - val_accuracy: 0.7188\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8057 - val_loss: 0.5614 - val_accuracy: 0.7240\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7733 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7835 - val_loss: 0.5615 - val_accuracy: 0.7188\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7586 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7848 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7816 - val_loss: 0.5608 - val_accuracy: 0.7188\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7886 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7867 - val_loss: 0.5599 - val_accuracy: 0.7292\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7911 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8223 - val_loss: 0.5621 - val_accuracy: 0.7188\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7982 - val_loss: 0.5610 - val_accuracy: 0.7188\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7838 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7890 - val_loss: 0.5609 - val_accuracy: 0.7240\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7949 - val_loss: 0.5600 - val_accuracy: 0.7240\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7956 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7708 - val_loss: 0.5607 - val_accuracy: 0.7188\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7735 - val_loss: 0.5605 - val_accuracy: 0.7188\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7744 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7824 - val_loss: 0.5602 - val_accuracy: 0.7188\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.8033 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7957 - val_loss: 0.5598 - val_accuracy: 0.7188\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7844 - val_loss: 0.5602 - val_accuracy: 0.7240\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7917 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8082 - val_loss: 0.5620 - val_accuracy: 0.7292\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7794 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7925 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8182 - val_loss: 0.5610 - val_accuracy: 0.7292\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7950 - val_loss: 0.5605 - val_accuracy: 0.7292\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7738 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7875 - val_loss: 0.5595 - val_accuracy: 0.7240\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7959 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7844 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7902 - val_loss: 0.5625 - val_accuracy: 0.7344\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7912 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7649 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7922 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7948 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7901 - val_loss: 0.5612 - val_accuracy: 0.7292\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.5601 - val_accuracy: 0.7292\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8124 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7918 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7784 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7915 - val_loss: 0.5599 - val_accuracy: 0.7292\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7921 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7941 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7795 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7960 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7740 - val_loss: 0.5605 - val_accuracy: 0.7292\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7800 - val_loss: 0.5625 - val_accuracy: 0.7344\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8053 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7962 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7995 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7936 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7911 - val_loss: 0.5611 - val_accuracy: 0.7396\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7960 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7787 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7956 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7722 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.8001 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7822 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7728 - val_loss: 0.5616 - val_accuracy: 0.7396\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7978 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7946 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8040 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7954 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5604 - val_accuracy: 0.7396\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7900 - val_loss: 0.5610 - val_accuracy: 0.7396\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7704 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7792 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8304 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7920 - val_loss: 0.5608 - val_accuracy: 0.7396\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8133 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7897 - val_loss: 0.5599 - val_accuracy: 0.7396\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7899 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7747 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8056 - val_loss: 0.5575 - val_accuracy: 0.7292\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8022 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.8005 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7979 - val_loss: 0.5580 - val_accuracy: 0.7292\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8098 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7948 - val_loss: 0.5608 - val_accuracy: 0.7396\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8197 - val_loss: 0.5605 - val_accuracy: 0.7396\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7781 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8054 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8052 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8021 - val_loss: 0.5620 - val_accuracy: 0.7344\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7561 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7854 - val_loss: 0.5599 - val_accuracy: 0.7396\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7861 - val_loss: 0.5610 - val_accuracy: 0.7396\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7880 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7836 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7824 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8035 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8084 - val_loss: 0.5614 - val_accuracy: 0.7292\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7615 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7782 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7926 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7860 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7913 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8110 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7797 - val_loss: 0.5598 - val_accuracy: 0.7448\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7888 - val_loss: 0.5587 - val_accuracy: 0.7448\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8069 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7737 - val_loss: 0.5615 - val_accuracy: 0.7292\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7998 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7904 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8354 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7764 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7893 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8056 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8048 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8249 - val_loss: 0.5617 - val_accuracy: 0.7344\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7832 - val_loss: 0.5581 - val_accuracy: 0.7448\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7683 - val_loss: 0.5587 - val_accuracy: 0.7396\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7985 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7832 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7719 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7935 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7949 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7872 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8092 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8187 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7850 - val_loss: 0.5588 - val_accuracy: 0.7396\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7970 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7799 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8122 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7773 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7896 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7831 - val_loss: 0.5599 - val_accuracy: 0.7396\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7871 - val_loss: 0.5624 - val_accuracy: 0.7344\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7769 - val_loss: 0.5623 - val_accuracy: 0.7344\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7870 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7736 - val_loss: 0.5615 - val_accuracy: 0.7344\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7817 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7956 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7953 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7870 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7657 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7955 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7841 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7648 - val_loss: 0.5588 - val_accuracy: 0.7396\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7623 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7903 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8057 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7894 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8026 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7973 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7535 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7696 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7943 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7923 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7870 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7883 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7671 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7556 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7895 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7649 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7845 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7470 - val_loss: 0.5567 - val_accuracy: 0.7396\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7638 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7846 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7994 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.8021 - val_loss: 0.5602 - val_accuracy: 0.7344\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7752 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7671 - val_loss: 0.5588 - val_accuracy: 0.7396\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7906 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.5598 - val_accuracy: 0.7344\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7716 - val_loss: 0.5589 - val_accuracy: 0.7396\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7860 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7738 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7871 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7686 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7913 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7838 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8120 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7667 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7975 - val_loss: 0.5620 - val_accuracy: 0.7344\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7945 - val_loss: 0.5621 - val_accuracy: 0.7292\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.8094 - val_loss: 0.5629 - val_accuracy: 0.7292\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7769 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7522 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7630 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7759 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7854 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7936 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8002 - val_loss: 0.5610 - val_accuracy: 0.7292\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7720 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7602 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7818 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7543 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7740 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7869 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7593 - val_loss: 0.5619 - val_accuracy: 0.7292\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7744 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7945 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7659 - val_loss: 0.5619 - val_accuracy: 0.7292\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7809 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7693 - val_loss: 0.5582 - val_accuracy: 0.7292\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7800 - val_loss: 0.5595 - val_accuracy: 0.7292\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7774 - val_loss: 0.5610 - val_accuracy: 0.7292\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7826 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7800 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7898 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7895 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7815 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7651 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7947 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7645 - val_loss: 0.5615 - val_accuracy: 0.7240\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7819 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7527 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7577 - val_loss: 0.5592 - val_accuracy: 0.7344\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8070 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7879 - val_loss: 0.5620 - val_accuracy: 0.7240\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7870 - val_loss: 0.5579 - val_accuracy: 0.7292\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7659 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7804 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7560 - val_loss: 0.5571 - val_accuracy: 0.7292\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7729 - val_loss: 0.5567 - val_accuracy: 0.7292\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7682 - val_loss: 0.5568 - val_accuracy: 0.7292\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7699 - val_loss: 0.5566 - val_accuracy: 0.7292\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7867 - val_loss: 0.5567 - val_accuracy: 0.7292\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7897 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7741 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7670 - val_loss: 0.5610 - val_accuracy: 0.7240\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7858 - val_loss: 0.5600 - val_accuracy: 0.7240\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7684 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7695 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7677 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7408 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7716 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7670 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8027 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7350 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7791 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5584 - val_accuracy: 0.7240\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7744 - val_loss: 0.5579 - val_accuracy: 0.7240\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8032 - val_loss: 0.5576 - val_accuracy: 0.7240\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7849 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7437 - val_loss: 0.5570 - val_accuracy: 0.7240\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7668 - val_loss: 0.5580 - val_accuracy: 0.7240\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7753 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7636 - val_loss: 0.5577 - val_accuracy: 0.7240\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7904 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7902 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7898 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7886 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7675 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7959 - val_loss: 0.5601 - val_accuracy: 0.7292\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8142 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7711 - val_loss: 0.5567 - val_accuracy: 0.7240\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7698 - val_loss: 0.5567 - val_accuracy: 0.7240\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7789 - val_loss: 0.5579 - val_accuracy: 0.7292\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8098 - val_loss: 0.5616 - val_accuracy: 0.7292\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7994 - val_loss: 0.5572 - val_accuracy: 0.7292\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7841 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7966 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7855 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.5591 - val_accuracy: 0.7292\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8048 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8057 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7541 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7512 - val_loss: 0.5594 - val_accuracy: 0.7292\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7866 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7659 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8005 - val_loss: 0.5576 - val_accuracy: 0.7292\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7913 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8087 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7959 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7741 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7717 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7796 - val_loss: 0.5567 - val_accuracy: 0.7292\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7804 - val_loss: 0.5584 - val_accuracy: 0.7292\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7829 - val_loss: 0.5582 - val_accuracy: 0.7292\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7835 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7624 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8079 - val_loss: 0.5566 - val_accuracy: 0.7292\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7505 - val_loss: 0.5555 - val_accuracy: 0.7344\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7855 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8015 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7722 - val_loss: 0.5539 - val_accuracy: 0.7240\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7570 - val_loss: 0.5565 - val_accuracy: 0.7344\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7836 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7683 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8074 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7671 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7682 - val_loss: 0.5543 - val_accuracy: 0.7292\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7816 - val_loss: 0.5576 - val_accuracy: 0.7292\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7648 - val_loss: 0.5589 - val_accuracy: 0.7292\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7883 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7803 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7782 - val_loss: 0.5570 - val_accuracy: 0.7292\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7712 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7750 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7827 - val_loss: 0.5593 - val_accuracy: 0.7240\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7864 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7653 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7997 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7963 - val_loss: 0.5609 - val_accuracy: 0.7188\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7886 - val_loss: 0.5588 - val_accuracy: 0.7240\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7687 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7730 - val_loss: 0.5576 - val_accuracy: 0.7292\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7648 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8006 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7624 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7702 - val_loss: 0.5595 - val_accuracy: 0.7188\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7850 - val_loss: 0.5567 - val_accuracy: 0.7292\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8037 - val_loss: 0.5576 - val_accuracy: 0.7292\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7939 - val_loss: 0.5583 - val_accuracy: 0.7240\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.5583 - val_accuracy: 0.7240\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7831 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7593 - val_loss: 0.5571 - val_accuracy: 0.7292\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.5594 - val_accuracy: 0.7188\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.5588 - val_accuracy: 0.7240\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7807 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7689 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7680 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7705 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7843 - val_loss: 0.5603 - val_accuracy: 0.7188\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7837 - val_loss: 0.5619 - val_accuracy: 0.7188\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7598 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7911 - val_loss: 0.5574 - val_accuracy: 0.7240\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7910 - val_loss: 0.5559 - val_accuracy: 0.7292\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7904 - val_loss: 0.5566 - val_accuracy: 0.7240\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7894 - val_loss: 0.5551 - val_accuracy: 0.7292\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7959 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7787 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7806 - val_loss: 0.5576 - val_accuracy: 0.7135\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7569 - val_loss: 0.5543 - val_accuracy: 0.7292\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7676 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7732 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7884 - val_loss: 0.5581 - val_accuracy: 0.7135\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7915 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7784 - val_loss: 0.5565 - val_accuracy: 0.7240\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7892 - val_loss: 0.5560 - val_accuracy: 0.7240\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7964 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7923 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7900 - val_loss: 0.5603 - val_accuracy: 0.7135\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7898 - val_loss: 0.5582 - val_accuracy: 0.7135\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7837 - val_loss: 0.5587 - val_accuracy: 0.7135\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7686 - val_loss: 0.5582 - val_accuracy: 0.7135\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7700 - val_loss: 0.5562 - val_accuracy: 0.7240\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7960 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7978 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.5546 - val_accuracy: 0.7292\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7914 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7498 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7859 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7978 - val_loss: 0.5564 - val_accuracy: 0.7188\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8068 - val_loss: 0.5560 - val_accuracy: 0.7188\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7793 - val_loss: 0.5584 - val_accuracy: 0.7135\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7817 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7887 - val_loss: 0.5569 - val_accuracy: 0.7188\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7800 - val_loss: 0.5554 - val_accuracy: 0.7240\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7776 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7849 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7852 - val_loss: 0.5566 - val_accuracy: 0.7188\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7671 - val_loss: 0.5548 - val_accuracy: 0.7240\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8094 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7804 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7715 - val_loss: 0.5564 - val_accuracy: 0.7188\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7846 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7995 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7527 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8065 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7878 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7740 - val_loss: 0.5585 - val_accuracy: 0.7188\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7742 - val_loss: 0.5588 - val_accuracy: 0.7135\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7944 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7854 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7573 - val_loss: 0.5548 - val_accuracy: 0.7188\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7853 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7832 - val_loss: 0.5557 - val_accuracy: 0.7188\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7638 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7658 - val_loss: 0.5592 - val_accuracy: 0.7135\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7994 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7972 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7984 - val_loss: 0.5612 - val_accuracy: 0.7135\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7748 - val_loss: 0.5603 - val_accuracy: 0.7135\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7858 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7611 - val_loss: 0.5579 - val_accuracy: 0.7188\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7876 - val_loss: 0.5566 - val_accuracy: 0.7188\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8032 - val_loss: 0.5599 - val_accuracy: 0.7135\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7699 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7799 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7755 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7948 - val_loss: 0.5597 - val_accuracy: 0.7135\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7871 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7839 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7663 - val_loss: 0.5558 - val_accuracy: 0.7188\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7842 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8019 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7885 - val_loss: 0.5552 - val_accuracy: 0.7188\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7840 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8126 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8004 - val_loss: 0.5642 - val_accuracy: 0.7135\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7791 - val_loss: 0.5585 - val_accuracy: 0.7188\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7782 - val_loss: 0.5563 - val_accuracy: 0.7188\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7940 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7630 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7960 - val_loss: 0.5597 - val_accuracy: 0.7135\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7434 - val_loss: 0.5602 - val_accuracy: 0.7135\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7730 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7724 - val_loss: 0.5599 - val_accuracy: 0.7135\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7942 - val_loss: 0.5609 - val_accuracy: 0.7135\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7949 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7758 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7660 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7985 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7943 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7877 - val_loss: 0.5590 - val_accuracy: 0.7188\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7649 - val_loss: 0.5587 - val_accuracy: 0.7188\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7978 - val_loss: 0.5585 - val_accuracy: 0.7188\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7771 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8048 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7846 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7590 - val_loss: 0.5597 - val_accuracy: 0.7135\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7706 - val_loss: 0.5592 - val_accuracy: 0.7188\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7807 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8131 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8066 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7947 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7970 - val_loss: 0.5618 - val_accuracy: 0.7135\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7823 - val_loss: 0.5612 - val_accuracy: 0.7135\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7653 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7922 - val_loss: 0.5621 - val_accuracy: 0.7135\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7716 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7957 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7799 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7976 - val_loss: 0.5596 - val_accuracy: 0.7135\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7712 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7640 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7670 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7702 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7845 - val_loss: 0.5603 - val_accuracy: 0.7135\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7590 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7923 - val_loss: 0.5581 - val_accuracy: 0.7188\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7694 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7737 - val_loss: 0.5592 - val_accuracy: 0.7188\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7915 - val_loss: 0.5566 - val_accuracy: 0.7188\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8025 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7859 - val_loss: 0.5603 - val_accuracy: 0.7135\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7521 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7669 - val_loss: 0.5587 - val_accuracy: 0.7188\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7868 - val_loss: 0.5591 - val_accuracy: 0.7188\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7858 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7930 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7723 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8086 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8042 - val_loss: 0.5602 - val_accuracy: 0.7135\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7915 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7701 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7825 - val_loss: 0.5567 - val_accuracy: 0.7188\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7808 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7998 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8054 - val_loss: 0.5587 - val_accuracy: 0.7188\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7989 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8189 - val_loss: 0.5581 - val_accuracy: 0.7188\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7920 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8128 - val_loss: 0.5579 - val_accuracy: 0.7188\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7886 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7595 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7827 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7754 - val_loss: 0.5599 - val_accuracy: 0.7135\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7499 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8009 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7993 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7736 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7921 - val_loss: 0.5591 - val_accuracy: 0.7135\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7920 - val_loss: 0.5583 - val_accuracy: 0.7135\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7759 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7866 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7873 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7889 - val_loss: 0.5588 - val_accuracy: 0.7135\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7807 - val_loss: 0.5588 - val_accuracy: 0.7135\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7845 - val_loss: 0.5589 - val_accuracy: 0.7135\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7848 - val_loss: 0.5580 - val_accuracy: 0.7240\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7888 - val_loss: 0.5585 - val_accuracy: 0.7135\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7978 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7788 - val_loss: 0.5585 - val_accuracy: 0.7135\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7871 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7798 - val_loss: 0.5580 - val_accuracy: 0.7240\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7628 - val_loss: 0.5567 - val_accuracy: 0.7240\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7775 - val_loss: 0.5573 - val_accuracy: 0.7240\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7792 - val_loss: 0.5568 - val_accuracy: 0.7240\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7981 - val_loss: 0.5553 - val_accuracy: 0.7240\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7781 - val_loss: 0.5556 - val_accuracy: 0.7240\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7988 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8023 - val_loss: 0.5579 - val_accuracy: 0.7240\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7497 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7807 - val_loss: 0.5577 - val_accuracy: 0.7240\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7749 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7745 - val_loss: 0.5591 - val_accuracy: 0.7188\n",
            "Evaluating on training set...\n",
            "loss=0.4454, accuracy: 78.1250%\n",
            "Evaluating on testing set...\n",
            "loss=0.5591, accuracy: 71.8750%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum Loss : 0.6911\n",
            "\n",
            "Minimum Loss : 0.4459\n",
            "\n",
            "Loss difference : 0.2452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aUib8rxU-Vui",
        "outputId": "2e453fe7-ffb5-480a-ea8f-c2f977aa091a"
      },
      "source": [
        "# Hyperparameters\r\n",
        "training_epochs1 = 1000 # Total number of training epochs\r\n",
        "learning_rate1 = 0.01 # The learning rate\r\n",
        "#momentum = 0.9\r\n",
        "\r\n",
        "# create a model\r\n",
        "def create_model1():\r\n",
        "    model1 = tf.keras.Sequential()\r\n",
        "    # Hidden layer\r\n",
        "    model1.add(tf.keras.layers.Dense(20, input_dim=8,activation='relu'))\r\n",
        "    # Hidden layer 2\r\n",
        "    model1.add(tf.keras.layers.Dense(20, input_dim=8,activation='relu'))\r\n",
        "    # Output layer\r\n",
        "    model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    # Compile a model\r\n",
        "    model1.compile(loss='binary_crossentropy', \r\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    return model1\r\n",
        "\r\n",
        "model1 = create_model1()\r\n",
        "model1.summary()\r\n",
        "\r\n",
        "\r\n",
        "results1 = model1.fit(\r\n",
        "    x_tr, y_tr,\r\n",
        "    epochs= training_epochs1,\r\n",
        "    validation_data = (x_ts, y_ts),\r\n",
        "    verbose = 1\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Evaluating on training set...\")\r\n",
        "(loss, accuracy) = model1.evaluate(x_tr, y_tr, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "print(\"Evaluating on testing set...\")\r\n",
        "(loss, accuracy) = model1.evaluate(x_ts, y_ts, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(results1.history['accuracy'])\r\n",
        "plt.plot(results1.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(results1.history['loss'])\r\n",
        "plt.plot(results1.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "max_loss1 = np.max(results1.history['loss'])\r\n",
        "min_loss1 = np.min(results1.history['loss'])\r\n",
        "print(\"Maximum Loss : {:.4f}\".format(max_loss1))\r\n",
        "print(\"\")\r\n",
        "print(\"Minimum Loss : {:.4f}\".format(min_loss1))\r\n",
        "print(\"\")\r\n",
        "print(\"Loss difference : {:.4f}\".format((max_loss1 - min_loss1)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 20)                180       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 621\n",
            "Trainable params: 621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6890 - accuracy: 0.6315 - val_loss: 0.6819 - val_accuracy: 0.6302\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6653 - val_loss: 0.6789 - val_accuracy: 0.6302\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.6471 - val_loss: 0.6767 - val_accuracy: 0.6302\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6649 - val_loss: 0.6750 - val_accuracy: 0.6302\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.6610 - val_loss: 0.6737 - val_accuracy: 0.6302\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6423 - val_loss: 0.6728 - val_accuracy: 0.6302\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6762 - val_loss: 0.6720 - val_accuracy: 0.6302\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6765 - val_loss: 0.6713 - val_accuracy: 0.6302\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6611 - val_loss: 0.6708 - val_accuracy: 0.6302\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6648 - val_loss: 0.6702 - val_accuracy: 0.6302\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6539 - val_loss: 0.6698 - val_accuracy: 0.6302\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6493 - val_loss: 0.6693 - val_accuracy: 0.6302\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6248 - val_loss: 0.6689 - val_accuracy: 0.6302\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6813 - val_loss: 0.6685 - val_accuracy: 0.6302\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6416 - val_loss: 0.6681 - val_accuracy: 0.6302\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6560 - val_loss: 0.6676 - val_accuracy: 0.6302\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6611 - val_loss: 0.6672 - val_accuracy: 0.6302\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6308 - val_loss: 0.6668 - val_accuracy: 0.6302\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6701 - val_loss: 0.6663 - val_accuracy: 0.6302\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6579 - val_loss: 0.6658 - val_accuracy: 0.6302\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6599 - val_loss: 0.6653 - val_accuracy: 0.6302\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6871 - val_loss: 0.6648 - val_accuracy: 0.6302\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6674 - val_loss: 0.6644 - val_accuracy: 0.6302\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6519 - val_loss: 0.6639 - val_accuracy: 0.6302\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6744 - val_loss: 0.6633 - val_accuracy: 0.6302\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6567 - val_loss: 0.6628 - val_accuracy: 0.6302\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6472 - val_loss: 0.6624 - val_accuracy: 0.6302\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6525 - val_loss: 0.6619 - val_accuracy: 0.6302\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6635 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6665 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6594 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6875 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6526 - val_loss: 0.6594 - val_accuracy: 0.6302\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6545 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6408 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6592 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.6456 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6600 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6802 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6617 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6504 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.6828 - val_loss: 0.6548 - val_accuracy: 0.6302\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6217 - val_loss: 0.6545 - val_accuracy: 0.6302\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6242 - val_loss: 0.6540 - val_accuracy: 0.6302\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6648 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6520 - val_loss: 0.6529 - val_accuracy: 0.6302\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.6721 - val_loss: 0.6524 - val_accuracy: 0.6302\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6435 - val_loss: 0.6520 - val_accuracy: 0.6302\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6570 - val_loss: 0.6515 - val_accuracy: 0.6302\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6460 - val_loss: 0.6510 - val_accuracy: 0.6302\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6355 - val_loss: 0.6505 - val_accuracy: 0.6302\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6437 - val_loss: 0.6499 - val_accuracy: 0.6302\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6917 - val_loss: 0.6493 - val_accuracy: 0.6302\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6523 - val_loss: 0.6487 - val_accuracy: 0.6302\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6444 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6659 - val_loss: 0.6476 - val_accuracy: 0.6302\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6468 - val_loss: 0.6470 - val_accuracy: 0.6302\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6761 - val_loss: 0.6463 - val_accuracy: 0.6302\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6537 - val_loss: 0.6458 - val_accuracy: 0.6302\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.6669 - val_loss: 0.6452 - val_accuracy: 0.6302\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6457 - val_loss: 0.6446 - val_accuracy: 0.6302\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6568 - val_loss: 0.6440 - val_accuracy: 0.6302\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6313 - val_loss: 0.6435 - val_accuracy: 0.6302\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6168 - val_loss: 0.6429 - val_accuracy: 0.6302\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6817 - val_loss: 0.6422 - val_accuracy: 0.6302\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6797 - val_loss: 0.6416 - val_accuracy: 0.6302\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6640 - val_loss: 0.6409 - val_accuracy: 0.6302\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6491 - val_loss: 0.6403 - val_accuracy: 0.6302\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6302\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6671 - val_loss: 0.6389 - val_accuracy: 0.6302\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.6789 - val_loss: 0.6382 - val_accuracy: 0.6302\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6542 - val_loss: 0.6376 - val_accuracy: 0.6302\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6383 - val_loss: 0.6370 - val_accuracy: 0.6302\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6764 - val_loss: 0.6363 - val_accuracy: 0.6302\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6284 - val_loss: 0.6357 - val_accuracy: 0.6302\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6716 - val_loss: 0.6350 - val_accuracy: 0.6302\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.6520 - val_loss: 0.6343 - val_accuracy: 0.6302\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6585 - val_loss: 0.6337 - val_accuracy: 0.6302\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6689 - val_loss: 0.6330 - val_accuracy: 0.6302\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6426 - val_loss: 0.6323 - val_accuracy: 0.6302\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6542 - val_loss: 0.6316 - val_accuracy: 0.6302\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6440 - val_loss: 0.6310 - val_accuracy: 0.6250\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6727 - val_loss: 0.6303 - val_accuracy: 0.6250\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6406 - val_loss: 0.6296 - val_accuracy: 0.6250\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6722 - val_loss: 0.6289 - val_accuracy: 0.6250\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6548 - val_loss: 0.6283 - val_accuracy: 0.6250\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6406 - val_loss: 0.6276 - val_accuracy: 0.6250\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6931 - val_loss: 0.6268 - val_accuracy: 0.6250\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6511 - val_loss: 0.6261 - val_accuracy: 0.6250\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6440 - val_loss: 0.6254 - val_accuracy: 0.6250\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6707 - val_loss: 0.6246 - val_accuracy: 0.6250\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6826 - val_loss: 0.6238 - val_accuracy: 0.6302\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6537 - val_loss: 0.6232 - val_accuracy: 0.6406\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6564 - val_loss: 0.6225 - val_accuracy: 0.6406\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6746 - val_loss: 0.6217 - val_accuracy: 0.6458\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6889 - val_loss: 0.6209 - val_accuracy: 0.6458\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.6657 - val_loss: 0.6200 - val_accuracy: 0.6458\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6618 - val_loss: 0.6193 - val_accuracy: 0.6510\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6791 - val_loss: 0.6184 - val_accuracy: 0.6562\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6639 - val_loss: 0.6176 - val_accuracy: 0.6562\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.6609 - val_loss: 0.6169 - val_accuracy: 0.6562\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.6780 - val_loss: 0.6161 - val_accuracy: 0.6562\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.6965 - val_loss: 0.6152 - val_accuracy: 0.6562\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6929 - val_loss: 0.6144 - val_accuracy: 0.6510\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6775 - val_loss: 0.6136 - val_accuracy: 0.6615\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6873 - val_loss: 0.6128 - val_accuracy: 0.6615\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6946 - val_loss: 0.6120 - val_accuracy: 0.6615\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.7220 - val_loss: 0.6112 - val_accuracy: 0.6615\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6870 - val_loss: 0.6105 - val_accuracy: 0.6615\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7057 - val_loss: 0.6096 - val_accuracy: 0.6667\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7034 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7059 - val_loss: 0.6081 - val_accuracy: 0.6615\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7193 - val_loss: 0.6072 - val_accuracy: 0.6615\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7047 - val_loss: 0.6064 - val_accuracy: 0.6615\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7249 - val_loss: 0.6056 - val_accuracy: 0.6615\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7312 - val_loss: 0.6048 - val_accuracy: 0.6615\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7075 - val_loss: 0.6041 - val_accuracy: 0.6615\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7175 - val_loss: 0.6032 - val_accuracy: 0.6615\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7309 - val_loss: 0.6024 - val_accuracy: 0.6667\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7435 - val_loss: 0.6016 - val_accuracy: 0.6667\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7375 - val_loss: 0.6008 - val_accuracy: 0.6667\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7257 - val_loss: 0.6000 - val_accuracy: 0.6667\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7283 - val_loss: 0.5991 - val_accuracy: 0.6771\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7286 - val_loss: 0.5983 - val_accuracy: 0.6771\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7142 - val_loss: 0.5976 - val_accuracy: 0.6771\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7335 - val_loss: 0.5968 - val_accuracy: 0.6719\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7567 - val_loss: 0.5960 - val_accuracy: 0.6719\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7368 - val_loss: 0.5952 - val_accuracy: 0.6771\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7273 - val_loss: 0.5944 - val_accuracy: 0.6771\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7082 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7539 - val_loss: 0.5928 - val_accuracy: 0.6771\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7063 - val_loss: 0.5920 - val_accuracy: 0.6667\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7081 - val_loss: 0.5912 - val_accuracy: 0.6719\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6950 - val_loss: 0.5905 - val_accuracy: 0.6823\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7420 - val_loss: 0.5897 - val_accuracy: 0.6823\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6904 - val_loss: 0.5889 - val_accuracy: 0.6823\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7157 - val_loss: 0.5881 - val_accuracy: 0.6823\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7227 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7076 - val_loss: 0.5866 - val_accuracy: 0.6823\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7370 - val_loss: 0.5858 - val_accuracy: 0.6875\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7136 - val_loss: 0.5850 - val_accuracy: 0.6823\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7250 - val_loss: 0.5843 - val_accuracy: 0.6823\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7447 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7438 - val_loss: 0.5828 - val_accuracy: 0.6823\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7127 - val_loss: 0.5821 - val_accuracy: 0.6823\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7067 - val_loss: 0.5813 - val_accuracy: 0.6875\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7377 - val_loss: 0.5806 - val_accuracy: 0.6875\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7385 - val_loss: 0.5799 - val_accuracy: 0.6875\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7057 - val_loss: 0.5791 - val_accuracy: 0.6823\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7128 - val_loss: 0.5784 - val_accuracy: 0.6875\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7363 - val_loss: 0.5777 - val_accuracy: 0.6719\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7365 - val_loss: 0.5769 - val_accuracy: 0.6875\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.6823\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7309 - val_loss: 0.5757 - val_accuracy: 0.6875\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7500 - val_loss: 0.5749 - val_accuracy: 0.6875\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7503 - val_loss: 0.5741 - val_accuracy: 0.6771\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7439 - val_loss: 0.5736 - val_accuracy: 0.6719\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7227 - val_loss: 0.5729 - val_accuracy: 0.6719\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7199 - val_loss: 0.5719 - val_accuracy: 0.6771\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7472 - val_loss: 0.5715 - val_accuracy: 0.6719\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7430 - val_loss: 0.5708 - val_accuracy: 0.6719\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7494 - val_loss: 0.5701 - val_accuracy: 0.6719\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7561 - val_loss: 0.5695 - val_accuracy: 0.6719\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7327 - val_loss: 0.5687 - val_accuracy: 0.6719\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7693 - val_loss: 0.5684 - val_accuracy: 0.6719\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7440 - val_loss: 0.5674 - val_accuracy: 0.6719\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7491 - val_loss: 0.5666 - val_accuracy: 0.6719\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7390 - val_loss: 0.5668 - val_accuracy: 0.6615\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7675 - val_loss: 0.5655 - val_accuracy: 0.6719\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7772 - val_loss: 0.5661 - val_accuracy: 0.6771\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7487 - val_loss: 0.5647 - val_accuracy: 0.6667\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7755 - val_loss: 0.5642 - val_accuracy: 0.6719\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7584 - val_loss: 0.5630 - val_accuracy: 0.6667\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7756 - val_loss: 0.5634 - val_accuracy: 0.6875\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7604 - val_loss: 0.5624 - val_accuracy: 0.6823\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7542 - val_loss: 0.5618 - val_accuracy: 0.6875\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7664 - val_loss: 0.5613 - val_accuracy: 0.6771\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7580 - val_loss: 0.5601 - val_accuracy: 0.6823\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7567 - val_loss: 0.5599 - val_accuracy: 0.6823\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7934 - val_loss: 0.5600 - val_accuracy: 0.6875\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7884 - val_loss: 0.5606 - val_accuracy: 0.6927\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7896 - val_loss: 0.5585 - val_accuracy: 0.6823\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7400 - val_loss: 0.5584 - val_accuracy: 0.6927\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7763 - val_loss: 0.5579 - val_accuracy: 0.6927\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7650 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7726 - val_loss: 0.5565 - val_accuracy: 0.6979\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7890 - val_loss: 0.5557 - val_accuracy: 0.6927\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7818 - val_loss: 0.5555 - val_accuracy: 0.6979\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.8083 - val_loss: 0.5552 - val_accuracy: 0.6927\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7715 - val_loss: 0.5557 - val_accuracy: 0.6927\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.8006 - val_loss: 0.5570 - val_accuracy: 0.6927\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7483 - val_loss: 0.5529 - val_accuracy: 0.6927\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7802 - val_loss: 0.5539 - val_accuracy: 0.6927\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7747 - val_loss: 0.5525 - val_accuracy: 0.6927\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7462 - val_loss: 0.5527 - val_accuracy: 0.6927\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7764 - val_loss: 0.5521 - val_accuracy: 0.6979\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7778 - val_loss: 0.5526 - val_accuracy: 0.6927\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7598 - val_loss: 0.5530 - val_accuracy: 0.6927\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7773 - val_loss: 0.5510 - val_accuracy: 0.6979\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7633 - val_loss: 0.5501 - val_accuracy: 0.6979\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7678 - val_loss: 0.5505 - val_accuracy: 0.6927\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.8012 - val_loss: 0.5508 - val_accuracy: 0.6927\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7983 - val_loss: 0.5490 - val_accuracy: 0.6979\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7957 - val_loss: 0.5493 - val_accuracy: 0.7031\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7973 - val_loss: 0.5505 - val_accuracy: 0.7031\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7765 - val_loss: 0.5507 - val_accuracy: 0.7031\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7951 - val_loss: 0.5487 - val_accuracy: 0.7031\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7793 - val_loss: 0.5463 - val_accuracy: 0.6875\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7965 - val_loss: 0.5477 - val_accuracy: 0.7031\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7826 - val_loss: 0.5471 - val_accuracy: 0.7031\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7598 - val_loss: 0.5458 - val_accuracy: 0.6875\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7721 - val_loss: 0.5455 - val_accuracy: 0.6927\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7638 - val_loss: 0.5439 - val_accuracy: 0.6927\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7893 - val_loss: 0.5457 - val_accuracy: 0.7031\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7796 - val_loss: 0.5459 - val_accuracy: 0.7031\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7714 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7805 - val_loss: 0.5475 - val_accuracy: 0.7031\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7757 - val_loss: 0.5466 - val_accuracy: 0.7031\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7632 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7793 - val_loss: 0.5449 - val_accuracy: 0.7083\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7663 - val_loss: 0.5460 - val_accuracy: 0.7031\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8074 - val_loss: 0.5463 - val_accuracy: 0.7031\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7742 - val_loss: 0.5441 - val_accuracy: 0.7031\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7982 - val_loss: 0.5435 - val_accuracy: 0.7031\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7629 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7799 - val_loss: 0.5447 - val_accuracy: 0.7135\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7997 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7697 - val_loss: 0.5415 - val_accuracy: 0.7031\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7896 - val_loss: 0.5417 - val_accuracy: 0.7031\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7958 - val_loss: 0.5420 - val_accuracy: 0.7031\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7797 - val_loss: 0.5423 - val_accuracy: 0.7031\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8006 - val_loss: 0.5411 - val_accuracy: 0.7031\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7892 - val_loss: 0.5401 - val_accuracy: 0.6979\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7960 - val_loss: 0.5415 - val_accuracy: 0.7083\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7850 - val_loss: 0.5415 - val_accuracy: 0.7031\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7840 - val_loss: 0.5381 - val_accuracy: 0.6979\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7928 - val_loss: 0.5395 - val_accuracy: 0.6979\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7607 - val_loss: 0.5416 - val_accuracy: 0.6979\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7970 - val_loss: 0.5399 - val_accuracy: 0.7031\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7836 - val_loss: 0.5435 - val_accuracy: 0.7083\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7908 - val_loss: 0.5430 - val_accuracy: 0.7135\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7577 - val_loss: 0.5396 - val_accuracy: 0.7031\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7885 - val_loss: 0.5393 - val_accuracy: 0.7031\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.8094 - val_loss: 0.5422 - val_accuracy: 0.7135\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7743 - val_loss: 0.5392 - val_accuracy: 0.7083\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7801 - val_loss: 0.5386 - val_accuracy: 0.7083\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7831 - val_loss: 0.5411 - val_accuracy: 0.7135\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8019 - val_loss: 0.5422 - val_accuracy: 0.7135\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7910 - val_loss: 0.5414 - val_accuracy: 0.7135\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7944 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7959 - val_loss: 0.5413 - val_accuracy: 0.7135\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7567 - val_loss: 0.5371 - val_accuracy: 0.7083\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7932 - val_loss: 0.5363 - val_accuracy: 0.7083\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7929 - val_loss: 0.5391 - val_accuracy: 0.7135\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8087 - val_loss: 0.5387 - val_accuracy: 0.7135\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7787 - val_loss: 0.5377 - val_accuracy: 0.7135\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7774 - val_loss: 0.5362 - val_accuracy: 0.7083\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7726 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7964 - val_loss: 0.5405 - val_accuracy: 0.7135\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7651 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7756 - val_loss: 0.5397 - val_accuracy: 0.7135\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7860 - val_loss: 0.5434 - val_accuracy: 0.7031\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7889 - val_loss: 0.5391 - val_accuracy: 0.7135\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7897 - val_loss: 0.5415 - val_accuracy: 0.7083\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7729 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7876 - val_loss: 0.5408 - val_accuracy: 0.7083\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7135\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8027 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.8011 - val_loss: 0.5390 - val_accuracy: 0.7135\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7818 - val_loss: 0.5357 - val_accuracy: 0.7135\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7941 - val_loss: 0.5386 - val_accuracy: 0.7135\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7949 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7873 - val_loss: 0.5401 - val_accuracy: 0.7083\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7717 - val_loss: 0.5405 - val_accuracy: 0.7031\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7931 - val_loss: 0.5435 - val_accuracy: 0.7031\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7777 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8048 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7802 - val_loss: 0.5394 - val_accuracy: 0.7031\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7942 - val_loss: 0.5408 - val_accuracy: 0.7031\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8006 - val_loss: 0.5412 - val_accuracy: 0.7083\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8070 - val_loss: 0.5418 - val_accuracy: 0.7083\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7898 - val_loss: 0.5435 - val_accuracy: 0.7083\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7959 - val_loss: 0.5390 - val_accuracy: 0.7083\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7796 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7821 - val_loss: 0.5381 - val_accuracy: 0.7083\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7949 - val_loss: 0.5416 - val_accuracy: 0.7135\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7978 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.8020 - val_loss: 0.5414 - val_accuracy: 0.7135\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7779 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7915 - val_loss: 0.5377 - val_accuracy: 0.7135\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.8003 - val_loss: 0.5369 - val_accuracy: 0.7135\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7721 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7993 - val_loss: 0.5355 - val_accuracy: 0.7135\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7961 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8108 - val_loss: 0.5346 - val_accuracy: 0.7188\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8092 - val_loss: 0.5359 - val_accuracy: 0.7135\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8048 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7987 - val_loss: 0.5387 - val_accuracy: 0.7188\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7731 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8081 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7188\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8186 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8017 - val_loss: 0.5433 - val_accuracy: 0.7240\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7905 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8043 - val_loss: 0.5400 - val_accuracy: 0.7135\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8123 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7910 - val_loss: 0.5353 - val_accuracy: 0.7188\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7977 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7826 - val_loss: 0.5407 - val_accuracy: 0.7188\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8034 - val_loss: 0.5429 - val_accuracy: 0.7240\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7838 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7907 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7766 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7891 - val_loss: 0.5390 - val_accuracy: 0.7188\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7896 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7878 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7770 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7740 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7886 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7791 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7769 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8024 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7759 - val_loss: 0.5416 - val_accuracy: 0.7292\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8099 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7843 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7752 - val_loss: 0.5325 - val_accuracy: 0.7292\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7916 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7957 - val_loss: 0.5385 - val_accuracy: 0.7188\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7934 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7751 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8011 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7829 - val_loss: 0.5434 - val_accuracy: 0.7344\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8052 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8023 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7961 - val_loss: 0.5377 - val_accuracy: 0.7240\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8092 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7811 - val_loss: 0.5406 - val_accuracy: 0.7292\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8096 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8148 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7909 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7657 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7720 - val_loss: 0.5328 - val_accuracy: 0.7240\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7850 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8084 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7873 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7947 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7568 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7754 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7953 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7891 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8016 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8044 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8133 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7995 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7826 - val_loss: 0.5380 - val_accuracy: 0.7240\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7757 - val_loss: 0.5373 - val_accuracy: 0.7240\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7973 - val_loss: 0.5360 - val_accuracy: 0.7240\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8046 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8064 - val_loss: 0.5487 - val_accuracy: 0.7448\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8041 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7956 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.8016 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7959 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8039 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8326 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8357 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7789 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7898 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7882 - val_loss: 0.5445 - val_accuracy: 0.7396\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8084 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7431 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7582 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7948 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7727 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8034 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8145 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7944 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7678 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7654 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7907 - val_loss: 0.5459 - val_accuracy: 0.7292\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7995 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7928 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8076 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8018 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7548 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8174 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7967 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7988 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7599 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7914 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7995 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7827 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7800 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8187 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7873 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7838 - val_loss: 0.5360 - val_accuracy: 0.7344\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7531 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8288 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7712 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7859 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7850 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7801 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7784 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7956 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8040 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8028 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7974 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7868 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7820 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7944 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7962 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7653 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7909 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7887 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7806 - val_loss: 0.5474 - val_accuracy: 0.7292\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8049 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7967 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7923 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7932 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7828 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7918 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8116 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7731 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.8141 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8066 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8082 - val_loss: 0.5662 - val_accuracy: 0.7188\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7943 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8270 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7623 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8007 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8139 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8071 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7718 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7539 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7954 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8285 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7633 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7848 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7788 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7965 - val_loss: 0.5457 - val_accuracy: 0.7344\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7750 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7835 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7898 - val_loss: 0.5412 - val_accuracy: 0.7292\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8007 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8196 - val_loss: 0.5642 - val_accuracy: 0.7188\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7662 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8081 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7635 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8069 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8031 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7955 - val_loss: 0.5551 - val_accuracy: 0.7240\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7876 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7725 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7868 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7796 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7911 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8040 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7796 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7817 - val_loss: 0.5456 - val_accuracy: 0.7344\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7687 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7616 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8032 - val_loss: 0.5581 - val_accuracy: 0.7292\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7946 - val_loss: 0.5517 - val_accuracy: 0.7240\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7806 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7839 - val_loss: 0.5515 - val_accuracy: 0.7240\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8033 - val_loss: 0.5568 - val_accuracy: 0.7292\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7500 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7853 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8280 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8152 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8028 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8137 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8056 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7932 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7930 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8122 - val_loss: 0.5579 - val_accuracy: 0.7292\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8097 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8096 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8109 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7788 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7668 - val_loss: 0.5561 - val_accuracy: 0.7292\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7762 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8046 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8115 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8204 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8041 - val_loss: 0.5558 - val_accuracy: 0.7240\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8097 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7822 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7919 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8023 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8066 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8078 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7935 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7805 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7737 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8069 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8060 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7894 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8039 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7790 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7997 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8105 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7985 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7975 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7869 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8102 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7958 - val_loss: 0.5457 - val_accuracy: 0.7344\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8137 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7811 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8227 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8095 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7580 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7768 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8141 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7931 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7883 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7816 - val_loss: 0.5532 - val_accuracy: 0.7240\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7826 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7961 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8088 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7897 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7855 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8070 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7774 - val_loss: 0.5622 - val_accuracy: 0.7344\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7886 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8099 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8042 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8208 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7662 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7794 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7933 - val_loss: 0.5552 - val_accuracy: 0.7344\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7821 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8005 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7926 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8319 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7892 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7853 - val_loss: 0.5633 - val_accuracy: 0.7344\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8155 - val_loss: 0.5498 - val_accuracy: 0.7292\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7662 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7872 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7859 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7909 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8180 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7665 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7815 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8160 - val_loss: 0.5589 - val_accuracy: 0.7396\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7944 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8226 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7988 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7953 - val_loss: 0.5430 - val_accuracy: 0.7344\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7756 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8007 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8122 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8061 - val_loss: 0.5581 - val_accuracy: 0.7396\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8119 - val_loss: 0.5559 - val_accuracy: 0.7344\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7886 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7773 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7876 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7761 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7724 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7774 - val_loss: 0.5551 - val_accuracy: 0.7344\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8012 - val_loss: 0.5416 - val_accuracy: 0.7344\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7979 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8151 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8154 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7831 - val_loss: 0.5627 - val_accuracy: 0.7396\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7878 - val_loss: 0.5669 - val_accuracy: 0.7396\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7890 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8052 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7723 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8307 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8123 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7820 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7796 - val_loss: 0.5347 - val_accuracy: 0.7396\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8005 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8138 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7930 - val_loss: 0.5624 - val_accuracy: 0.7396\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8057 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7872 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7909 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7871 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8224 - val_loss: 0.5627 - val_accuracy: 0.7448\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8062 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7790 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8044 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8064 - val_loss: 0.5619 - val_accuracy: 0.7448\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7752 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7878 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8082 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8073 - val_loss: 0.5423 - val_accuracy: 0.7344\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7923 - val_loss: 0.5635 - val_accuracy: 0.7396\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7852 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7686 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7723 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7853 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8218 - val_loss: 0.5555 - val_accuracy: 0.7344\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7849 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8094 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7873 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7980 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7983 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8237 - val_loss: 0.5589 - val_accuracy: 0.7344\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7792 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7939 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7721 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8128 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8030 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7861 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8063 - val_loss: 0.5664 - val_accuracy: 0.7396\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7775 - val_loss: 0.5558 - val_accuracy: 0.7344\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7715 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7548 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7968 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7839 - val_loss: 0.5605 - val_accuracy: 0.7448\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7806 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8092 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8122 - val_loss: 0.5651 - val_accuracy: 0.7396\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7897 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7808 - val_loss: 0.5474 - val_accuracy: 0.7292\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7811 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7874 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7981 - val_loss: 0.5448 - val_accuracy: 0.7344\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7863 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8273 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8051 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8155 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8085 - val_loss: 0.5558 - val_accuracy: 0.7344\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8329 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7904 - val_loss: 0.5651 - val_accuracy: 0.7396\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7996 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7717 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7891 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7941 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8076 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7957 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7993 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7998 - val_loss: 0.5627 - val_accuracy: 0.7448\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7858 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7789 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7743 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7825 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7960 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7915 - val_loss: 0.5581 - val_accuracy: 0.7396\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7955 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7954 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7975 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7506 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7841 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8201 - val_loss: 0.5619 - val_accuracy: 0.7448\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8172 - val_loss: 0.5629 - val_accuracy: 0.7396\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7784 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7926 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7933 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8018 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8013 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7766 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8131 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7745 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7755 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8005 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8076 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7770 - val_loss: 0.5566 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7747 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.7904 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7914 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7943 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7997 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7993 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8016 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8017 - val_loss: 0.5572 - val_accuracy: 0.7396\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8009 - val_loss: 0.5607 - val_accuracy: 0.7448\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7953 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8009 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7932 - val_loss: 0.5559 - val_accuracy: 0.7344\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7939 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7920 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7734 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7957 - val_loss: 0.5656 - val_accuracy: 0.7396\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7741 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7779 - val_loss: 0.5622 - val_accuracy: 0.7448\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8161 - val_loss: 0.5701 - val_accuracy: 0.7396\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8273 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7906 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7753 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7458 - val_loss: 0.5433 - val_accuracy: 0.7396\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7908 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7955 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7791 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8000 - val_loss: 0.5686 - val_accuracy: 0.7396\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7622 - val_loss: 0.5407 - val_accuracy: 0.7396\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8015 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7973 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7987 - val_loss: 0.5681 - val_accuracy: 0.7396\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7880 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8190 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7734 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7707 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8019 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7979 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7803 - val_loss: 0.5494 - val_accuracy: 0.7448\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7925 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7797 - val_loss: 0.5433 - val_accuracy: 0.7448\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7691 - val_loss: 0.5558 - val_accuracy: 0.7396\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7954 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7740 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7945 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7895 - val_loss: 0.5499 - val_accuracy: 0.7448\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7837 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8015 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.8006 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8143 - val_loss: 0.5572 - val_accuracy: 0.7396\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7689 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8005 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8289 - val_loss: 0.5675 - val_accuracy: 0.7396\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7824 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8213 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7974 - val_loss: 0.5494 - val_accuracy: 0.7448\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7888 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8176 - val_loss: 0.5525 - val_accuracy: 0.7448\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7631 - val_loss: 0.5503 - val_accuracy: 0.7448\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7856 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8029 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7908 - val_loss: 0.5477 - val_accuracy: 0.7396\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7721 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8229 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8257 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8101 - val_loss: 0.5591 - val_accuracy: 0.7448\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7685 - val_loss: 0.5532 - val_accuracy: 0.7448\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5506 - val_accuracy: 0.7448\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7786 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7961 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7869 - val_loss: 0.5505 - val_accuracy: 0.7448\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7978 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8115 - val_loss: 0.5688 - val_accuracy: 0.7396\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7884 - val_loss: 0.5728 - val_accuracy: 0.7292\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7908 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8102 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7946 - val_loss: 0.5569 - val_accuracy: 0.7448\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7845 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7834 - val_loss: 0.5535 - val_accuracy: 0.7448\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7630 - val_loss: 0.5514 - val_accuracy: 0.7448\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7950 - val_loss: 0.5499 - val_accuracy: 0.7448\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8087 - val_loss: 0.5599 - val_accuracy: 0.7448\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7870 - val_loss: 0.5536 - val_accuracy: 0.7448\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7598 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7855 - val_loss: 0.5466 - val_accuracy: 0.7396\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7761 - val_loss: 0.5592 - val_accuracy: 0.7448\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7864 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8002 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7992 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7915 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7998 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7804 - val_loss: 0.5502 - val_accuracy: 0.7448\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7936 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7811 - val_loss: 0.5582 - val_accuracy: 0.7448\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7988 - val_loss: 0.5511 - val_accuracy: 0.7448\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7789 - val_loss: 0.5526 - val_accuracy: 0.7448\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8135 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7889 - val_loss: 0.5530 - val_accuracy: 0.7448\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7587 - val_loss: 0.5523 - val_accuracy: 0.7448\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8029 - val_loss: 0.5694 - val_accuracy: 0.7396\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7872 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7916 - val_loss: 0.5517 - val_accuracy: 0.7448\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7674 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8091 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7990 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8034 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7921 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8061 - val_loss: 0.5595 - val_accuracy: 0.7448\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8231 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.5634 - val_accuracy: 0.7448\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7921 - val_loss: 0.5678 - val_accuracy: 0.7396\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7935 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7945 - val_loss: 0.5534 - val_accuracy: 0.7448\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8220 - val_loss: 0.5606 - val_accuracy: 0.7448\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8067 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7907 - val_loss: 0.5649 - val_accuracy: 0.7396\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7845 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7696 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7790 - val_loss: 0.5540 - val_accuracy: 0.7552\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7887 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8136 - val_loss: 0.5575 - val_accuracy: 0.7500\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7734 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8074 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8082 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7956 - val_loss: 0.5479 - val_accuracy: 0.7552\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5505 - val_accuracy: 0.7552\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8131 - val_loss: 0.5546 - val_accuracy: 0.7552\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7767 - val_loss: 0.5552 - val_accuracy: 0.7552\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7861 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8118 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7839 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8221 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7767 - val_loss: 0.5570 - val_accuracy: 0.7552\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7992 - val_loss: 0.5539 - val_accuracy: 0.7552\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7897 - val_loss: 0.5540 - val_accuracy: 0.7552\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8016 - val_loss: 0.5643 - val_accuracy: 0.7396\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7791 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7936 - val_loss: 0.5495 - val_accuracy: 0.7552\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7997 - val_loss: 0.5507 - val_accuracy: 0.7552\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7762 - val_loss: 0.5601 - val_accuracy: 0.7500\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7716 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7745 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7932 - val_loss: 0.5535 - val_accuracy: 0.7552\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8001 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7914 - val_loss: 0.5590 - val_accuracy: 0.7552\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7939 - val_loss: 0.5594 - val_accuracy: 0.7552\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8357 - val_loss: 0.5529 - val_accuracy: 0.7604\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8036 - val_loss: 0.5580 - val_accuracy: 0.7552\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8201 - val_loss: 0.5747 - val_accuracy: 0.7396\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7839 - val_loss: 0.5500 - val_accuracy: 0.7552\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7912 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8148 - val_loss: 0.5480 - val_accuracy: 0.7552\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8138 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7955 - val_loss: 0.5522 - val_accuracy: 0.7604\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7780 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8069 - val_loss: 0.5513 - val_accuracy: 0.7604\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8086 - val_loss: 0.5521 - val_accuracy: 0.7604\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7962 - val_loss: 0.5543 - val_accuracy: 0.7604\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8052 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8041 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7872 - val_loss: 0.5499 - val_accuracy: 0.7552\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8005 - val_loss: 0.5515 - val_accuracy: 0.7604\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8018 - val_loss: 0.5628 - val_accuracy: 0.7448\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7868 - val_loss: 0.5588 - val_accuracy: 0.7500\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8189 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8192 - val_loss: 0.5546 - val_accuracy: 0.7604\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7930 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8134 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8148 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8025 - val_loss: 0.5727 - val_accuracy: 0.7396\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7852 - val_loss: 0.5506 - val_accuracy: 0.7604\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7864 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7924 - val_loss: 0.5571 - val_accuracy: 0.7604\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7989 - val_loss: 0.5498 - val_accuracy: 0.7552\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8104 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7894 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7878 - val_loss: 0.5332 - val_accuracy: 0.7500\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7989 - val_loss: 0.5487 - val_accuracy: 0.7552\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7689 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8059 - val_loss: 0.5501 - val_accuracy: 0.7604\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7956 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7885 - val_loss: 0.5587 - val_accuracy: 0.7552\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7903 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7735 - val_loss: 0.5478 - val_accuracy: 0.7500\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8046 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8065 - val_loss: 0.5541 - val_accuracy: 0.7604\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7968 - val_loss: 0.5496 - val_accuracy: 0.7552\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8006 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7861 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7785 - val_loss: 0.5519 - val_accuracy: 0.7604\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8005 - val_loss: 0.5497 - val_accuracy: 0.7552\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8144 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7923 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7740 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7542 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8011 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8005 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8127 - val_loss: 0.5610 - val_accuracy: 0.7500\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7911 - val_loss: 0.5738 - val_accuracy: 0.7396\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7798 - val_loss: 0.5624 - val_accuracy: 0.7500\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5528 - val_accuracy: 0.7604\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7824 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7862 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7661 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8122 - val_loss: 0.5578 - val_accuracy: 0.7552\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7793 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8113 - val_loss: 0.5719 - val_accuracy: 0.7448\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8025 - val_loss: 0.5537 - val_accuracy: 0.7604\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7753 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8055 - val_loss: 0.5505 - val_accuracy: 0.7604\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8040 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7923 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8035 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8149 - val_loss: 0.5524 - val_accuracy: 0.7604\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8079 - val_loss: 0.5568 - val_accuracy: 0.7552\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7875 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8047 - val_loss: 0.5548 - val_accuracy: 0.7604\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7883 - val_loss: 0.5550 - val_accuracy: 0.7552\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8281 - val_loss: 0.5509 - val_accuracy: 0.7552\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8017 - val_loss: 0.5530 - val_accuracy: 0.7604\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7906 - val_loss: 0.5580 - val_accuracy: 0.7500\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7772 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7829 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8257 - val_loss: 0.5775 - val_accuracy: 0.7448\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7996 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7647 - val_loss: 0.5590 - val_accuracy: 0.7500\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7925 - val_loss: 0.5541 - val_accuracy: 0.7604\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7973 - val_loss: 0.5516 - val_accuracy: 0.7552\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8073 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7825 - val_loss: 0.5364 - val_accuracy: 0.7448\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7891 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8124 - val_loss: 0.5673 - val_accuracy: 0.7552\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7757 - val_loss: 0.5587 - val_accuracy: 0.7500\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7825 - val_loss: 0.5490 - val_accuracy: 0.7552\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8064 - val_loss: 0.5536 - val_accuracy: 0.7604\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7988 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7748 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7950 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7842 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5550 - val_accuracy: 0.7552\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8063 - val_loss: 0.5658 - val_accuracy: 0.7552\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7877 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8064 - val_loss: 0.5599 - val_accuracy: 0.7500\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8423 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8030 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8048 - val_loss: 0.5400 - val_accuracy: 0.7448\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7811 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7753 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8012 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7864 - val_loss: 0.5621 - val_accuracy: 0.7500\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8215 - val_loss: 0.5554 - val_accuracy: 0.7552\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8073 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8159 - val_loss: 0.5499 - val_accuracy: 0.7552\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7908 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7739 - val_loss: 0.5529 - val_accuracy: 0.7552\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8090 - val_loss: 0.5691 - val_accuracy: 0.7552\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8046 - val_loss: 0.5482 - val_accuracy: 0.7552\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8192 - val_loss: 0.5768 - val_accuracy: 0.7500\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8028 - val_loss: 0.5480 - val_accuracy: 0.7552\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7908 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8061 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8115 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7619 - val_loss: 0.5624 - val_accuracy: 0.7552\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8005 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7855 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7892 - val_loss: 0.5490 - val_accuracy: 0.7552\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8224 - val_loss: 0.5470 - val_accuracy: 0.7552\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7862 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8131 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7799 - val_loss: 0.5522 - val_accuracy: 0.7500\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8139 - val_loss: 0.5646 - val_accuracy: 0.7552\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8056 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7832 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7943 - val_loss: 0.5364 - val_accuracy: 0.7448\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8180 - val_loss: 0.5587 - val_accuracy: 0.7552\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7958 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7997 - val_loss: 0.5526 - val_accuracy: 0.7448\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7919 - val_loss: 0.5514 - val_accuracy: 0.7500\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7948 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8008 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7840 - val_loss: 0.5488 - val_accuracy: 0.7552\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7952 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8087 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8210 - val_loss: 0.5584 - val_accuracy: 0.7552\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7936 - val_loss: 0.5494 - val_accuracy: 0.7552\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8009 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8033 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8068 - val_loss: 0.5468 - val_accuracy: 0.7552\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8055 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7880 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8257 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8004 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7918 - val_loss: 0.5628 - val_accuracy: 0.7552\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8178 - val_loss: 0.5526 - val_accuracy: 0.7448\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8431 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7980 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.7995 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8075 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8106 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8022 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.5514 - val_accuracy: 0.7500\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7941 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7994 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7753 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7935 - val_loss: 0.5542 - val_accuracy: 0.7448\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8095 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8080 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7965 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7878 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8069 - val_loss: 0.5463 - val_accuracy: 0.7552\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8099 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8106 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8037 - val_loss: 0.5533 - val_accuracy: 0.7448\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7997 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7923 - val_loss: 0.5618 - val_accuracy: 0.7552\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8004 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7904 - val_loss: 0.5518 - val_accuracy: 0.7500\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7973 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7913 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8020 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
            "Evaluating on training set...\n",
            "loss=0.4270, accuracy: 80.2083%\n",
            "Evaluating on testing set...\n",
            "loss=0.5519, accuracy: 75.0000%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVdrAf28mjYSEEnrvHQREwIYCoqBi18XuWnBde0GxLLK6u5b1s2MXu6iLurKCUhQEBaWJUkR6CTVSQgLpOd8f596ZOzN3JpOQST2/58lz7z3n3DtnSDjvfct5X1FKYTAYDAZDpMRU9gQMBoPBUL0wgsNgMBgMpcIIDoPBYDCUCiM4DAaDwVAqjOAwGAwGQ6kwgsNgMBgMpcIIDoMhDCLytoj8I8KxW0TktGjPyWCobIzgMBgMBkOpMILDYKgFiEhsZc/BUHMwgsNQ7bFMRONE5FcROSwib4pIUxH5SkSyRGSOiDRwjD9HRFaLyEERmSci3R19/URkuXXfx0BiwGedLSIrrHsXikifCOd4loj8LCKHRGS7iEwM6D/Jet5Bq/8aq72OiPyfiGwVkUwR+d5qO1VE0l3+HU6zzieKyFQReV9EDgHXiMhAEVlkfcYuEXlRROId9/cUkdkisl9E9ojIAyLSTESOiEiaY1x/EckQkbhIvruh5mEEh6GmcCEwAugCjAa+Ah4AGqP/zm8DEJEuwBTgDqtvBvA/EYm3FtH/Au8BDYH/WM/FurcfMBm4EUgDXgWmiUhCBPM7DFwF1AfOAm4SkfOs57a15vuCNae+wArrvqeAY4ETrDndCxRH+G9yLjDV+swPgCLgTqARcDwwHPirNYcUYA7wNdAC6AR8o5TaDcwDLnE890rgI6VUQYTzMNQwjOAw1BReUErtUUrtABYAPymlflZK5QKfA/2scX8CpiulZlsL31NAHfTCPBiIA55VShUopaYCSxyfMRZ4VSn1k1KqSCn1DpBn3RcWpdQ8pdRKpVSxUupXtPA6xeq+DJijlJpife4+pdQKEYkBrgVuV0rtsD5zoVIqL8J/k0VKqf9an5mjlFqmlPpRKVWolNqCFnz2HM4Gdiul/k8plauUylJK/WT1vQNcASAiHuBStHA11FKM4DDUFPY4znNcruta5y2ArXaHUqoY2A60tPp2KP/Mn1sd522Buy1Tz0EROQi0tu4Li4gMEpG5loknE/gL+s0f6xkbXW5rhDaVufVFwvaAOXQRkS9FZLdlvvpXBHMA+ALoISLt0VpdplJqcRnnZKgBGMFhqG3sRAsAAERE0IvmDmAX0NJqs2njON8O/FMpVd/xk6SUmhLB534ITANaK6XqAa8A9udsBzq63PMHkBui7zCQ5PgeHrSZy0lg6uuXgbVAZ6VUKtqU55xDB7eJW1rbJ2it40qMtlHrMYLDUNv4BDhLRIZbzt270eamhcAioBC4TUTiROQCYKDj3teBv1jag4hIsuX0Tongc1OA/UqpXBEZiDZP2XwAnCYil4hIrIikiUhfSxuaDDwtIi1ExCMix1s+lXVAovX5ccBDQEm+lhTgEJAtIt2Amxx9XwLNReQOEUkQkRQRGeTofxe4BjgHIzhqPUZwGGoVSqnf0W/OL6Df6EcDo5VS+UqpfOAC9AK5H+0P+cxx71LgBuBF4ACwwRobCX8FHhGRLGACWoDZz90GnIkWYvvRjvFjrO57gJVoX8t+4AkgRimVaT3zDbS2dBjwi7Jy4R60wMpCC8GPHXPIQpuhRgO7gfXAUEf/D2in/HKllNN8Z6iFiCnkZDAYIkFEvgU+VEq9UdlzMVQuRnAYDIYSEZHjgNloH01WZc/HULkYU5XBYAiLiLyD3uNxhxEaBjAah8FgMBhKidE4DAaDwVAqakXis0aNGql27dpV9jQMBoOhWrFs2bI/lFKB+4Nqh+Bo164dS5curexpGAwGQ7VCRFxDr42pymAwGAylwggOg8FgMJQKIzgMBoPBUCpqhY/DjYKCAtLT08nNza3sqUSVxMREWrVqRVycqbljMBjKh1orONLT00lJSaFdu3b4J0OtOSil2LdvH+np6bRv376yp2MwGGoItdZUlZubS1paWo0VGgAiQlpaWo3XqgwGQ8VSawUHUKOFhk1t+I4Gg6FiqdWCw2CoSqzakcnP2w5U9jQMhhIxgqOSOHjwIC+99FKp7zvzzDM5ePBgFGZkqGzOfuF7zn9pYWVPw2AoESM4KolQgqOwsDDsfTNmzKB+/frRmpYhiqzYfpCvVu5y7ftlu//LwLKt+5m1endFTKtSWJmeyZe/7gzZv3jzfr75bU/I/urIki37mb1mD1+v2sVyF81yzpo9vPjteuzEs0XFiklzN5Cd578mZGTl8fr8TSil+GTJdtbvyWLW6t0s27ofpRRvLNjE3kO5rNqRyf2f/cqOgznl/l1qbVRVZTN+/Hg2btxI3759iYuLIzExkQYNGrB27VrWrVvHeeedx/bt28nNzeX2229n7NixgC99SnZ2NqNGjeKkk05i4cKFtGzZki+++II6depU8jczhOK8ST8AsOXxs4L6zrX6bC58eVHIsTWB0S9+D8DZfVq49l/yas37/he/ssjvOvC7Xf+uTot02aC2NEyOZ/rKXfx75u/8kZ3Hw6N7esfd9+mvfLt2LwPbN+TeT3/1e8asO4fwj+m/8e3avYzq1Ywpi7dz2/DO5f5doio4RGQk8BzgAd5QSj0e0N8GeAeob40Zr5SaYfXdD1wHFAG3KaVmRvLMsvD3/61mzc5DR/sYP3q0SPX7ZQfy+OOPs2rVKlasWMG8efM466yzWLVqlTdsdvLkyTRs2JCcnByOO+44LrzwQtLS0vyesX79eqZMmcLrr7/OJZdcwqeffsoVV1xRrt/DUPFE+ob4y/aDPDXrd37bdYh3rx1EjxappfqcnQdzePP7zTxwZnc8MZUTRPHP6Wu4ZVhnnpr5O/ef2Y2keP8l6elZv3PniC6VFuSRlVvAk1+7z608efHb9d7zT5elc8OQDhy2NI0jeUXevtfnb2LB+gwA9mblBT3H1k6ycgvZmHGYugmxNEtNLPf5Rs1UJSIeYBIwCugBXCoiPQKGPQR8opTqB4wBXrLu7WFd9wRGAi+JiCfCZ1ZLBg4c6LfX4vnnn+eYY45h8ODBbN++nfXr1wfd0759e/r27QvAsccey5YtWypquoYocufHKyIad+6kH1iw/g/+yM73vsGXhrs/+YU3v99cqQ751xds5uYPlvPej1t5b1FwPr3nv93AoZzw5tto8sp3G3nvx628/2P0yqwXFyuemrXOe/3PGb8B2lQF4PGIX19BkW7fmxUcZp+Vq/+t4mNj2HMol2b1EqMidKOpcQwENiilNgGIyEfAucAaxxgF2K9J9QDb6Hku8JFSKg/YLCIbrOcRwTNLTTjNoKJITk72ns+bN485c+awaNEikpKSOPXUU133YiQkJHjPPR4POTnlb8us6eQWFHHzB8t58KzudGhct1T3LlifwazVe3j0vF6u/bszc7nv01/p27o+jVMSXMcAQbb8xZv3e88PHsnn7k9+4YmL+tCobuhn2ItMIFMWb+NQTgE3ntIxqK+gqBiAELdWGAdz8sPOI6+wiLs+Wc2Vg9uy51AeK7YfZPyoboDe5Dpu6q/86bjWzFmzhz6t6nNWn+b6ecWK8Z/pvmPbNnR99uLN+/lseTqPXdDbdYHNKyi2PsfXtmFvFs/OWc/oY1pw43vLePfagQzp4ss8vnTLfqYs3s5TF/cJu2i3Gz+dOnEe7j69S1Dft2v3+ASH9YzAonu7DgavCZ8tTwdg2dYDdGycTHJCdJb4aDrHWwLbHdfpVpuTicAVIpIOzABuLeHeSJ4JgIiMFZGlIrI0IyOjrN8haqSkpJCV5V6FMzMzkwYNGpCUlMTatWv58ccfK3h2tYdFG/fxzdq9/P1/pX/3uPLNxbwX5k30hW/X8926DJ77Zj0P/XdVyHGT5m4I2ffh4m18s3YvbyzYXOr5Adz/2Uoe+2qta5+9plV2FdBca3EOZS3bfiCHz5bv4IZ3l/KX95fxyncbvX2H84uYuiydy1//iVfnb+LmD5d7+3YczOGTpenc8uHPIT/7klcX8dGS7eQUFLn2F1n/Nk5T3j+m/8aXv+7ixveWAXDV5MV+91z2+k98ujw9yKntRk5BEf+Y/ltQ+7VvL/UJDuuzbU3DZqeLSXNfdr73fGPGYRLjPCXOoSxUtnP8UuBtpdT/icjxwHsi4v76VkqUUq8BrwEMGDCgytXHTUtL48QTT6RXr17UqVOHpk2bevtGjhzJK6+8Qvfu3enatSuDBw+uxJlWLbbtO8J5L/1ATn4RE0b34NXvNvLqlQPo2iwF0Hshxr67lHeuHcitU37mxcv606mJT5N4ZvY6DuUW8PDonizfdoA/v70EgOIwi6dSijOenc+WfUe4anBbxo/qxunPzPf2FxWrIB/BzoM5fPDTNtfnjXj6Oxomx/OTQ7MIxZNf/w7A4bxChv/fPJ68qA/Htm3It2uDI45um/Iz367dS2Kch6apCSSXYJMXrDdZtI195Y5MXr1yABv2ZnP15MV89tcTePiL1SzbdoB6deL4z43H898VO1i0cR+vXTUg5HPnrt3Lo9PX8PXtQ4iPjeHLX3dyy4c/M7B9Qz658fig8Tn5etF+7Ku1bMzI5smLjvHrv/BlHaLsXARzC4pIjPOQZy34+Zb2BPpN/q0/H0eMJRkbJMWH/XcAWLhhn9c5ve4fo7jijZ9YvMX3+7F/v1e++RML1v8RdH+fiTNp1yiZabec5J1LcTEcyS/kgpcWsnZ36Uu1P/KlfpmJEeHv/1vNgcP5fv27DwVrHIHCKvNIQak/NxKiKTh2AK0d162sNifXoX0YKKUWiUgi0KiEe0t6ZrXhww8/dG1PSEjgq6++cu2z/RiNGjVi1SrfW+w999xT7vOriny8dBv7rf9A93+2EoDnvlnHS5cfC8DL8zayMzOXB/+7irW7s3jlu408dbFvIXruG+0renh0T55wvIkXFoUWHAVFinV7sgF44/vN3HRqRzb9cdjRX4wnxv/N7sMQQgNg/d7siL6rkyVb9rMx4zDPzF7Pe9cN5IHPgjWYab9oS292XiF/ZAc7TkOhFH429rcXbmbHwRy+XrWbr62Q4IysPFakH4xIM/vbF6tIP5DDzoM5tGuU7PXZLA4hKJ1v+58sTQ8SHDZ1HILjwJF8mterQ15hsevYBz5byX0jtTmrTrz/70YpFWRC+p8jNHjrvsN+QgO04MjJL3IVGgCHcgv5NT2TfMd8CoqL2b0/v0xCw0mxUry9cEtQeySC4/c9R/fZoYimqWoJ0FlE2otIPNrZPS1gzDZgOICIdAcSgQxr3BgRSRCR9kBnYHGEzzRUUYqLFe3GT+fN7yMzu+zLzqPd+Ol+PoBAdR1gz6E8Lnv9R9qNn850a5+Ec5Ea/n/zaDd+Ou3GT/e2Hcot8HtLXbRpH0Of0uN+2PAH7cZPZ1NGNmc+t4DbpoQ2dQAUWiaFIU/O5YHPtTArbex8nCe8A9NefLLzCml//wzXRaMkFm3cR7vx09mVmcOkuRu8i+M1b/lMLe3GT/dG8QRqYX9+a4n3PJRPpfvfvib9gP7upz41j8ycAr/fmZtZbH/Am/TJT37r+mynwD3+sW9pN3669+UhkF2ZudxhCSznXL/8dSddH/qaduOn88TXvheHL1b4BMc9U/1DXAEmfLGa7hO+dv0sJ10e8r3wFRYp9h2OXIADtG4YHE5/OITJa3dm8N/AhjK8lJSFqAkOpVQhcAswE/gNHT21WkQeEZFzrGF3AzeIyC/AFOAapVkNfIJ2en8N3KyUKgr1zGh9B0P5kluoF6R/WVEjxcXKu5DkFhSRV+hvZ15lhUi/vXALSumxThuujVKKhRv3uX7mgcP5bMw4HNS+Lzs/6FmbLS3icUsT+WHjPtbsOuR967YJfMsttATQtv1H+PCnbRQXK3JD2MxDkRAbmS06/cCRUj3XycdLtBY057e9vDZ/k7c98PvszNQL/4EwZo7D+YVBwiMnvyjIV/B7wNt2TkFRiT6V7fsjF7rfrSvZf5lfWEyxNde5azO8Lwwvz9voOj5wM2ZZ+SM7j50uDuxw3HxqJxJi/ZflUFrDEcvE17Fxsmt/NImqj8PakzEjoG2C43wNcGKIe/8J/DOSZxqqB7Yt236T7fDADC4d2JrHLujDsKfmkZQQy5y7TvGOt9X+hNgYRr/4Pat2uO+1ifOEfv/5Zu1e1/ahT80Lec/KHZkA/C2EQ/uEx/3fiPOLiv0Www4PzKB789LtqYiPjYEIXk7/cBGckVLfsvWH+l42trN6Y5i31+veXsKSLQd4bkxfzu2r41PGvrc0aJy9kc+mx4SZpZpzebBm1yE6PDCD58b05VMr6qgiOPuFkkOkT+iYxvYDR7zCsl6dOK46vi2vO4Ihfk3PDPuMsUM6cN+n7pqX079XnpiUI4YKw34bVQrvG+CUxdspLlbszMxlw95sCouK2Xsol4NH8jl4RC+Sh3ILQwoNCDZ1VDRrd2UFbcb6bVfpNpTGuwi/Lk3L7z/99v1H2JgRmRljhfXGPX996Lf5JVv03o9/z/yd7LxCtvxxOKT9v7z59u5TuHtEF1rUC72x7fQeTYPaShKYpWX+uKGlvufM3s285x0bJ/PKlcfy6U0neMO142NjvKa907o35e0/Hxf0jBtObs/Inr7n1A/h/H//ukGuwQjlgREchgrDab5xmkfW7fWp4hOmrWbgv76h7yOzGWfZmkM5VW3K4mwuT66avNgvygpCh5YCjD4mOM3GoA7B+wwuG9im1HMZc1xr1/aTn5xb6oXd3kwWjvQDOfR6eCanhtHgypsOjety6/DOTBgdeu/vvSO7BrUdcvk+x3dIC7vHJhQnd25Em7QkGtUtOWLLyZWD2/k+u2MaqYlxNElJ5IpBbQFo1SDJa0o7pUsjTurUKOgZ943sxh0jdBqR2BihXZq/qcoWKse1b0DD5NLNL1KM4DBUGLYJCPB7+3XuUQgXjVSVyczx9weE21Q3rFvjoLZbh3UKaksKs3lr8YPDufO04I1jzetFJ1fZYxf0ZmA790105UW4BfzJi/oEtY3s1dx17O3DO9OpSUpEn1lQVMysO4ZENkEHr12pw5G/uetU5o8byofXD4rovgHtGnDRsa0ASHT4tW4Z1olZdw6ha7MUCqyXqvjYGGI9Mcy5awhvXj2AOXcNYeYdQ4j1xNCtWSr/+cvxfH2Hvmf2nb7v8OyYvsy959SI/WZlwQiOSqKsadUBnn32WY4cKbuTtLK48+NfvOdO++/UZRVnd64M7J3MNt2apXLJgFbe68S4GNf/5MVhpE+TlESGdWsS1G5H5Vx/UnuObdugrFMOomeLVIZ0CX77LS96NE/1LqhunOEwzTgZ1Su4vV2jJAC6NStZeOzJyqWB9Vbesr5P6CZbIbzJjlDeq45vS/82OjO1HeJbLymONmlJnOCiGbgR54nhgn7aJ3RCJ1/uOU+M0KWpnu/xHXV7zxb1AOjUJIXh3ZvSqUmKd78SwHHtGnp9GJ2tewe1b0hinIf2jaLrMDeCo5KoCYJjw94stu8/QvqBI6xzRH7kFhSxcOMffLcuwxt5U1DkHm9fWp79U1/X9osDFp0F97rbn0f1asbiB4Z7r5OsBeC96wa62qydqSTKynN/6svKiacz844h/PTAcLo3T+Uf5/Xmu3GnsvrvZ7D8byOCImlAO91X/f2MkM+Nd7mnVYMkfv7bCO4/szsf3jCIge2PXkuYe8+p9GlVPygIwelHePDM7vx4/3A/reSH8cOYP24oix8cTjh+nXg6n/31BO45vWvIsSkhtK9n/tSX+eOGsurvZ3jNOjn5+m/tvzefyK8TT/cbvzrg39Pev/PLhNN58bJ+gN5R/+51WoOIi43hlwmns/iB4Tw8uidTxg4OemY4lv9tRFDbCZ0asfSh0xjWLdgPA3B+v5Ysfeg0erWsF/HnAPzy8Om8e93AkgeWA0ZwVBLOtOrjxo3j3//+N8cddxx9+vTh4YcfBuDw4cOcddZZHHPMMfTq1YuPP/6Y559/np07dzJ06FCGDi29c648Oe3p+Zz85FxOemKun43/rk9WcNnrP3H15MW8PE+n0zhwpHwc2I1TEmhimTScpo3BHfwzB7dumOSbzwifSad5vTo0sbKFjujR1Lv4tktLpk1aEoGc0DEtqK00tE1LItYTQ0piHF2bpdDU+uz42BjapulcQknxsa5CoH+bBtRNiHXVLOxnBNIwOY4GyfF4YoSEWI/fprlQXDE4vC/FfnsNFBzO0NuTOjeiWb1EEuJ8Y1rWr0ObtCSapITPzpqaGEdinAdPjIQcGxMj1InzBGlRiXEe2qQlUTchlrFDOgDQt3V9b19qYhw3nqLbh3drQnJCLPGeGK8Pyt6DUy8pzqtxPHFhH5ITPN7vXC8pjiapid5/09TEuLDfx0nD5HiuP6l9UHu4vGMiErY/FPXqxEXVPOWkslOOVA2+Gg+73cPZykyz3jAqdMZ3Z1r1WbNmMXXqVBYvXoxSinPOOYf58+eTkZFBixYtmD5db1zLzMykXr16PP3008ydO5dGjaJnOgjHd+sy6OCiCt/zn1/o1iyFGSt9+x6enr0OpaBfG3ezyQ0nt/cLPbxxSAfuOaMrR/KKSIiLoe8js7zhoaBV+vn3DkUE4mJi6PCAjsxOig/9H+bWYZ3wxAj/nvm7d6Pdpn+diQj0f3Q24FsU1z46km5/8230ql8n9CJx52ldeGbOupD9z43pG9LEEkis9fnJ8R5W/f0MlNKLJcCbVw+g/f3BEehuWkrDZP8Fp7A4WNN78sI+fnUcHj23FzcP7cTxjwVvvJvlsJ0HblJ0RrMFLnTvXOv/5vvbIyMj2kAXjtV/P4NwiV6HdGnMpn+d6f13sxk/shv3ndHNe/37P0ayaschRr/4vZ85sElqIhv/dSaeGPH64Nyi3SKlVQMtiB48qzsPntW9zM+pihiNowowa9YsZs2aRb9+/ejfvz9r165l/fr19O7dm9mzZ3PfffexYMEC6tUrneoaLa6evJgznp0f1D51WXpQwrZiBf83e13IBTZQHW/ZoI73LS8xzhPkZI4RITHOQ0Ksh5gY4cYhHWiSkkB/x5uoXbhm7JAONKobj4h4zSp2RFNMjCAi3tQTdi6ixDiP3+5dt7d6G/utNFRYaKO6CREnmbM1g3tHdkNE/BY/5/ydBM6tZf061AsQdG477esn+cbcZ31e4MLfqG48KYmxNHd8t1O6aM2njaXNOTPuNrCeea31dt0zoDZInXgPjerGe30ENrZ24P/ZCV7tAXyRYvbvLByBQgPw/nvafSLi9VEUBWxGtP8O7KeUtKPfybUn+msWtkZs/51VVk2RaGA0DgirGVQESinuv/9+brzxxqC+5cuXM2PGDB566CGGDx/OhAkTXJ4QfZZu2U9mTgGndtWLh71rNVKWbdVx/20aJrFtv/bPXDqwtZ9JCYLNIYEO4sB14f4zu3P/mfptLrCi2gNnducBq69z0xTXanL28xS+z1lw7zBu/mA501fuItYTw7l9W/ilpLDZbn2Pni3rsdNK/7D5sTMZ+ewCft+TRd1SpLT2xEjYanevXTWA9vdP90vv7dQ4nrr4GFfncqGLbynOuq9+Uhw3naoX/zhPDFseP4urJy/mu3UZPHpuL0b19nfqt0lLCpqjnY7F1piGdm0S8nssfWgEc9fu5c9vL+Hkzo147zr3SKSlD52mv7O1u/3xC4Mjqo4Wr+AIkaPMNmHFlkLjmDC6B5cNasNpT38HQEopTFrVDaNxVBLOtOpnnHEGkydPJjtbq8c7duxg79697Ny5k6SkJK644grGjRvH8uXLg+6tKC56ZRHXvbM0olTRoWhRL9HvbbewSNG1aQpdmtbl8Qt60yw1keHd/e359hvgRce2olWDOqXekV0Sj13Qhw6Nk4MyqNqx9PEe4aZTO9I0NYEnL+pDW4cf5NqT2tM2LYl7z/DtGRARr3koMLne0fL8GO28tWtRODWOU7u6O/HvtRL9tWmYRP829Xniwt4kWIuhW76pSwe2oV1akl/0TjgePLO7qzYUiqry0m1reIUhItfaNEyiXVoSE4+iVs89LnU2agpG46gknGnVR40axWWXXcbxx+tdnnXr1uX9999nw4YNjBs3jpiYGOLi4nj55ZcBGDt2LCNHjqRFixbMnTu3QuftrIUQSJOUBNdyljbvXjeIOz72JQwsUorkhFhm3anTjIxx2fA2dkgHXvh2A60bJPHUfe5ZU4+GET2aMsJl4bPf1GNjdMz8Tw/ot+BLBvhvsPvOJRLLXovKuxzr6GNa+G0edNrfQzlTB3dIC9IAllrJDd1SRo3s1YyRLiGuobhhSAducJiVSiLGW5Qo4luiQqLlxA80Vfn6Pcwrw85wWzB2aJRMn1bBZriaghEclUhgWvXbb7/d77pjx46ccUZwOOatt97KrbfeGtReEYRKDAdw6/DOvL9oq19SthE9mnLl4Lb89+cdtG+UzNOX9OXxr9ailOKe04N39wZy3UntWbcni0sHue+IjhYTz+lJ/IzfOKlz6QMQXrysH6/N30TbhsFRWuVJWW3mdlW40iZiLA8Gtm/I6T2aerWmcNw/qlvYoIejoU6ch4uPbcXFA8r376ptwyTO6t3cawKsqRjBYQhizpo9/P3L1TSqm0BqYhyHciMrBtMkJYGZdw5h1Y5Mzn7he/q3qc/rVsEfez9El6YpTL4mOP9OKOonxfPqlaGLBkWLtmnJZf7cni3q8ZxlVqqK2GkoQplpoklinCdsESgnbuVuywsR4d8Xl78GG+uJYdLl/cv9uVUNIzgMQTzx9Vq278+JKL31yJ7NvGnH7QiUHs1TGTukA1cObhvVeVYlnvnTMRHtmShv/nZ2D45pVbpou0gq4hkM4ajVgsOtElhNoyz1pN0KxDg5qVMjvt+gE+bVifdwVp/mTP91F3Xi9J9TTIx4o5lqC+f3C50uI5pc57K5rCTChRgbDJFQawVHYmIi+/btIy0trcYKD6UU+/btIzEx/M7dQPJLSA8y6fL+vLtwC3GxMVzYvxWxMUKflkJq7mMAACAASURBVPUY7JLh1VA1eW5M36jVajDUfKQsb6TVjQEDBqilS/2LzBQUFJCenk5ubulLcFYnEhMTadWqFXFxJceUL9zwB9e8vcSvbnIgjVMSWPLgaeU5RYPBUEURkWVKqSCnVK3VOOLi4mjfvvRqfk1FKcVvu7PCCg2gUuz4BoOhalFrBYfBH7dcSAaDweBGVL1kIjJSRH4XkQ0iMt6l/xkRWWH9rBORg1b7UEf7ChHJFZHzrL63RWSzo889z7ahRHILilx3gv/bpWiOXemshrqDDAZDKYia4BARDzAJGAX0AC4VEb9aj0qpO5VSfZVSfYEXgM+s9rmO9mHAEWCW49Zxdr9SakW0vkNN5+wXvqfXwzODIq8uHtCa1ER/ZfRvZ+tf3YkRFqwxGAw1l2iaqgYCG5RSmwBE5CPgXGBNiPGXAg+7tF8EfKWUqvzKRTWMDVat7oUb9wX1zb93KAP/+Q35RcU8el4vzu7Tgh7NU2mbFt3KYgaDoeoTTVNVS2C74zrdagtCRNoC7YHgggAwBpgS0PZPEfnVMnW5JukRkbEislRElmZkZJR+9rWIy9/4yXveobEWDPWT4rnuZB08cFbv5nhihM5NU8weAIPBUGWy444Bpiql/JLniEhzoDcw09F8P9ANOA5oCNzn9kCl1GtKqQFKqQGNGx99+c/awuc3neg9v+f0rix76DRvigqDwWCA6AqOHYAzg1grq80NN60C4BLgc6WUN1mSUmqX0uQBb6FNYoZyop4j7bknRkgrQwlLg8FQs4mm4FgCdBaR9iISjxYO0wIHiUg3oAGwyOUZlxIgUCwtBNHbvc8DVpXzvGstduU8g8FgCEfUnONKqUIRuQVtZvIAk5VSq0XkEWCpUsoWImOAj1RAaI+ItENrLN8FPPoDEWmMru64AvhLtL5DbWNE98gL8hgMhtpLVDcAKqVmADMC2iYEXE8Mce8WXJzpSqlh5TfD2sn8dRls3e8LUnv58v5BZUINBoMhFGbneC3kqsmL/a4Hd0irpJkYDIbqSFWJqjJUEN/8tsfv+s7TutDARE0ZDIZSYARHLeO6d/yzBF8xOLjOt8FgMITDCI5aTJemdU24rcFgKDVGcNRiEmJNinSDwVB6jOCoRZz8pH9GlwSTPsRgMJQBs3LUIrbvz/G7Togzv36DwVB6zMpRS3jlu41Bbb+mZ1bCTAwGQ3XHCI5awuNfrQ1qy8oNLuJkMNR6cg9BYX5lz6JKYzYAGgwGw8R6MHAsLH4t9JhhD8G3/4BOI2DDbN3W6TS44lOY+SAsehHOnQRf3Bx875/eh4+vgBsXwKtDoONQuPLz6HyXCsBoHLWYheNN9haDgSJL8w4nNAAWvqCPttAA2DBHHxe9qI/L33O/d8WH+rh5PqBgo1vpoeqDERy1lKuOb0uL+nUqexoGQ+WTnxXZuEjMV8UF7u0eKztDUV5kn1XFMaaqWsgXN59I9+aplT0Ng6FqkBep4MgteUxxCL+hWO/oBTnu/dUMIzhqIce0rl/ZUzAYqg6RCg5UyUOKi8L3H9kf4WdVbYzgqOGs2pHpl8TwTwNahxltqDXsXgV1m+if6opSsGkedDgVRPz7juyHg9ugRV/IOQj7NkJyI9j8HbQeBHtWgyqGhFRYP6v85rSnhLpyOxy54lZ9Ch2HQZ0GkJkOa6ZBbDx4EqBJdziwBeq3gRiP1lSa9IBtP2qtJrmR7juyH5r38T2zIBdWTYXkxtCsD6RGp1yCERw1nLNf+N7vOiXR/MoNwCsnQmI9GL+tsmdSdlb+Bz67Ac55Afpf5d/35gjYtwEmZsKHf4LtP0L3c+C3aRCXDAWHK3auRZZ/ZNcvvrap18IJt8Lp/4Bnepb92RMd+7Fm3AM/Ww76mFiYsK/szw2DcY7XMiJQtg21hdxqvgH00A593LchuM/Ztv1HfTxoCcnyFhrFxSWPCWUOO7SrfOey82ffeSh/SzlgBEcNpqg4WEyc3cdU+jPUEOxIpXDRTs6K1FnlvEjb5GeXPCZiP8pRUlgxUVtRFRwiMlJEfheRDSIy3qX/GRFZYf2sE5GDjr4iR980R3t7EfnJeubHImKqEIWgoCj4TahfmwaVMBODIQp4BUeYaKciR3hs9p7Q446GSIRCqDEqAm2lJIocmkV1Fxwi4gEmAaOAHsClItLDOUYpdadSqq9Sqi/wAvCZozvH7lNKneNofwJ4RinVCTgAXBet71DdyQ8QHPec3qWSZmIwRIFYq5ZMUYi9ExB6X0V5EongCKWVFBw5+s8vync/jyLR1DgGAhuUUpuUUvnAR8C5YcZfCkwJ90AREWAYMNVqegc4rxzmWiMpKPQXHLcM61xJMzEYAti6EJZO1ufL3oHNC4LHFObp9B3r5/jaFr8OWxf5j1vxvk758b874Jle2hlu89755T/3QF4aVPKYUGaydV/D8/2P7vPfOx/+2Rw+vQGyd/v3fXQ5ZO44uue7EM0Qm5bAdsd1OuD6LywibYH2gHMffqKILAUKgceVUv8F0oCDSilbN0u3PsftmWOBsQBt2tTO8qgFRT777h2nGaFhqEK8NUofB1wL/7tNn08McNb/sR5+fh/Wz4Z71um2Gff4xjrNMnbKD4BMx7Kz/SffebPe0GUUrJ/pH90UKclN4PBefR6bCElpPgf90bA/OHN1qbCd/ys/Ce47sCUqWldVcY6PAaYqpZy7Z9oqpQYAlwHPikjH0jxQKfWaUmqAUmpA48aNy3Ou1YZv1vpsujcP7VSJMzEYyoCdnsP2TaiAYI/SmGUueB3+8j0MexBunA/H36LbRzyqhVCn0/T1Je/Bn78Kvr/7aBi3Xo+dmAkP7YG71viPaXtiZHNpYlnsG3bwtSU1ch/b+5LgtrROvvmG4+r/wU0/QIN2kc2rFERTcOwAnLvNWlltbowhwEyllNphHTcB84B+wD6gvojYmlK4Z9Z6HvzctxkpzlNV3hEMhggJjJYKdPyWxhHsCYihsZ3SEvD/IiYWElKC7w8c50agYAtFihXZGJsY2Xi3z3GbYyCRjCkj0VxNlgCdrSioeLRwmBY4SES6AQ2ARY62BiKSYJ03Ak4E1iilFDAXuMgaejXwRRS/Q7XlsRm/VfYUDFWVSPYdVAUCEwIGOqFDaRxxycFtgYLDTg0SqeAoj+gnm5Rm1omEHWZ9sHtzRIIjevnooiY4LD/ELcBM4DfgE6XUahF5REScUVJjgI8soWDTHVgqIr+gBcXjSilbL7wPuEtENqB9Hm9G6ztUZ16dv6myp2CoqqgS8ilVFQKjpfIOBfSHEByxLhH6gW22IIjxBI+Nd1mUy1PYehd055IXQkCE0qrc5hg0pm5pZlUqopp/Qik1A5gR0DYh4Hqiy30Lgd4hnrkJHbFlMARTVAiPNoKzn4EfnoMe58CIRyp7VuF5tLFeBP/yPXw1XucXuvANX/9TXXRKjWEPlf0z5j4G3z2uz+9YGdw/Yxxs+R76XaGLFT3oEgV0YAs8dwxc/w20GgAZ62DScXrezaz/rhvmwPsXwgm36dQX922BJW/C9Lt0/81LoLEjLHxiPffzQB5t4q+BhBvbsAPsWObf5knwvw40VTnfW101jgiEbWC+rFDY+aNSW8Be6324QTs44pIeJKlhcFu9lpFpHPEumlc5YRIX1VBEfP8XTu/RtHInU5HkZwMKZk/Qb6g/PFf1BYf95vzLR7DVyi3mFBzZe2D+v49OcNhCA3SivEDsIkYzH9DH4qLgt/H1VgGjFR9owfGbZXleOdUnOBZN0seFz/ueM8sx7zVfwCnjSjd3O8eUzcAbYfGr+nzIvXBgs85bBdD2JLj4LXhjuC/FCPj2fNh4BYfLYh8bryv2bfsRti3SQihU1tu//qi//4Kn9PVfvtcmtaICqNsUMtZCm8E67LbbaH3sfZH+z9ntbB2mu/wdOOkuvadDBA7t1MkbWw+CnudrX0hKM2g9GNIXQ9czYd1M3xxSWkDWTjj5bhCP/rtv0h0SqqnGYah4iosVHR7wU/I4qzalGbH/g0fqqKxKlMdmsEgIt2HOpjAP4pOC28Dx9q4Cji7kZ2v/gv3dylLIaMQjsHGuLrjU60IY9YRPcAx7UB8btIf5T0L7k3XG39HPw3uOLV4hneOWcLQFiH3sPlr/rPjQEhwh8j416a7LwNqCo1mAoaRJN3089hp97He5Pp50hz426qTn7KTlsfqzbUY94Ttve7w+bv1BH3tfooUbQO+L9XwqACM4ahi5hb43o2tOaMeQLo0Y2rUap84uLfbCVFGL8NHitJ1XVJGfSOL6i/KAJJc2wBMX+r5AgZ2X5b9olyUlRmyCNs3kZ0FMnLuW4E0/EmKOMQFLnQrhHA/13HCmKvs7V+TLitP0Zn9uoHCMIiZGs4ZxJN/3B54Y52FYt6ZIpLbXmoC9cFQXB7AzU6ubsIvGYhSRxuHieLbbvGYfCTi6kJftbyYqS0oMT7zPph8oAGxs57f9/JIWUfvfNVLBUVKBporG7f+0m6M/ShiNo4aR4yc4asF7QeYOSEz1LSxui+LOFVCvNSSnle7Z+zdBait9lBjt1M1YB406B//HLcjV9uqG7fV1/hGfCaFhe9i/GerU11adpj30M/OPaEenTa4jaujIfu2MruOo1pi9Vy+cInrsoZ3Q6jg4uFUn+ouJ047h9CV6TEycdsTmHMQP527n7Az3xXPPSkixfGO5mbBnjS8c9tBO2PitT9Ad2afn5lYUauM3/ju5ty2CzfODx4XDE++z13tCCQ5rT4T94hBKwNiE2scR9FxL6FU1weEqrCvuBdEIjhpGboHvDzwhtuLeQCqNZ3pAw45w23J97WZDf+0UfQxMaRGOnAPwfD9IbelbaEc8op3uI5+AwX/xH//FX3VFtwf3QFwi/DhJRye50bg7ZFj7bC5519e+aa7v/OMrfHZsm6estDGJ9SHXEgYXvK6LGdm0PcnnYA/F9884nhkio8D7F8JVX+jqes/384/4WfGB/rH5+T39MzEzWKDaznabXb/AO6MpFbEJPk2iwJEJ16lVNO+rj60HBfeBrojnpO2J8MsUn0+g4zAdEVa/rf84e0d3i36h51ff2ufcOYLd3OVF46762P5kXQ3wx5d0Ya4KwgiOGsa2/T5zR0JsLdA4wD/XT7jaDKUh54A+Ot/Of/ufPjrLf9r8/rU+5mdrwZGd4Yu1zw/YuJbh2JyZvdf98wOFhpNchwZxYGvAfSUIjdKQsU4LDrcw0fLm8k/hgwv1+fXfam0nLwvqNNSCo/fFsHulL4X6+O3+QqrNILhrrS/U1enjuHudT3uy6XeFTtthjx/8V+14927Os2jZH/76k396kEAatIO7f9e5rCqKFn31901pprWnE+/w106jjBEcNYzr3vEtaolxtUDjCKQsUTtuuDlx8yNwuOcd0m+AeVmWaUoFCw6/Zx5lNbpoFSeqaGwTH0CrY4P77Td/28SU6LIr2llf2yk4AoUGaKHjHC8SLDTsdjsyKhxu90Ybe/7icf+OUcQIjhrEl7/u9LtOTqiFgqO8CtnkudRPsG364RzWth8g75D2u5SUquJoo79qiuCwfQkS4m/W7o809UdMmMgvw1FjBEcNYdnWA9zy4c9+bSmJtfDXW16FbNy0hEgWeVvg5GdbKR9KiIo6Wo3j0M6Sx5SV0kamFReVPQrMDi8NFQ1laxCRCo4KDE2tjdTClaVmcjgveINSUnw1//Vu+UE7/c59EepYJW8L8+Gnl2HQTb5CQKAL1rQ5Hhq0dX8WwOc36Tf0ony9I3fjXOhyuk5T3e4kvegteErvOM5yKTNqp/deNVVHPDU/RjtUm/byhdXOGAfXz9GaR2J9oi44dq04uvvD8fV42FeKWhHT7yr7fOxQ0sAd3t7+0goOo3FEk2q+shhsPDHBoXhxnmq+f+PtM/UxJhYueUefL3lDRzbtWA5r/usbu/ZL/TP6OV9bnQY+JzfALx/6zm3n8+/T9XFiJmSmh46ECmTHUp+T/KDDQb13tU4LkZelQ4Cjbaoqb5Kb6EXcNoHZqTzcSEjVfhw7tceaab4NjXWb6lDhtV/6xhbkaF9AUYH2Rdm/m2Mu0/3124ZOD+PNKWUER1UgIsEhIp+hs9B+pVR55hc2lBcxLhuCPDE1JKoqZ7/v3HZ+Z6a7jz38hz7etkI7XL+8C5ZGmEA5ktrRkT4nL9vycURJ47BDi92S/bUcAOe/Ai8O0Nf9rtCV9Gz6XqHLrdo0aKc1qFPug6EP+D/3jpXaET31Wh1ufMxlcP7LZZtzSdzxa+g+WyMxPo4qQaQry0voSnzrReRxEekaxTkZyoBT42jdsA7DuzWhe/PoFXKpNOKsNBihFlw7dNQ2eZS0EcxJuQqOLC04SspierSmKjckxv9zA6vLBeag8qb5dtFQ7dTc9vOiWBwoLPaLUaQb8YzGEVUiEhxKqTlKqcuB/sAWYI6ILBSRP4uI+Q1VAYqKfW+2fVs34M1rjquZGwDtHcJH/nDvtwWH7WwtTRqG8hIcuYe0cz0hBeLqhB8bLVOVsxaD7R+yiUsKPTYQW2v1CpDoZVwNi5RW46iBf/tViIhtGSKSBlwDXA/8DDyHFiSzozIzQ6kodCTLq+6ujSCc5h5bcBzOcB9rm6rs3EWRlPy0CbffojRk79bHhJSSo3uioXGAfy2GwBKlgXUaIllkbc2tJEEYLWyNw1jKqwSR+jg+B7oC7wGjlVJ28PjHIuKyjdZQ0RQW+RbXw/lVLa/OUbJlgba5JzeBwyF2Wtts/EYf7QU7UlNVuMJApcVO6RFft2Qfx55V4fvLQmI9/13VgZvlAjUQO1VFOKHgNf1VkoHBFn5RLE5kiJxIDcDPK6XmunUopQaU43wMZaSgyPcmFl9TU42UJDQ8CY7U37bgCHibTmqk31qdDvdAuozSi2hxoc5l9J1VD6HPGJ3c77jrdCSRM18TwIVvwqfX+a4TUqDLGdrxnL5E+xIiSQkSE6s/e9hD+jw7Q2tQ8XX1AtrmeN/Y67/VKVcO7YRuZ8Hi17UzHODMp3TIce+L9b9H1m5dda7b2VozKzisj2c/o4XdIEf+rWum60SLNn0v19e9Lyp5/tGg9SAYPgH6Xx35Pee+BM37RG9OtRhREWzYEZGbgQ+UUget6wbApUqpl0q4byTapOUB3lBKPR7Q/www1LpMApoopeqLSF/gZSAVKAL+qZT62LrnbeAUwM5Yd41SKmzw+IABA9TSpTVHMSosKuaYv8/i7+f24qJjW/H07HU8/816b//twztz54guYZ5QTShJC0hI9a9DfdpEmDPRutf685j7L9/Cb7dn7tDJEUPxt33+WVjteYRqdz7b2XbZf/Q+EZtDu+BpK31Fzwtg9Wfun29XvLvoLeh1Qeh5GgxRRkSWuSkHkb6a3mALDQCl1AHghjDjEREPMAkYBfQALhURv/+tSqk7lVJ9lVJ9gRcA+3/SEeAqpVRPYCTwrIg4M3iNs+8rSWjURLYfyOFwfhFPzfwdgElzN3j7ju+Qxs1DQ2Q8rWkEZjx1i/hxS2FRUmRQqNTdpXW4Bn6O02wWaC5y4k3lHaLqnMFQyUQqODziqAZkCYWS9vQPBDYopTYppfKBj4Bzw4y/FJgCoJRap5Rab53vBPYCjcPcW6t4bs46AFo10DbpeI/v1/jEhX1qrqkqkMD6D/EuAsFtsQ8XRRSO0hbECoxA8kQoOOyIsPJKn2IwlDORrjBfox3hw0VkOHqB/7qEe1oCjgoupFttQYhIW6A98K1L30C0kHLmPviniPwqIs+IiGuOAhEZKyJLRWRpRkaICJxqyOG8QpZu1Ttum6YmopTy82/EVueQqsI8vbu4qMA95UcgyQH7E9w0CTfBUVEbIwPDXp0aRzgnr70HobwSNhoM5UykzvH7gBuBm6zr2cAb5TiPMcBUpfyzqolIc3Qk19WOHev3A7vRwuQ1a25BeQqUUq9Z/QwYMKACiwFHl54Pz/SeT1+5i0OTCyh07OGo1oLjhQGQuQ26ngm/zyh5fLshvhoZ4BMkiQ6rZqhsqxVBkKnKEZGUFKYaYYu+sAyo3yYq0zIYjpaIBIe1aL9s/UTKDqC147qV1ebGGOBmZ4OIpALTgQeVUj865mKHAueJyFvAPaWYU7Vm58GcoLYF6/03wsVW5zQjmVbOo0iExhWf6kI8rQZAvVb67Ty1pW6v51hwQ+3juG2Fz4dwZJ/eT9GkR9lqld+8xBfKOm6TjpxKbRlsSotLhLHzdLqUzqfr6KicA5DWUZd3TUjRc0ptAc366CJCBkMVJNJ9HJ2Bx9BObu9uIqVUmLJYLAE6i0h7tMAYg05bEvjsbkADYJGjLR74HHhXKTU1YHxzpdQuy+dyHhCFQPiqyR0flRwHUGuq/nUYpo+Bi2ungPKdofwSzsJBdD66uaS28PkzktOgRxhXXot+vjKkjR2Rb4FmNyM0DFWYSFeZt9DaRiE6fPZd4P1wNyilCoFbgJnAb8AnSqnVIvKIiJzjGDoG+Ej5xwVfAgwBrhGRFdaPVVSYD0RkJbASaAREmM60epNfWMziLftp0zCJxQ8Odx2z+IHhJCfUkoTHVUmzKk0+LIOhBhDpX3wdpdQ3IiJKqa3ARBFZBkwId5NSagYwI6BtQsD1RJf73ieEYFJKDYtwzjUKe59G/aQ4mqQk0qtlKqt2+PYwnNW7OU1SE0PdbogmJqGeoZYRqeDIE5EYdHbcW9Cmp0rKdlY72fSHriy3/7AO0fzi5pO48+MVTPtFV4D7v0uOqbS5BZF7CDbPhy4j4ZcpOoJIYqBxV8jNhDaD4eB2WPa29k8c2lm6nFJVDZNQz1DLiFRw3I7e2X0b8CjaXFWKvf+Go6Vhst42c8dp2i7uiRG6NU9h2i+6v0r5Nqbdqoss9b8alr8T3D8xE146vvySCoajiWPPac/zy/aMvlf4R2/ZnHKf/650g6GWUKLgsDb7/UkpdQ+QDfw56rMyBJFbUEzzeolcdGwrb1unxj6lT0q7OS2a2BXh9v4Weoyb0LjgDfjsel3K9dZluk0pXYNBYrSjWxWX7g2/41CYsP/otILzJumfQIY+4Ct8ZDDUIkoUHEqpIhE5qSImYwjNrsycIB9GpyZV1FoYW8adz0nWbmpnKnIR/x3XZdmXYUxJBkO5Eqmp6mcRmQb8B/AWEFBKhcjSZihvNuzN5sRO/iGbbRomhRhdydgLf2kFR7hKdAaDocoQqeBIBPYBzogmhS8poSGKFBUr9hzKo1UDf0ER64nh+pPa07tVOdaSKA9sjSM/u3T3VVaRIIPBUCoi3Tlu/BqVSFZuAQD16gSHfT50dpj04OVNQS7873ZdJ6K+lRRgwxyY+RAU5kDdprB/s69uhu3rCCR9mXu7HVkVKjutwWCoEkS6c/wttIbhh1Lq2nKfkSGIQzk6NYab4KhQNsyGXz/SmsQYq4jR+xf6+g9siew5b40KbvvTB9C4uy4mNHDsUU/VYDBEj0hf7b50nCcC5wM7y386Bjcyc7TGkZpYyW/i9ub+CIp/BRGXrCvOARTr70OfMXDBq/7jRpnwVoOhqhOpqepT57WITAEiqIFpKA8OhTFVVRti432CQxWHH2swGKo0Zd011hloUuIoQ7lwyNY4KltwlBQl5UxnHkhlpjc3GAzlSqQ+jiz8fRy70XUwDBXA3ixd0KdSNY6CHP/63m4kpkLuwfBjDAZDtSdSU1UJRZoN0WLnwRwenrYaqCSNY+9aeGmQPq/bzNf++nBf9JRNww7ukVQN2kGeS2hug3blNUuDwVCBRGSqEpHzRaSe47q+iJwXvWkZbDZm+Bbc5PhKMPdsWeA7z96tj6oIdiwNFhIXToZzX4KrpsFgR12u6+YEpx4f/jAMqTU1uAyGGkWkPo6HlVKZ9oVS6iDwcHSmZHBy5ZuLvedVJh9V/uHgtnYn6yJG/S6HDqdAk+66/ZjLoG5j7Ry3adobTr7LpCM3GKopkQoOt3Fml1YF8vpVAyp7Cj7cfB2BQs2+to+eBF9fnKkbYjBUZyIVHEtF5GkR6Wj9PA2E2P5riAZ9KiutiNueDTd/RUnEOgRHrBEcBkN1JlKt4Vbgb8DH6Oiq2cDNYe8wlCt1K7Ik7O6VsHOF3m/h9HHYHP6j9M90Zrw1OakMhmpNpFFVh4HxUZ6LIQx14irQMf6fa2DfhtD9eZnBbW1P9L9u0U8fu5yhj52Gw87l1tgTjnqKBoOh8oh0H8ds4GLLKY6INAA+UkqdUcJ9I4HnAA/whlLq8YD+Z9DVBEFXGGyilKpv9V0NPGT1/UMp9Y7VfizwNlAHXc/8dqXKkgOjetCobgKndGlMTEwFOsYDNYq2J8KYDyFnP6S2hNWfw+c3+vovfht6BATZNe0JD+7x+TOGPggDbwQUJDeO5uwNBkOUidT+0cgWGgBKqQMiEnbnuFU5cBIwAkgHlojINKXUGsdz7nSMvxXoZ503REdtDUCbxpZZ9x4AXgZuAH5CC46RwFcRfo9qR1FxMckJFahtKBUcNVWvNdSpr38AGnb072/YIdg5Dv5OcBEdXWUwGKo9kTrHi0WkjX0hIu1wyZYbwEBgg1Jqk1IqH/gIODfM+EuBKdb5GcBspdR+S1jMBkaKSHMgVSn1o6VlvAvU6P0kBUWK2JgKrCdemOdLQmjjDKUFSAjYDxpfRSsRGgyGqBCpxvEg8L2IfIcuz3YyUFLu65bAdsd1OjDIbaCItAXaA9+Gubel9ZPu0u72zLH2HNu0aeM2pFpQUFRMXGwFmqnyXGqBO0NpARICBIW3cp/BYKgNRPQqq5T6Gm02+h2tFdwN5JTjPMYAU5VSReX1QKXUa0qpAUqpAY0bV18TSWGxIi5aGsfhfTBpsPZZ5GZqp/hHlwaPiw0QHHEBJWsDNRCDwVCjidQ5fj1wO9AKWAEMBhbhX0o2kB1Aa8d1K6vNjTH4h/fuAE4NuHee1d4qwmdWe5RSFBUrYj1R0ji+Hg8Zv2mBMegmPqDBGgAAFKpJREFULUDc8ASYqhLrQ8dhsPFb6HZ2sGAxGAw1mkhNVbcDxwE/KqWGikg34F8l3LME6Cwi7dGL+xjgssBB1rMaoAWRzUzgX1b0FsDpwP1Kqf0ickhEBqOd41cBL0T4HaodBUXajRTniZLG4fRlFBwJPS5QMMTEwJUhhIzBYKjxRCo4cpVSuSKCiCQopdaKSNdwNyilCkXkFrQQ8ACTlVKrReQRYKlSapo1dAw6tFc57t0vIo+ihQ/AI0qp/db5X/GF435FDY6oKizWBY9ioxWKG+i7CDnO5JQyGAw+IhUc6SJSH/gvMFtEDgBbS7pJKTUDHTLrbJsQcD0xxL2Tgcku7UuBXhHOu1pjaxyx0dI4AqOlQhGpgDEYDLWCSHeOn2+dThSRuUA94OuozcoA6IgqgLho+TicAiFcOVfjwzAYDA5KnQBJKfVdNCZi8Ke4WDHgH3MAorOP4/E2OpLK5uf3Qo81piqDweDApEavouQX+TSA1DpR+DU5hUa/K6BOQ9i7Bhp3g7SO8OWdvv6O4YLnDAZDbcMIjipKgUNwNEyK0BdRVs6dFNzmFBz1Wgf3GwyGWksF5rIwlIaiYl9Gl4Z1y1lwFBWUPMZJVak8aDAYqgRGcFRR7IgqiILG4ZZWxGAwGCLEmKqqKLbGcdmgNjRJLaFiXnExHNwKKc1gxzKQGB0l1aQHJDX0H3twG2Ssi9KsDQZDbcAIjiqK7ePo27p+yYMXPgdzJkKvC2HVp772VgPh+tm+a6Xg2d6RTaBeG8jcFvmEDQZDrcEIjiqKrXFEtIdjs1XeNX2pf3v6Yv/rYpcckrf97P7Mvy6Cwxm+GhwGg8FgYQRHFcVON+KJaA+H5Q8pyXdRXBjcltLcfWxC3eD06QaDwYBxjldZvAkOS5OnKmd/+H63rPWBmW8NBoOhBIzgqKLYpipPeSY4dNM4YiqwLK3BYKgRGFNVFcWXpyqMbC8qhAVPwc4VkT3UzcdhMBgMpcRoHFUUW+MIW8Rp72qY95jPtxFYwjUpzf86MJFhWuejnKXBYKiNGI2jivLWD1uAEkxVBbn6eNlH0Ok0fb7rF3h1iD6PCUhO6DRVxafArQFRWAaDwRABRuOogiilmL5yF1CSqSpPH53p0Z3Cwu63cZqqIq3FYTAYDAEYwVEFyc7zaQZhNY6ifH101suIcSiRhfn+450ah4mmMhgMZcQIjirIgcO+JISecAkGbcHgrJfhcQiOQI3DGY5rBIfBYCgjURUcIjJSRH4XkQ0iMj7EmEtEZI2IrBaRD622oSKywvGTKyLnWX1vi8hmR1/faH6HymDfYd+C79Q+AFg7A57vDxPrwUeX6jZPCI2juBD+c431oL3w8om+vuRG5Ttpg8FQa4iac1xEPMAkYASQDiwRkWlKqTWOMZ2B+4ETlVIHRKQJgFJqLtDXGtMQ2ADMcjx+nFJqarTmXtls238EgBE9mjKofUCSwi3fw/6N/m2xIXwcAKs/h4vfhhUfQoF+Lk17wSVhKv4ZDAZDGKKpcQwENiilNiml8oGPgHMDxtwATFJKHQBQSu11ec5FwFdKqSNRnGuVYuPebGIEXrysH7GBzvFA8xP4m51iXN4Figp8/hCAU+6Fei3LZ7IGg6HWEU3B0RLY7rhOt9qcdAG6iMgPIvKjiIx0ec4YYEpA2z9F5FcReUZEElzuQUTGishSEVmakZFR1u9QKezNyqNR3QQSYl12dRe6CA6nxuFxERx5Wf6CQ8xucYPBUHYq2zkeC3QGTgUuBV4XEW86VhFpDvQGZjruuR/oBhwHNATuc3uwUuo1pdQApdSAxo0bR2f2UWLf4XwaJodwXhflB7f5aRxxwf352f4Cx00rMRgMhgiJpuDYATiLVbey2pykA9OUUgVKqc3AOrQgsbkE+Fwp5Q0zUkrtUpo84C20SaxGseWPw6EFh5vGUZKpas9q2LfBMcZoHAaDoexEU3AsATqLSHsRiUebnKYFjPkvWttARBqhTVebHP2XEmCmsrQQRESA84BV0Zh8ZbHjYA7r92aTkhhCK3CrF+5nqrI0Dme69Clj4PcZvmupbEXTYDBUZ6Jms1BKFYrILWgzkweYrJRaLSKPAEuVUtOsvtNFZA1QhI6W2gcgIu3QGst3AY/+QEQaAwKsAP4Sre9Q0WTmFPD6fC03L+zfyn1QUV5wdT6nBhHjgZsWQv22sHUhZO3S5q0Z9zjGGFOVwWAoO1FdQZRSM4AZAW0THOcKuMv6Cbx3C8HOdJRSw8p9olWEWz5czoL1fwBwQqcQ+ywK86BeK0hMhT0hlK2mPfWxy+n6mJ3hLziMxmEwGI4Cs4JUIWyhESNQNyGUqSq/9HmmAse7hfQaDAZDhBjBUYWw64u3bFAn9KDCPL1TXKnIH+wJiFguyCnD7AwGg0FjBEcVItatvnjWHlg6WS/2O3+GXSv8c1NFQmBeqvxas5fSYDBEASM4qhD1k7RA+MspHX2N8/4FX94JG+fC1w/otrROMPgmfd60d8kPDhRIrQaUw2wNBkNtxYTXVCFiRLjo2FZcPqitrzFrjz7mHoScA9BhKJw2EUSg/5Wl/5CJmeUxVYPBUIsxGkcV4kh+IUnxITbn5WXpHeApzbXQMBgMhkrCCI4qwvJtBzhwpIA6cWEER14WJKRU7MQMBoMhACM4qggXvLQQgOTAMFw7dDbvkCU46lbwzAwGg8EfIziqGN79G0rBtNsgfam+/uVjXcHPaBwGg6GSMc7xKkBhUbH33Ou+KMyF5e9Ag3aQWB/qt4Em3aBjGTfOj3oSUpod9VwNBoPBCI5K5LYpP7NqRyaFxb7NfIm2j8POgjvwRjj+r0f/YYNuPPpnGAwGA0ZwVBpZuQVM+2UnvVqm0r5RXXq1TCUlIY4L+lvpuey6G6VNL2IwGAxRxgiOMNz0/jJv/qjypthKGXLbsM6c3tPFhGRrHIHpQgwGg6GSMYIjDEO6NKZF/TB5o46SpHgPQ7q4VCcsLoac/fo81ggOg8FQtTCCIwyXDmxTOR/8/gWwaa4+D8wzZTAYDJWMCcetimSs9Z0bwWEwGKoYRnBURfKyfOfGOW4wGKoYRnBUNYqLdU4qGwmRgsRgMBgqiagKDhEZKSK/i8gGERkfYswlIrJGRFaLyIeO9iIRWWH9THO0txeRn6xnfiwiNeuV3Ck0wBeWazAYDFWEqAkOEfEAk4BRQA/gUhHpETCmM3A/cKJSqidwh6M7RynV1/o5x9H+BPCMUqoTcAC4LlrfoVJwmqnACA6DwVDliKbGMRDYoJTapJTKBz4Czg0YcwMwSSl1AEAptTfcA0VEgGHAVKvpHeC8cp11ZWMLji4j9bFRl8qbi8FgMLgQTcHREtjuuE632px0AbqIyA8i8qOIjHT0JYrIUqvdFg5pwEGlVGGYZ1ZvbFPVgOvg/h3QuGvlzsdgMBgCqOx9HLFAZ+BUoBUwX0R6K6UOAm2VUjtEpAPwrYisBCIuXyciY4GxAG3aVNJ+jLKQd0gfE1JMCnWDwVAliabGsQNo7bhuZbU5SQemKaUKlFKbgXVoQYJSaod13ATMA/oB+4D6IhIb5plY972mlBqglBrQ+P/bu/cYOasyjuPfX3dpuQotFFJaAlQWBS+0uCKlaIhARWIEkypFLgWJxAQioEFokKBNSDQhVkwabCN3KiDIpanRKqXBYAS6lYLtltJtq7II9pJyqYZtu3384z1ThqW3dzuz7zuzv08y2XnPe2b2PHt28+w575n3jNzBp7PLqjJV5dunm1lJ1TNxLALa0iqoocAUYG6fOk+QjTaQdBjZ1NVqScMlDasqnwh0RkQAC4HJ6fVTgSfrGMPA60lTVU4cZlZSdUsc6TrE1cB8YDnwm4hYJmm6pMoqqfnABkmdZAnh+ojYAJwAdEh6KZX/JCI602tuAL4nqYvsmsed9YphwEXAwluz504cZlZSiojd12pw7e3t0dHRUXQzdm/TWritDTQEbl4PQ/zhPzMrjqTFEdHet9yfHC+TyvWNr81y0jCz0nLiKJPKiqqhXk1lZuXlxFEmXlFlZg3AiaNMvKLKzBqAE0eZLJmTfXXiMLMSc+Iok23pTiojxhbbDjOzXXDiKJOtPTDmsyAV3RIzs51y4iiT3i3QMqzoVpiZ7ZITR5n09kDLPkW3wsxsl5w4ymRrD7R6xGFm5ebEUSa9m6GluXbCNbPm48RRJh5xmFkDcOIok97NvjhuZqXnxFEmW3ug1VNVZlZuThxl4uW4ZtYAit5zvNxefADWv1rf77HfcDjtGhgyJFuO6xGHmZWcE8eurPg9dD1Vv/ff1gvbtkDbJBh5Amx9D1r3q9/3MzOrASeOXZkyp77vv2oh3H8+vPcObK7cGdd7cZhZufkaR5Eqd8HtebcqcfjOuGZWbnVNHJLOkbRCUpekG3dS5xuSOiUtk/TrVDZO0l9T2cuSLqiqf4+kNZKWpMe4esZQV9sTxzvexMnMGkbdpqoktQAzgbOBbmCRpLkR0VlVpw2YBkyMiI2SDk+n/gdcGhErJR0JLJY0PyLeSuevj4hH69X2AVPZInbzpvcTx1AnDjMrt3pe4zgF6IqI1QCSHgLOAzqr6nwbmBkRGwEiYm36un0pU0T8W9JaYCTwFs2kMrp4+lZo3TeV+RqHmZVbPaeqRgOvVR13p7JqxwPHS/qLpOckndP3TSSdAgwFVlUV35qmsGZI2uEHHyRdKalDUse6dev2LpJ6GXYQnH4dHD0BRo+H8RfDqMadeTOzwaHoVVWtQBtwBjAG+LOkT1WmpCSNAu4HpkbEtvSaacCbZMlkNnADML3vG0fE7HSe9vb2qG8Y/STBWT8quhVmZrnUc8TxOnBU1fGYVFatG5gbEVsiYg3wKlkiQdJHgN8BN0XEc5UXRMQbkekB7iabEjMzswFSz8SxCGiTdKykocAUYG6fOk+QjTaQdBjZ1NXqVP9x4L6+F8HTKARJAs4HltYxBjMz66NuU1URsVXS1cB8oAW4KyKWSZoOdETE3HRukqROoJdstdQGSRcDXwAOlXRZesvLImIJMEfSSEDAEuA79YrBzMw+TBHlnP6vpfb29ujo6Ci6GWZmDUXS4oho71vuT46bmVkuThxmZpaLE4eZmeXixGFmZrkMiovjktYB/+znyw8D1tewOY3AMQ8Ojnlw2JuYj46IkX0LB0Xi2BuSOna0qqCZOebBwTEPDvWI2VNVZmaWixOHmZnl4sSxe7OLbkABHPPg4JgHh5rH7GscZmaWi0ccZmaWixOHmZnl4sSxC5LOkbRCUpekG4tuTy1IOkrSQkmdkpZJuiaVj5D0J0kr09fhqVySfpF+Bi9LOrnYCPpPUoukFyXNS8fHSno+xfZwup0/koal4650/pgi291fkg6R9KikVyQtlzSh2ftZ0nXp93qppAcl7dts/SzpLklrJS2tKsvdr5KmpvorJU3N0wYnjp2Q1ALMBL4MnAhcKOnEYltVE1uB70fEicCpwFUprhuBBRHRBixIx5DF35YeVwJ3DHyTa+YaYHnV8U+BGRFxHLARuCKVXwFsTOUzUr1GdDvwh4j4OHASWexN28+SRgPfBdoj4pNk2zlMofn6+R6g7zbbufpV0gjgFuBzZJvh3VJJNnskIvzYwQOYAMyvOp4GTCu6XXWI80ngbGAFMCqVjQJWpOezgAur6m+v10gPsh0oFwBfBOaR7eeyHmjt299k+8RMSM9bUz0VHUPOeA8G1vRtdzP3MzAaeA0YkfptHvClZuxn4BhgaX/7FbgQmFVV/oF6u3t4xLFzlV/Ciu5U1jTS0Hw88DxwRES8kU69CRyRnjfLz+HnwA+Ayt71hwJvRcTWdFwd1/aY0/m3U/1GciywDrg7Tc/9StIBNHE/R8TrwG3Av4A3yPptMc3dzxV5+3Wv+tuJY5CSdCDwW+DaiHin+lxk/4I0zTptSV8B1kbE4qLbMoBagZOBOyJiPPBf3p++AJqyn4cD55ElzSOBA/jwlE7TG4h+deLYudeBo6qOx6SyhidpH7KkMSciHkvF/6naz30UsDaVN8PPYSLwVUn/AB4im666HThEUmX75Oq4tseczh8MbBjIBtdAN9AdEc+n40fJEkkz9/NZwJqIWBcRW4DHyPq+mfu5Im+/7lV/O3Hs3CKgLa3IGEp2kW1uwW3aa5IE3Aksj4ifVZ2aC1RWVkwlu/ZRKb80rc44FXi7akjcECJiWkSMiYhjyPrx6Yi4CFgITE7V+sZc+VlMTvUb6j/ziHgTeE3Sx1LRmUAnTdzPZFNUp0raP/2eV2Ju2n6ukrdf5wOTJA1PI7VJqWzPFH2Rp8wP4FzgVWAVcFPR7alRTKeTDWNfBpakx7lkc7sLgJXAU8CIVF9kq8tWAX8nW7FSeBx7Ef8ZwLz0fCzwAtAFPAIMS+X7puOudH5s0e3uZ6zjgI7U108Aw5u9n4EfA68AS4H7gWHN1s/Ag2TXcLaQjSyv6E+/At9KsXcBl+dpg285YmZmuXiqyszMcnHiMDOzXJw4zMwsFycOMzPLxYnDzMxyceIwKzlJZ1Tu6GtWBk4cZmaWixOHWY1IuljSC5KWSJqV9v/YJGlG2iNigaSRqe44Sc+lPRIer9o/4ThJT0l6SdLfJH00vf2BVXtrzEmfjDYrhBOHWQ1IOgG4AJgYEeOAXuAishvtdUTEJ4BnyPZAALgPuCEiPk32id5K+RxgZkScBJxG9glhyO5ifC3Z3jBjye7BZFaI1t1XMbM9cCbwGWBRGgzsR3ajuW3Aw6nOA8Bjkg4GDomIZ1L5vcAjkg4CRkfE4wAR8R5Aer8XIqI7HS8h24/h2fqHZfZhThxmtSHg3oiY9oFC6eY+9fp7j5+eque9+G/XCuSpKrPaWABMlnQ4bN8D+miyv7HKnVm/CTwbEW8DGyV9PpVfAjwTEe8C3ZLOT+8xTNL+AxqF2R7wfy1mNRARnZJ+CPxR0hCyO5deRbaB0inp3Fqy6yCQ3fr6lykxrAYuT+WXALMkTU/v8fUBDMNsj/juuGZ1JGlTRBxYdDvMaslTVWZmlotHHGZmlotHHGZmlosTh5mZ5eLEYWZmuThxmJlZLk4cZmaWy/8Brq+Kj+JqUPAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum Loss : 0.6824\n",
            "\n",
            "Minimum Loss : 0.4282\n",
            "\n",
            "Loss difference : 0.2542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_h1JvAvBO4G",
        "outputId": "a6964485-f82b-4b75-c88a-b6360b637a4c"
      },
      "source": [
        "# Hyperparameters\r\n",
        "training_epochs2 = 1000 # Total number of training epochs\r\n",
        "learning_rate2 = 0.01 # The learning rate\r\n",
        "momentum = 0.9\r\n",
        "\r\n",
        "# create a model\r\n",
        "def create_model2():\r\n",
        "    model2 = tf.keras.Sequential()\r\n",
        "    # Hidden layer 1\r\n",
        "    model2.add(tf.keras.layers.Dense(30, input_dim=8,activation='relu'))\r\n",
        "    model2.add(Dropout(0.5))\r\n",
        "    # Hidden layer 2\r\n",
        "    model2.add(tf.keras.layers.Dense(12, input_dim=30,activation='relu'))\r\n",
        "    model2.add(Dropout(0.5))\r\n",
        "    # Output layer\r\n",
        "    model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    # Compile a model\r\n",
        "    model2.compile(loss='binary_crossentropy', \r\n",
        "                  optimizer='adam', #tf.keras.optimizers.SGD(learning_rate2, momentum),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    return model2\r\n",
        "\r\n",
        "model2 = create_model2()\r\n",
        "model2.summary()\r\n",
        "\r\n",
        "\r\n",
        "my_callbacks = [\r\n",
        "    EarlyStopping(monitor='accuracy',patience=100),\r\n",
        "\r\n",
        "]\r\n",
        "\r\n",
        "results2 = model2.fit(\r\n",
        "    x_tr, y_tr,\r\n",
        "    epochs= training_epochs2,\r\n",
        "    batch_size=5,\r\n",
        "    validation_data = (x_ts, y_ts),\r\n",
        "    callbacks=my_callbacks,\r\n",
        "    verbose = 1\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"Evaluating on training set...\")\r\n",
        "(loss, accuracy) = model2.evaluate(x_tr, y_tr, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "print(\"Evaluating on testing set...\")\r\n",
        "(loss, accuracy) = model2.evaluate(x_ts, y_ts, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(results2.history['accuracy'])\r\n",
        "plt.plot(results2.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(results2.history['loss'])\r\n",
        "plt.plot(results2.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "max_loss2 = np.max(results2.history['loss'])\r\n",
        "min_loss2 = np.min(results2.history['loss'])\r\n",
        "print(\"Maximum Loss : {:.4f}\".format(max_loss2))\r\n",
        "print(\"\")\r\n",
        "print(\"Minimum Loss : {:.4f}\".format(min_loss2))\r\n",
        "print(\"\")\r\n",
        "print(\"Loss difference : {:.4f}\".format((max_loss2 - min_loss2)))\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 30)                270       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 12)                372       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 655\n",
            "Trainable params: 655\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "116/116 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.5669 - val_loss: 0.6659 - val_accuracy: 0.6354\n",
            "Epoch 2/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6605 - val_loss: 0.6580 - val_accuracy: 0.6354\n",
            "Epoch 3/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6818 - val_loss: 0.6496 - val_accuracy: 0.6354\n",
            "Epoch 4/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6572 - val_loss: 0.6394 - val_accuracy: 0.6406\n",
            "Epoch 5/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6942 - val_loss: 0.6307 - val_accuracy: 0.6406\n",
            "Epoch 6/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6925 - val_loss: 0.6232 - val_accuracy: 0.6719\n",
            "Epoch 7/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6977 - val_loss: 0.6159 - val_accuracy: 0.6719\n",
            "Epoch 8/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6672 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
            "Epoch 9/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7051 - val_loss: 0.5941 - val_accuracy: 0.6927\n",
            "Epoch 10/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6858 - val_loss: 0.5857 - val_accuracy: 0.6979\n",
            "Epoch 11/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6893 - val_loss: 0.5808 - val_accuracy: 0.6771\n",
            "Epoch 12/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7021 - val_loss: 0.5796 - val_accuracy: 0.6927\n",
            "Epoch 13/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6759 - val_loss: 0.5707 - val_accuracy: 0.6875\n",
            "Epoch 14/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7414 - val_loss: 0.5900 - val_accuracy: 0.6927\n",
            "Epoch 15/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7050 - val_loss: 0.5599 - val_accuracy: 0.7135\n",
            "Epoch 16/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7148 - val_loss: 0.5561 - val_accuracy: 0.7135\n",
            "Epoch 17/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7355 - val_loss: 0.5538 - val_accuracy: 0.6875\n",
            "Epoch 18/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7047 - val_loss: 0.5511 - val_accuracy: 0.7031\n",
            "Epoch 19/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7440 - val_loss: 0.5700 - val_accuracy: 0.7031\n",
            "Epoch 20/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6954 - val_loss: 0.5488 - val_accuracy: 0.7031\n",
            "Epoch 21/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7167 - val_loss: 0.5472 - val_accuracy: 0.6979\n",
            "Epoch 22/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7274 - val_loss: 0.5482 - val_accuracy: 0.6927\n",
            "Epoch 23/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7009 - val_loss: 0.5471 - val_accuracy: 0.7083\n",
            "Epoch 24/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7445 - val_loss: 0.5425 - val_accuracy: 0.6875\n",
            "Epoch 25/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7362 - val_loss: 0.5423 - val_accuracy: 0.7031\n",
            "Epoch 26/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7752 - val_loss: 0.5308 - val_accuracy: 0.7083\n",
            "Epoch 27/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7353 - val_loss: 0.5409 - val_accuracy: 0.7083\n",
            "Epoch 28/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.6955 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
            "Epoch 29/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7133 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
            "Epoch 30/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7346 - val_loss: 0.5326 - val_accuracy: 0.6979\n",
            "Epoch 31/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7441 - val_loss: 0.5238 - val_accuracy: 0.7031\n",
            "Epoch 32/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7531 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 33/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7599 - val_loss: 0.5259 - val_accuracy: 0.7292\n",
            "Epoch 34/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7281 - val_loss: 0.5296 - val_accuracy: 0.7083\n",
            "Epoch 35/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7405 - val_loss: 0.5433 - val_accuracy: 0.7031\n",
            "Epoch 36/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7544 - val_loss: 0.5244 - val_accuracy: 0.7083\n",
            "Epoch 37/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7271 - val_loss: 0.5445 - val_accuracy: 0.7135\n",
            "Epoch 38/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7233 - val_loss: 0.5223 - val_accuracy: 0.7031\n",
            "Epoch 39/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7589 - val_loss: 0.5475 - val_accuracy: 0.7135\n",
            "Epoch 40/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7745 - val_loss: 0.5531 - val_accuracy: 0.7292\n",
            "Epoch 41/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7448 - val_loss: 0.5439 - val_accuracy: 0.7031\n",
            "Epoch 42/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7892 - val_loss: 0.5476 - val_accuracy: 0.7188\n",
            "Epoch 43/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7837 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
            "Epoch 44/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7588 - val_loss: 0.5261 - val_accuracy: 0.7031\n",
            "Epoch 45/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7472 - val_loss: 0.5404 - val_accuracy: 0.7135\n",
            "Epoch 46/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7871 - val_loss: 0.5166 - val_accuracy: 0.7083\n",
            "Epoch 47/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7979 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
            "Epoch 48/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7905 - val_loss: 0.5428 - val_accuracy: 0.7135\n",
            "Epoch 49/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7493 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
            "Epoch 50/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7608 - val_loss: 0.5103 - val_accuracy: 0.7396\n",
            "Epoch 51/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7876 - val_loss: 0.5254 - val_accuracy: 0.7135\n",
            "Epoch 52/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7576 - val_loss: 0.5236 - val_accuracy: 0.7031\n",
            "Epoch 53/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7551 - val_loss: 0.5231 - val_accuracy: 0.7188\n",
            "Epoch 54/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7662 - val_loss: 0.5335 - val_accuracy: 0.6979\n",
            "Epoch 55/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7552 - val_loss: 0.5319 - val_accuracy: 0.6979\n",
            "Epoch 56/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7822 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
            "Epoch 57/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7643 - val_loss: 0.5380 - val_accuracy: 0.7031\n",
            "Epoch 58/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7999 - val_loss: 0.5207 - val_accuracy: 0.7292\n",
            "Epoch 59/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7805 - val_loss: 0.5343 - val_accuracy: 0.7031\n",
            "Epoch 60/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7435 - val_loss: 0.5271 - val_accuracy: 0.7083\n",
            "Epoch 61/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7525 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
            "Epoch 62/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7919 - val_loss: 0.5388 - val_accuracy: 0.7083\n",
            "Epoch 63/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7460 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
            "Epoch 64/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7742 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
            "Epoch 65/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7977 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 66/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7799 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 67/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7768 - val_loss: 0.5437 - val_accuracy: 0.7135\n",
            "Epoch 68/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7493 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
            "Epoch 69/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8112 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 70/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7740 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 71/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7942 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 72/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7730 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 73/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7925 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 74/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7929 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
            "Epoch 75/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7905 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
            "Epoch 76/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7898 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 77/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7394 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 78/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7545 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 79/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8002 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
            "Epoch 80/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7540 - val_loss: 0.5012 - val_accuracy: 0.7396\n",
            "Epoch 81/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7574 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
            "Epoch 82/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7769 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
            "Epoch 83/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7460 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
            "Epoch 84/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7959 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 85/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8029 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
            "Epoch 86/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8027 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
            "Epoch 87/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8019 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 88/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7720 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 89/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7864 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
            "Epoch 90/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7599 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 91/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7779 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
            "Epoch 92/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8247 - val_loss: 0.5476 - val_accuracy: 0.7135\n",
            "Epoch 93/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7802 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
            "Epoch 94/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8155 - val_loss: 0.5524 - val_accuracy: 0.7135\n",
            "Epoch 95/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7715 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
            "Epoch 96/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7639 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
            "Epoch 97/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7823 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
            "Epoch 98/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7467 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
            "Epoch 99/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7822 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 100/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7853 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 101/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7774 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 102/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7683 - val_loss: 0.5306 - val_accuracy: 0.7240\n",
            "Epoch 103/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7869 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
            "Epoch 104/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7929 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 105/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7670 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 106/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7679 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 107/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7774 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7827 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
            "Epoch 109/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7961 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 110/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7566 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 111/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7913 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 112/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7648 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
            "Epoch 113/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7634 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
            "Epoch 114/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8010 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
            "Epoch 115/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7988 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
            "Epoch 116/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7749 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
            "Epoch 117/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7892 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 118/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7919 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
            "Epoch 119/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7655 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
            "Epoch 120/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8024 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
            "Epoch 121/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7779 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 122/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7684 - val_loss: 0.5097 - val_accuracy: 0.7292\n",
            "Epoch 123/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7783 - val_loss: 0.5138 - val_accuracy: 0.7188\n",
            "Epoch 124/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7811 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
            "Epoch 125/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7416 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
            "Epoch 126/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8058 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
            "Epoch 127/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8029 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
            "Epoch 128/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7594 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
            "Epoch 129/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7970 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 130/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8217 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
            "Epoch 131/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7859 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 132/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8088 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
            "Epoch 133/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7957 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
            "Epoch 134/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8110 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
            "Epoch 135/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7722 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
            "Epoch 136/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8084 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 137/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7723 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 138/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8522 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 139/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8204 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
            "Epoch 140/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7990 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 141/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7528 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
            "Epoch 142/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7905 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
            "Epoch 143/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7991 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
            "Epoch 144/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8202 - val_loss: 0.5125 - val_accuracy: 0.7240\n",
            "Epoch 145/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7909 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
            "Epoch 146/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8062 - val_loss: 0.5561 - val_accuracy: 0.7135\n",
            "Epoch 147/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7943 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
            "Epoch 148/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8069 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
            "Epoch 149/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8004 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
            "Epoch 150/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7602 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
            "Epoch 151/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8560 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
            "Epoch 152/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8101 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 153/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7765 - val_loss: 0.5365 - val_accuracy: 0.7344\n",
            "Epoch 154/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7933 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 155/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8166 - val_loss: 0.5239 - val_accuracy: 0.7448\n",
            "Epoch 156/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7931 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 157/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8142 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
            "Epoch 158/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7890 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 159/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7930 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 160/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7878 - val_loss: 0.5286 - val_accuracy: 0.7656\n",
            "Epoch 161/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7748 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
            "Epoch 162/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7886 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
            "Epoch 163/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8074 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
            "Epoch 164/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8297 - val_loss: 0.5166 - val_accuracy: 0.7292\n",
            "Epoch 165/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7896 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 166/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7974 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
            "Epoch 167/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8030 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
            "Epoch 168/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7960 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 169/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8029 - val_loss: 0.5534 - val_accuracy: 0.7135\n",
            "Epoch 170/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7932 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 171/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8312 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
            "Epoch 172/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8114 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
            "Epoch 173/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8036 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 174/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7904 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
            "Epoch 175/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8041 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7884 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 177/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7931 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 178/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7749 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
            "Epoch 179/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7929 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 180/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8007 - val_loss: 0.5520 - val_accuracy: 0.7604\n",
            "Epoch 181/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7897 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 182/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8277 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 183/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8076 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
            "Epoch 184/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8240 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
            "Epoch 185/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8223 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7826 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 187/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8066 - val_loss: 0.5284 - val_accuracy: 0.7760\n",
            "Epoch 188/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8014 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 189/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8323 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
            "Epoch 190/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8064 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 191/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7817 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 192/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8221 - val_loss: 0.5448 - val_accuracy: 0.7708\n",
            "Epoch 193/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8185 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 194/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8197 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
            "Epoch 195/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8232 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 196/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7662 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 197/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
            "Epoch 198/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7855 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
            "Epoch 199/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8115 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
            "Epoch 200/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8274 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
            "Epoch 201/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8099 - val_loss: 0.5315 - val_accuracy: 0.7500\n",
            "Epoch 202/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7968 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 203/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8063 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 204/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7997 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 205/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7842 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 206/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7980 - val_loss: 0.5460 - val_accuracy: 0.7604\n",
            "Epoch 207/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8151 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 208/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8053 - val_loss: 0.5452 - val_accuracy: 0.7604\n",
            "Epoch 209/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7879 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
            "Epoch 210/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 211/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7983 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
            "Epoch 212/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8042 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
            "Epoch 213/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7814 - val_loss: 0.5341 - val_accuracy: 0.7708\n",
            "Epoch 214/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7967 - val_loss: 0.5556 - val_accuracy: 0.7552\n",
            "Epoch 215/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8137 - val_loss: 0.5723 - val_accuracy: 0.7135\n",
            "Epoch 216/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8043 - val_loss: 0.5450 - val_accuracy: 0.7604\n",
            "Epoch 217/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8072 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 218/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7785 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
            "Epoch 219/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7960 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
            "Epoch 220/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8049 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
            "Epoch 221/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8075 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
            "Epoch 222/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8007 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
            "Epoch 223/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8111 - val_loss: 0.5506 - val_accuracy: 0.7552\n",
            "Epoch 224/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8098 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 225/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8195 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 226/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8113 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 227/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8038 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
            "Epoch 228/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7927 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
            "Epoch 229/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7862 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
            "Epoch 230/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8250 - val_loss: 0.5683 - val_accuracy: 0.7396\n",
            "Epoch 231/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7776 - val_loss: 0.5769 - val_accuracy: 0.7240\n",
            "Epoch 232/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7968 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 233/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7766 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 234/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8400 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 235/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8369 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
            "Epoch 236/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7735 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 237/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8249 - val_loss: 0.5575 - val_accuracy: 0.7396\n",
            "Epoch 238/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8094 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 239/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8279 - val_loss: 0.5457 - val_accuracy: 0.7448\n",
            "Epoch 240/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8344 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7928 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 242/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7965 - val_loss: 0.5535 - val_accuracy: 0.7552\n",
            "Epoch 243/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8174 - val_loss: 0.5444 - val_accuracy: 0.7604\n",
            "Epoch 244/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8296 - val_loss: 0.5562 - val_accuracy: 0.7552\n",
            "Epoch 245/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8026 - val_loss: 0.5537 - val_accuracy: 0.7708\n",
            "Epoch 246/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8536 - val_loss: 0.5487 - val_accuracy: 0.7552\n",
            "Epoch 247/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7895 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 248/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8125 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
            "Epoch 249/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7981 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
            "Epoch 250/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8218 - val_loss: 0.5575 - val_accuracy: 0.7500\n",
            "Epoch 251/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8456 - val_loss: 0.5754 - val_accuracy: 0.7344\n",
            "Epoch 252/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7843 - val_loss: 0.5806 - val_accuracy: 0.7188\n",
            "Epoch 253/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8204 - val_loss: 0.5650 - val_accuracy: 0.7396\n",
            "Epoch 254/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7878 - val_loss: 0.5658 - val_accuracy: 0.7448\n",
            "Epoch 255/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8192 - val_loss: 0.5507 - val_accuracy: 0.7656\n",
            "Epoch 256/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8324 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
            "Epoch 257/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8147 - val_loss: 0.5553 - val_accuracy: 0.7656\n",
            "Epoch 258/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7743 - val_loss: 0.5454 - val_accuracy: 0.7604\n",
            "Epoch 259/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8029 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 260/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8011 - val_loss: 0.5553 - val_accuracy: 0.7552\n",
            "Epoch 261/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8008 - val_loss: 0.5662 - val_accuracy: 0.7396\n",
            "Epoch 262/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8061 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 263/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7976 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
            "Epoch 264/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8232 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
            "Epoch 265/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8273 - val_loss: 0.5657 - val_accuracy: 0.7396\n",
            "Epoch 266/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8042 - val_loss: 0.5596 - val_accuracy: 0.7448\n",
            "Epoch 267/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8141 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 268/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8115 - val_loss: 0.5412 - val_accuracy: 0.7656\n",
            "Epoch 269/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8062 - val_loss: 0.5487 - val_accuracy: 0.7552\n",
            "Epoch 270/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7920 - val_loss: 0.5572 - val_accuracy: 0.7604\n",
            "Epoch 271/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8050 - val_loss: 0.5579 - val_accuracy: 0.7448\n",
            "Epoch 272/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8398 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
            "Epoch 273/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7561 - val_loss: 0.5419 - val_accuracy: 0.7604\n",
            "Epoch 274/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8244 - val_loss: 0.5697 - val_accuracy: 0.7344\n",
            "Epoch 275/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8124 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
            "Epoch 276/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8294 - val_loss: 0.5309 - val_accuracy: 0.7708\n",
            "Epoch 277/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7922 - val_loss: 0.5640 - val_accuracy: 0.7344\n",
            "Epoch 278/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8340 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
            "Epoch 279/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8181 - val_loss: 0.5710 - val_accuracy: 0.7656\n",
            "Epoch 280/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8173 - val_loss: 0.5486 - val_accuracy: 0.7552\n",
            "Epoch 281/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7974 - val_loss: 0.5680 - val_accuracy: 0.7396\n",
            "Epoch 282/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7919 - val_loss: 0.5577 - val_accuracy: 0.7552\n",
            "Epoch 283/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7900 - val_loss: 0.5537 - val_accuracy: 0.7604\n",
            "Epoch 284/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7873 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 285/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8135 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
            "Epoch 286/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7966 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
            "Epoch 287/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8269 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
            "Epoch 288/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7725 - val_loss: 0.5753 - val_accuracy: 0.7552\n",
            "Epoch 289/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7731 - val_loss: 0.5641 - val_accuracy: 0.7396\n",
            "Epoch 290/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8099 - val_loss: 0.5690 - val_accuracy: 0.7135\n",
            "Epoch 291/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8306 - val_loss: 0.5816 - val_accuracy: 0.7396\n",
            "Epoch 292/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8172 - val_loss: 0.5642 - val_accuracy: 0.7396\n",
            "Epoch 293/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8236 - val_loss: 0.5865 - val_accuracy: 0.7188\n",
            "Epoch 294/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8204 - val_loss: 0.5631 - val_accuracy: 0.7448\n",
            "Epoch 295/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8197 - val_loss: 0.5539 - val_accuracy: 0.7292\n",
            "Epoch 296/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7947 - val_loss: 0.5510 - val_accuracy: 0.7604\n",
            "Epoch 297/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8284 - val_loss: 0.5423 - val_accuracy: 0.7604\n",
            "Epoch 298/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8138 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 299/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8178 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
            "Epoch 300/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7647 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 301/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8210 - val_loss: 0.5713 - val_accuracy: 0.7396\n",
            "Epoch 302/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8464 - val_loss: 0.5604 - val_accuracy: 0.7448\n",
            "Epoch 303/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7967 - val_loss: 0.5775 - val_accuracy: 0.7552\n",
            "Epoch 304/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8074 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
            "Epoch 305/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8101 - val_loss: 0.5665 - val_accuracy: 0.7396\n",
            "Epoch 306/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8324 - val_loss: 0.5619 - val_accuracy: 0.7448\n",
            "Epoch 307/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8259 - val_loss: 0.5672 - val_accuracy: 0.7500\n",
            "Epoch 308/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8187 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
            "Epoch 309/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8007 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 310/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8472 - val_loss: 0.5810 - val_accuracy: 0.7344\n",
            "Epoch 311/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7975 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 312/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8327 - val_loss: 0.5754 - val_accuracy: 0.7448\n",
            "Epoch 313/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8378 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7511 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
            "Epoch 315/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8151 - val_loss: 0.5573 - val_accuracy: 0.7552\n",
            "Epoch 316/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7991 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
            "Epoch 317/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8053 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
            "Epoch 318/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8011 - val_loss: 0.5836 - val_accuracy: 0.7188\n",
            "Epoch 319/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8211 - val_loss: 0.5737 - val_accuracy: 0.7396\n",
            "Epoch 320/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8097 - val_loss: 0.5666 - val_accuracy: 0.7448\n",
            "Epoch 321/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8339 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 322/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8276 - val_loss: 0.5601 - val_accuracy: 0.7448\n",
            "Epoch 323/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8200 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
            "Epoch 324/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7945 - val_loss: 0.5589 - val_accuracy: 0.7552\n",
            "Epoch 325/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8144 - val_loss: 0.6015 - val_accuracy: 0.7240\n",
            "Epoch 326/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7980 - val_loss: 0.5616 - val_accuracy: 0.7448\n",
            "Epoch 327/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7961 - val_loss: 0.5738 - val_accuracy: 0.7448\n",
            "Epoch 328/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7685 - val_loss: 0.5682 - val_accuracy: 0.7552\n",
            "Epoch 329/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8085 - val_loss: 0.5529 - val_accuracy: 0.7552\n",
            "Epoch 330/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8330 - val_loss: 0.5694 - val_accuracy: 0.7188\n",
            "Epoch 331/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8063 - val_loss: 0.5817 - val_accuracy: 0.7292\n",
            "Epoch 332/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8275 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
            "Epoch 333/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8405 - val_loss: 0.5738 - val_accuracy: 0.7552\n",
            "Epoch 334/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7894 - val_loss: 0.5734 - val_accuracy: 0.7240\n",
            "Epoch 335/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7944 - val_loss: 0.5675 - val_accuracy: 0.7500\n",
            "Epoch 336/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8483 - val_loss: 0.5759 - val_accuracy: 0.7292\n",
            "Epoch 337/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8051 - val_loss: 0.5648 - val_accuracy: 0.7344\n",
            "Epoch 338/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7968 - val_loss: 0.5647 - val_accuracy: 0.7344\n",
            "Epoch 339/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8356 - val_loss: 0.6043 - val_accuracy: 0.7135\n",
            "Epoch 340/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7978 - val_loss: 0.5796 - val_accuracy: 0.7344\n",
            "Epoch 341/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8233 - val_loss: 0.5893 - val_accuracy: 0.7292\n",
            "Epoch 342/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8194 - val_loss: 0.5740 - val_accuracy: 0.7292\n",
            "Epoch 343/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8086 - val_loss: 0.5953 - val_accuracy: 0.7292\n",
            "Epoch 344/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8115 - val_loss: 0.5807 - val_accuracy: 0.7448\n",
            "Epoch 345/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8248 - val_loss: 0.5849 - val_accuracy: 0.7344\n",
            "Epoch 346/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7885 - val_loss: 0.5976 - val_accuracy: 0.7344\n",
            "Epoch 347/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8183 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
            "Epoch 348/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8244 - val_loss: 0.5873 - val_accuracy: 0.7448\n",
            "Epoch 349/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8082 - val_loss: 0.5965 - val_accuracy: 0.7344\n",
            "Epoch 350/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8423 - val_loss: 0.5918 - val_accuracy: 0.7083\n",
            "Epoch 351/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8149 - val_loss: 0.5810 - val_accuracy: 0.7292\n",
            "Epoch 352/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7945 - val_loss: 0.5729 - val_accuracy: 0.7396\n",
            "Epoch 353/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7807 - val_loss: 0.5757 - val_accuracy: 0.7344\n",
            "Epoch 354/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7809 - val_loss: 0.5808 - val_accuracy: 0.7240\n",
            "Epoch 355/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8366 - val_loss: 0.5830 - val_accuracy: 0.7292\n",
            "Epoch 356/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8344 - val_loss: 0.5753 - val_accuracy: 0.7344\n",
            "Epoch 357/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7953 - val_loss: 0.5864 - val_accuracy: 0.7240\n",
            "Epoch 358/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8073 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
            "Epoch 359/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8314 - val_loss: 0.5819 - val_accuracy: 0.7448\n",
            "Epoch 360/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8170 - val_loss: 0.5905 - val_accuracy: 0.7396\n",
            "Epoch 361/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8058 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 362/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7985 - val_loss: 0.5982 - val_accuracy: 0.7135\n",
            "Epoch 363/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8140 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
            "Epoch 364/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7731 - val_loss: 0.5678 - val_accuracy: 0.7448\n",
            "Epoch 365/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7824 - val_loss: 0.5840 - val_accuracy: 0.7240\n",
            "Epoch 366/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7921 - val_loss: 0.6067 - val_accuracy: 0.7448\n",
            "Epoch 367/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8197 - val_loss: 0.5931 - val_accuracy: 0.7344\n",
            "Epoch 368/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7709 - val_loss: 0.5893 - val_accuracy: 0.7292\n",
            "Epoch 369/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8348 - val_loss: 0.6005 - val_accuracy: 0.7240\n",
            "Epoch 370/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8010 - val_loss: 0.5768 - val_accuracy: 0.7448\n",
            "Epoch 371/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8119 - val_loss: 0.6059 - val_accuracy: 0.7240\n",
            "Epoch 372/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8062 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
            "Epoch 373/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7934 - val_loss: 0.6014 - val_accuracy: 0.7396\n",
            "Epoch 374/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8160 - val_loss: 0.6033 - val_accuracy: 0.7396\n",
            "Epoch 375/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7915 - val_loss: 0.5831 - val_accuracy: 0.7396\n",
            "Epoch 376/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8237 - val_loss: 0.5707 - val_accuracy: 0.7448\n",
            "Epoch 377/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7545 - val_loss: 0.5791 - val_accuracy: 0.7292\n",
            "Epoch 378/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8071 - val_loss: 0.6011 - val_accuracy: 0.7188\n",
            "Epoch 379/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8193 - val_loss: 0.5927 - val_accuracy: 0.7292\n",
            "Epoch 380/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8153 - val_loss: 0.5939 - val_accuracy: 0.7240\n",
            "Epoch 381/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7888 - val_loss: 0.5850 - val_accuracy: 0.7292\n",
            "Epoch 382/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7894 - val_loss: 0.5957 - val_accuracy: 0.7292\n",
            "Epoch 383/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8314 - val_loss: 0.6150 - val_accuracy: 0.7344\n",
            "Epoch 384/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8446 - val_loss: 0.6169 - val_accuracy: 0.7292\n",
            "Epoch 385/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8217 - val_loss: 0.5940 - val_accuracy: 0.7188\n",
            "Epoch 386/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8057 - val_loss: 0.5986 - val_accuracy: 0.7396\n",
            "Epoch 387/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8082 - val_loss: 0.6067 - val_accuracy: 0.7292\n",
            "Epoch 388/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7632 - val_loss: 0.6156 - val_accuracy: 0.7083\n",
            "Epoch 389/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8233 - val_loss: 0.5983 - val_accuracy: 0.7240\n",
            "Epoch 390/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8006 - val_loss: 0.5879 - val_accuracy: 0.7240\n",
            "Epoch 391/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8181 - val_loss: 0.5825 - val_accuracy: 0.7344\n",
            "Epoch 392/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8288 - val_loss: 0.5922 - val_accuracy: 0.7292\n",
            "Epoch 393/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8193 - val_loss: 0.6031 - val_accuracy: 0.7135\n",
            "Epoch 394/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8182 - val_loss: 0.6097 - val_accuracy: 0.7292\n",
            "Epoch 395/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7974 - val_loss: 0.6041 - val_accuracy: 0.7135\n",
            "Epoch 396/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8292 - val_loss: 0.5981 - val_accuracy: 0.7240\n",
            "Epoch 397/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8222 - val_loss: 0.6104 - val_accuracy: 0.7083\n",
            "Epoch 398/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8600 - val_loss: 0.6142 - val_accuracy: 0.7344\n",
            "Epoch 399/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8171 - val_loss: 0.6380 - val_accuracy: 0.7083\n",
            "Epoch 400/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8030 - val_loss: 0.6088 - val_accuracy: 0.7031\n",
            "Epoch 401/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8163 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 402/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8080 - val_loss: 0.6046 - val_accuracy: 0.7344\n",
            "Epoch 403/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8398 - val_loss: 0.5927 - val_accuracy: 0.7344\n",
            "Epoch 404/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8213 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
            "Epoch 405/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7932 - val_loss: 0.6065 - val_accuracy: 0.7292\n",
            "Epoch 406/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8160 - val_loss: 0.5988 - val_accuracy: 0.7240\n",
            "Epoch 407/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8001 - val_loss: 0.6076 - val_accuracy: 0.7292\n",
            "Epoch 408/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.6115 - val_accuracy: 0.7396\n",
            "Epoch 409/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8182 - val_loss: 0.5957 - val_accuracy: 0.7396\n",
            "Epoch 410/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8264 - val_loss: 0.5988 - val_accuracy: 0.7396\n",
            "Epoch 411/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.6062 - val_accuracy: 0.7292\n",
            "Epoch 412/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8205 - val_loss: 0.6369 - val_accuracy: 0.7240\n",
            "Epoch 413/1000\n",
            "116/116 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8273 - val_loss: 0.6082 - val_accuracy: 0.7396\n",
            "Evaluating on training set...\n",
            "loss=0.3573, accuracy: 85.0694%\n",
            "Evaluating on testing set...\n",
            "loss=0.6082, accuracy: 73.9583%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum Loss : 0.6923\n",
            "\n",
            "Minimum Loss : 0.3887\n",
            "\n",
            "Loss difference : 0.3036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y7JUQDYhbyNe",
        "outputId": "7a74c4a9-89db-46db-9d20-0138da5ab669"
      },
      "source": [
        "# Hyperparameters\r\n",
        "training_epochs = 1000 # Total number of training epochs\r\n",
        "learning_rate = 0.02 # The learning rate\r\n",
        "\r\n",
        "\r\n",
        "# create a model\r\n",
        "def create_model3():\r\n",
        "    model3 = tf.keras.Sequential()\r\n",
        "    # Hidden layer\r\n",
        "    model3.add(tf.keras.layers.Dense(20, input_dim=8,activation='relu'))\r\n",
        "    # Hidden layer 2\r\n",
        "    model3.add(tf.keras.layers.Dense(1, input_dim=8,activation='sigmoid'))\r\n",
        "    # Output layer\r\n",
        "    model3.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    # Compile a model\r\n",
        "    model3.compile(loss='binary_crossentropy', \r\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    return model3\r\n",
        "\r\n",
        "model3 = create_model3()\r\n",
        "model3.summary()\r\n",
        "\r\n",
        "\r\n",
        "results3 = model3.fit(\r\n",
        "    x_tr, y_tr,\r\n",
        "    epochs= training_epochs,\r\n",
        "    validation_data = (x_ts, y_ts),\r\n",
        "    verbose = 1\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Evaluating on training set...\")\r\n",
        "(loss, accuracy) = model3.evaluate(x_tr, y_tr, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "print(\"Evaluating on testing set...\")\r\n",
        "(loss, accuracy) = model3.evaluate(x_ts, y_ts, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(results3.history['accuracy'])\r\n",
        "plt.plot(results3.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(results3.history['loss'])\r\n",
        "plt.plot(results3.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "max_loss3 = np.max(results3.history['loss'])\r\n",
        "min_loss3 = np.min(results3.history['loss'])\r\n",
        "print(\"Maximum Loss : {:.4f}\".format(max_loss3))\r\n",
        "print(\"\")\r\n",
        "print(\"Minimum Loss : {:.4f}\".format(min_loss3))\r\n",
        "print(\"\")\r\n",
        "print(\"Loss difference : {:.4f}\".format((max_loss3 - min_loss3)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 20)                180       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 21        \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 203\n",
            "Trainable params: 203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7810 - accuracy: 0.3152 - val_loss: 0.7417 - val_accuracy: 0.3698\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.3723 - val_loss: 0.7224 - val_accuracy: 0.3698\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.3506 - val_loss: 0.7077 - val_accuracy: 0.3698\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.3465 - val_loss: 0.6963 - val_accuracy: 0.3646\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4586 - val_loss: 0.6876 - val_accuracy: 0.6302\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.6346 - val_loss: 0.6809 - val_accuracy: 0.6302\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6735 - val_loss: 0.6758 - val_accuracy: 0.6302\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6504 - val_loss: 0.6719 - val_accuracy: 0.6302\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6609 - val_loss: 0.6688 - val_accuracy: 0.6302\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6465 - val_loss: 0.6665 - val_accuracy: 0.6302\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6760 - val_loss: 0.6648 - val_accuracy: 0.6302\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6785 - val_loss: 0.6635 - val_accuracy: 0.6302\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6775 - val_loss: 0.6625 - val_accuracy: 0.6302\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6302 - val_loss: 0.6618 - val_accuracy: 0.6302\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6499 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6541 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6451 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6800 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6592 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6711 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6667 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6696 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6357 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6582 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6719 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6595 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6635 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6563 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6079 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6333 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6743 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6412 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6615 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6752 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6808 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6710 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6634 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6279 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6527 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6702 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.6086 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6559 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6666 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6610 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6601 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6242 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6643 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6693 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6329 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6297 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6694 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6655 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6479 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6838 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6850 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6760 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6519 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6547 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6430 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6398 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6662 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6849 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6423 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6447 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6344 - val_loss: 0.6615 - val_accuracy: 0.6302\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6550 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6707 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6555 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6256 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6396 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6857 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6523 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6513 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6439 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6654 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6678 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6622 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6603 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6572 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.6060 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6871 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6417 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6222 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6364 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6565 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6680 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6777 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.7024 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6781 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6289 - val_loss: 0.6612 - val_accuracy: 0.6302\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6607 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6693 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6614 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5968 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6154 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6714 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6603 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6835 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6428 - val_loss: 0.6611 - val_accuracy: 0.6302\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6617 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6687 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6483 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.6200 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.6432 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6707 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6631 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6474 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6800 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6701 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6610 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6355 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6522 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6601 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.6139 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6488 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6477 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6504 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6438 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6579 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6400 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6440 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6325 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6633 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6641 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6466 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6157 - val_loss: 0.6608 - val_accuracy: 0.6302\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6602 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6636 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6322 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6536 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6697 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6689 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6477 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6090 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6670 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6490 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.6562 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6583 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6750 - val_loss: 0.6606 - val_accuracy: 0.6302\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6873 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6987 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6501 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6507 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6544 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6605 - val_loss: 0.6605 - val_accuracy: 0.6302\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6637 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6631 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6923 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6704 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6592 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6486 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6591 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6529 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6804 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6502 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6574 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6583 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.6322 - val_loss: 0.6603 - val_accuracy: 0.6302\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6564 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6708 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6583 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.6529 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6928 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6665 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6456 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6533 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.6459 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6417 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6642 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6760 - val_loss: 0.6601 - val_accuracy: 0.6302\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6472 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6833 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.6453 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6599 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6599 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6686 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6850 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.6762 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6461 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6881 - val_loss: 0.6599 - val_accuracy: 0.6302\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6482 - val_loss: 0.6598 - val_accuracy: 0.6302\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6727 - val_loss: 0.6598 - val_accuracy: 0.6302\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6825 - val_loss: 0.6598 - val_accuracy: 0.6302\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6605 - val_loss: 0.6598 - val_accuracy: 0.6302\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6609 - val_loss: 0.6598 - val_accuracy: 0.6302\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6504 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6415 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6643 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6415 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6590 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6454 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6410 - val_loss: 0.6597 - val_accuracy: 0.6302\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6633 - val_loss: 0.6596 - val_accuracy: 0.6302\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6695 - val_loss: 0.6596 - val_accuracy: 0.6302\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6512 - val_loss: 0.6596 - val_accuracy: 0.6302\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6832 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6509 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6520 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.6588 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6581 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6731 - val_loss: 0.6595 - val_accuracy: 0.6302\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6910 - val_loss: 0.6594 - val_accuracy: 0.6302\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6731 - val_loss: 0.6594 - val_accuracy: 0.6302\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6629 - val_loss: 0.6594 - val_accuracy: 0.6302\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.6877 - val_loss: 0.6593 - val_accuracy: 0.6302\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6762 - val_loss: 0.6593 - val_accuracy: 0.6302\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6616 - val_loss: 0.6593 - val_accuracy: 0.6302\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6479 - val_loss: 0.6593 - val_accuracy: 0.6302\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6972 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6601 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6694 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6436 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6367 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6741 - val_loss: 0.6592 - val_accuracy: 0.6302\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6542 - val_loss: 0.6591 - val_accuracy: 0.6302\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6473 - val_loss: 0.6591 - val_accuracy: 0.6302\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6526 - val_loss: 0.6591 - val_accuracy: 0.6302\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6727 - val_loss: 0.6591 - val_accuracy: 0.6302\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6432 - val_loss: 0.6591 - val_accuracy: 0.6302\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6462 - val_loss: 0.6590 - val_accuracy: 0.6302\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6713 - val_loss: 0.6590 - val_accuracy: 0.6302\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6334 - val_loss: 0.6590 - val_accuracy: 0.6302\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6933 - val_loss: 0.6590 - val_accuracy: 0.6302\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.6412 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6331 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6601 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6870 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6769 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6464 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6664 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6343 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6865 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6645 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6449 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6834 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6383 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6656 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6604 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6689 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6317 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6553 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6326 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6711 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6464 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6673 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6274 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6366 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6515 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6601 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6864 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6524 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6750 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6443 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.6361 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6554 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6494 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6570 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6753 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6476 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6345 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6484 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6604 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6535 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6741 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6649 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6523 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6555 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6382 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6575 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6846 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6433 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6361 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6417 - val_loss: 0.6575 - val_accuracy: 0.6302\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6509 - val_loss: 0.6575 - val_accuracy: 0.6302\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6876 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6628 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6600 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6678 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6512 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6350 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6487 - val_loss: 0.6572 - val_accuracy: 0.6302\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6541 - val_loss: 0.6572 - val_accuracy: 0.6302\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6826 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6722 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6628 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6344 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6716 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6688 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6565 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6706 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6349 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6449 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6742 - val_loss: 0.6567 - val_accuracy: 0.6302\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6480 - val_loss: 0.6567 - val_accuracy: 0.6302\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6619 - val_loss: 0.6567 - val_accuracy: 0.6302\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6445 - val_loss: 0.6566 - val_accuracy: 0.6302\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6568 - val_loss: 0.6566 - val_accuracy: 0.6302\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6656 - val_loss: 0.6565 - val_accuracy: 0.6302\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6662 - val_loss: 0.6565 - val_accuracy: 0.6302\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6777 - val_loss: 0.6564 - val_accuracy: 0.6302\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6809 - val_loss: 0.6564 - val_accuracy: 0.6302\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6586 - val_loss: 0.6563 - val_accuracy: 0.6302\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6516 - val_loss: 0.6563 - val_accuracy: 0.6302\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6713 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6608 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6535 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6873 - val_loss: 0.6561 - val_accuracy: 0.6302\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6781 - val_loss: 0.6560 - val_accuracy: 0.6302\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6668 - val_loss: 0.6560 - val_accuracy: 0.6302\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6526 - val_loss: 0.6559 - val_accuracy: 0.6302\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6418 - val_loss: 0.6559 - val_accuracy: 0.6302\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6424 - val_loss: 0.6559 - val_accuracy: 0.6302\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6609 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6789 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6564 - val_loss: 0.6557 - val_accuracy: 0.6302\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6438 - val_loss: 0.6557 - val_accuracy: 0.6302\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6259 - val_loss: 0.6556 - val_accuracy: 0.6302\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6312 - val_loss: 0.6556 - val_accuracy: 0.6302\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6467 - val_loss: 0.6555 - val_accuracy: 0.6302\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6539 - val_loss: 0.6555 - val_accuracy: 0.6302\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6675 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6446 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6355 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6594 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6704 - val_loss: 0.6552 - val_accuracy: 0.6302\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6744 - val_loss: 0.6551 - val_accuracy: 0.6302\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6516 - val_loss: 0.6551 - val_accuracy: 0.6302\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6451 - val_loss: 0.6550 - val_accuracy: 0.6302\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6221 - val_loss: 0.6550 - val_accuracy: 0.6302\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6494 - val_loss: 0.6549 - val_accuracy: 0.6302\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6739 - val_loss: 0.6549 - val_accuracy: 0.6302\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6899 - val_loss: 0.6548 - val_accuracy: 0.6302\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6675 - val_loss: 0.6547 - val_accuracy: 0.6302\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6216 - val_loss: 0.6547 - val_accuracy: 0.6302\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6547 - val_loss: 0.6546 - val_accuracy: 0.6302\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6461 - val_loss: 0.6546 - val_accuracy: 0.6302\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6554 - val_loss: 0.6545 - val_accuracy: 0.6302\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6377 - val_loss: 0.6544 - val_accuracy: 0.6302\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6620 - val_loss: 0.6544 - val_accuracy: 0.6302\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6301 - val_loss: 0.6543 - val_accuracy: 0.6302\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6764 - val_loss: 0.6542 - val_accuracy: 0.6302\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6777 - val_loss: 0.6542 - val_accuracy: 0.6302\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6436 - val_loss: 0.6541 - val_accuracy: 0.6302\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6634 - val_loss: 0.6540 - val_accuracy: 0.6302\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6598 - val_loss: 0.6540 - val_accuracy: 0.6302\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6811 - val_loss: 0.6539 - val_accuracy: 0.6302\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6600 - val_loss: 0.6538 - val_accuracy: 0.6302\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6841 - val_loss: 0.6537 - val_accuracy: 0.6302\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6651 - val_loss: 0.6537 - val_accuracy: 0.6302\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6419 - val_loss: 0.6536 - val_accuracy: 0.6302\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6529 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6528 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6468 - val_loss: 0.6534 - val_accuracy: 0.6302\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6561 - val_loss: 0.6533 - val_accuracy: 0.6302\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.6149 - val_loss: 0.6533 - val_accuracy: 0.6302\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6632 - val_loss: 0.6532 - val_accuracy: 0.6302\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6641 - val_loss: 0.6531 - val_accuracy: 0.6302\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6290 - val_loss: 0.6530 - val_accuracy: 0.6302\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6811 - val_loss: 0.6530 - val_accuracy: 0.6302\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6697 - val_loss: 0.6529 - val_accuracy: 0.6302\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6591 - val_loss: 0.6528 - val_accuracy: 0.6302\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6572 - val_loss: 0.6527 - val_accuracy: 0.6302\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6296 - val_loss: 0.6527 - val_accuracy: 0.6302\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6612 - val_loss: 0.6526 - val_accuracy: 0.6302\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6614 - val_loss: 0.6525 - val_accuracy: 0.6302\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6763 - val_loss: 0.6524 - val_accuracy: 0.6302\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6639 - val_loss: 0.6523 - val_accuracy: 0.6302\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6564 - val_loss: 0.6522 - val_accuracy: 0.6302\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6738 - val_loss: 0.6521 - val_accuracy: 0.6302\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6725 - val_loss: 0.6521 - val_accuracy: 0.6302\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6485 - val_loss: 0.6520 - val_accuracy: 0.6302\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6654 - val_loss: 0.6519 - val_accuracy: 0.6302\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6699 - val_loss: 0.6518 - val_accuracy: 0.6302\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6413 - val_loss: 0.6517 - val_accuracy: 0.6302\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6782 - val_loss: 0.6516 - val_accuracy: 0.6302\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6582 - val_loss: 0.6516 - val_accuracy: 0.6302\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6542 - val_loss: 0.6515 - val_accuracy: 0.6302\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6861 - val_loss: 0.6514 - val_accuracy: 0.6302\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6539 - val_loss: 0.6513 - val_accuracy: 0.6302\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6596 - val_loss: 0.6512 - val_accuracy: 0.6302\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6750 - val_loss: 0.6511 - val_accuracy: 0.6302\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6478 - val_loss: 0.6510 - val_accuracy: 0.6302\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6480 - val_loss: 0.6509 - val_accuracy: 0.6302\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6570 - val_loss: 0.6508 - val_accuracy: 0.6302\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6313 - val_loss: 0.6507 - val_accuracy: 0.6302\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6593 - val_loss: 0.6506 - val_accuracy: 0.6302\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6481 - val_loss: 0.6505 - val_accuracy: 0.6302\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6709 - val_loss: 0.6504 - val_accuracy: 0.6302\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6680 - val_loss: 0.6503 - val_accuracy: 0.6302\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6734 - val_loss: 0.6502 - val_accuracy: 0.6302\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6512 - val_loss: 0.6501 - val_accuracy: 0.6302\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6153 - val_loss: 0.6500 - val_accuracy: 0.6302\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6375 - val_loss: 0.6499 - val_accuracy: 0.6302\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6360 - val_loss: 0.6498 - val_accuracy: 0.6302\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6712 - val_loss: 0.6497 - val_accuracy: 0.6302\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6740 - val_loss: 0.6496 - val_accuracy: 0.6302\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6381 - val_loss: 0.6495 - val_accuracy: 0.6302\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6638 - val_loss: 0.6494 - val_accuracy: 0.6302\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6682 - val_loss: 0.6492 - val_accuracy: 0.6302\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6573 - val_loss: 0.6491 - val_accuracy: 0.6302\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6532 - val_loss: 0.6490 - val_accuracy: 0.6302\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6503 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6784 - val_loss: 0.6488 - val_accuracy: 0.6302\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6757 - val_loss: 0.6487 - val_accuracy: 0.6302\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6804 - val_loss: 0.6485 - val_accuracy: 0.6302\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6483 - val_loss: 0.6484 - val_accuracy: 0.6302\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.6621 - val_loss: 0.6483 - val_accuracy: 0.6302\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6470 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6652 - val_loss: 0.6481 - val_accuracy: 0.6302\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6716 - val_loss: 0.6479 - val_accuracy: 0.6302\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6483 - val_loss: 0.6478 - val_accuracy: 0.6302\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6348 - val_loss: 0.6477 - val_accuracy: 0.6302\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7181 - val_loss: 0.6475 - val_accuracy: 0.6302\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6551 - val_loss: 0.6474 - val_accuracy: 0.6302\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6310 - val_loss: 0.6473 - val_accuracy: 0.6302\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6780 - val_loss: 0.6472 - val_accuracy: 0.6302\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6896 - val_loss: 0.6470 - val_accuracy: 0.6302\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6521 - val_loss: 0.6469 - val_accuracy: 0.6302\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.6386 - val_loss: 0.6468 - val_accuracy: 0.6302\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6661 - val_loss: 0.6466 - val_accuracy: 0.6302\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.6882 - val_loss: 0.6465 - val_accuracy: 0.6302\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.6726 - val_loss: 0.6463 - val_accuracy: 0.6302\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6495 - val_loss: 0.6462 - val_accuracy: 0.6302\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6523 - val_loss: 0.6460 - val_accuracy: 0.6302\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6952 - val_loss: 0.6459 - val_accuracy: 0.6302\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6646 - val_loss: 0.6457 - val_accuracy: 0.6302\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6251 - val_loss: 0.6456 - val_accuracy: 0.6302\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6518 - val_loss: 0.6455 - val_accuracy: 0.6302\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6652 - val_loss: 0.6453 - val_accuracy: 0.6302\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6370 - val_loss: 0.6452 - val_accuracy: 0.6302\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6841 - val_loss: 0.6450 - val_accuracy: 0.6302\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6393 - val_loss: 0.6448 - val_accuracy: 0.6302\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6562 - val_loss: 0.6447 - val_accuracy: 0.6302\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.6498 - val_loss: 0.6445 - val_accuracy: 0.6302\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6690 - val_loss: 0.6443 - val_accuracy: 0.6302\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6547 - val_loss: 0.6442 - val_accuracy: 0.6302\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6560 - val_loss: 0.6440 - val_accuracy: 0.6302\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6759 - val_loss: 0.6438 - val_accuracy: 0.6302\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6516 - val_loss: 0.6437 - val_accuracy: 0.6302\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6622 - val_loss: 0.6435 - val_accuracy: 0.6302\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6503 - val_loss: 0.6433 - val_accuracy: 0.6302\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6721 - val_loss: 0.6431 - val_accuracy: 0.6302\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6369 - val_loss: 0.6430 - val_accuracy: 0.6302\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6603 - val_loss: 0.6428 - val_accuracy: 0.6302\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6402 - val_loss: 0.6426 - val_accuracy: 0.6302\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6757 - val_loss: 0.6424 - val_accuracy: 0.6302\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6570 - val_loss: 0.6422 - val_accuracy: 0.6302\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6293 - val_loss: 0.6421 - val_accuracy: 0.6302\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6517 - val_loss: 0.6419 - val_accuracy: 0.6302\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6497 - val_loss: 0.6417 - val_accuracy: 0.6302\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6595 - val_loss: 0.6415 - val_accuracy: 0.6302\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6889 - val_loss: 0.6413 - val_accuracy: 0.6302\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6543 - val_loss: 0.6411 - val_accuracy: 0.6302\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6514 - val_loss: 0.6409 - val_accuracy: 0.6302\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6794 - val_loss: 0.6407 - val_accuracy: 0.6302\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6736 - val_loss: 0.6404 - val_accuracy: 0.6302\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6700 - val_loss: 0.6402 - val_accuracy: 0.6302\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6802 - val_loss: 0.6400 - val_accuracy: 0.6302\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6619 - val_loss: 0.6398 - val_accuracy: 0.6302\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.6668 - val_loss: 0.6396 - val_accuracy: 0.6302\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6663 - val_loss: 0.6393 - val_accuracy: 0.6302\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6315 - val_loss: 0.6391 - val_accuracy: 0.6302\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6318 - val_loss: 0.6389 - val_accuracy: 0.6302\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6621 - val_loss: 0.6387 - val_accuracy: 0.6302\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6766 - val_loss: 0.6385 - val_accuracy: 0.6302\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6354 - val_loss: 0.6382 - val_accuracy: 0.6302\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6606 - val_loss: 0.6380 - val_accuracy: 0.6302\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6759 - val_loss: 0.6377 - val_accuracy: 0.6302\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6599 - val_loss: 0.6375 - val_accuracy: 0.6302\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6703 - val_loss: 0.6372 - val_accuracy: 0.6302\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6488 - val_loss: 0.6370 - val_accuracy: 0.6302\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6325 - val_loss: 0.6368 - val_accuracy: 0.6302\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.6650 - val_loss: 0.6365 - val_accuracy: 0.6302\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6369 - val_loss: 0.6363 - val_accuracy: 0.6302\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.6690 - val_loss: 0.6360 - val_accuracy: 0.6302\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6516 - val_loss: 0.6357 - val_accuracy: 0.6302\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6738 - val_loss: 0.6355 - val_accuracy: 0.6302\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6530 - val_loss: 0.6352 - val_accuracy: 0.6302\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6216 - val_loss: 0.6350 - val_accuracy: 0.6302\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.6740 - val_loss: 0.6347 - val_accuracy: 0.6302\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6627 - val_loss: 0.6344 - val_accuracy: 0.6302\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6501 - val_loss: 0.6341 - val_accuracy: 0.6302\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6629 - val_loss: 0.6338 - val_accuracy: 0.6302\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6355 - val_loss: 0.6336 - val_accuracy: 0.6302\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6375 - val_loss: 0.6333 - val_accuracy: 0.6302\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6769 - val_loss: 0.6330 - val_accuracy: 0.6302\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6587 - val_loss: 0.6327 - val_accuracy: 0.6302\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6532 - val_loss: 0.6324 - val_accuracy: 0.6302\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6616 - val_loss: 0.6321 - val_accuracy: 0.6302\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6432 - val_loss: 0.6318 - val_accuracy: 0.6302\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6676 - val_loss: 0.6315 - val_accuracy: 0.6302\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6702 - val_loss: 0.6311 - val_accuracy: 0.6302\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6291 - val_loss: 0.6308 - val_accuracy: 0.6302\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6682 - val_loss: 0.6305 - val_accuracy: 0.6302\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6722 - val_loss: 0.6302 - val_accuracy: 0.6302\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6751 - val_loss: 0.6298 - val_accuracy: 0.6302\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.6766 - val_loss: 0.6295 - val_accuracy: 0.6302\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.6379 - val_loss: 0.6292 - val_accuracy: 0.6302\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6554 - val_loss: 0.6289 - val_accuracy: 0.6302\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6397 - val_loss: 0.6285 - val_accuracy: 0.6302\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6592 - val_loss: 0.6282 - val_accuracy: 0.6302\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6465 - val_loss: 0.6279 - val_accuracy: 0.6302\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6664 - val_loss: 0.6275 - val_accuracy: 0.6302\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.6688 - val_loss: 0.6272 - val_accuracy: 0.6302\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6650 - val_loss: 0.6268 - val_accuracy: 0.6302\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6303 - val_loss: 0.6265 - val_accuracy: 0.6302\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6452 - val_loss: 0.6261 - val_accuracy: 0.6302\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6660 - val_loss: 0.6257 - val_accuracy: 0.6302\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6514 - val_loss: 0.6254 - val_accuracy: 0.6302\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6614 - val_loss: 0.6250 - val_accuracy: 0.6302\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6733 - val_loss: 0.6246 - val_accuracy: 0.6302\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6701 - val_loss: 0.6242 - val_accuracy: 0.6302\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6686 - val_loss: 0.6239 - val_accuracy: 0.6302\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.6630 - val_loss: 0.6235 - val_accuracy: 0.6302\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6621 - val_loss: 0.6231 - val_accuracy: 0.6302\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.6520 - val_loss: 0.6227 - val_accuracy: 0.6302\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6718 - val_loss: 0.6223 - val_accuracy: 0.6302\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6663 - val_loss: 0.6219 - val_accuracy: 0.6302\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6602 - val_loss: 0.6216 - val_accuracy: 0.6302\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6887 - val_loss: 0.6212 - val_accuracy: 0.6302\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.6700 - val_loss: 0.6208 - val_accuracy: 0.6302\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6658 - val_loss: 0.6204 - val_accuracy: 0.6302\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.6488 - val_loss: 0.6200 - val_accuracy: 0.6302\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6658 - val_loss: 0.6195 - val_accuracy: 0.6354\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6592 - val_loss: 0.6191 - val_accuracy: 0.6354\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.6880 - val_loss: 0.6187 - val_accuracy: 0.6354\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.6927 - val_loss: 0.6183 - val_accuracy: 0.6354\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6475 - val_loss: 0.6179 - val_accuracy: 0.6302\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6385 - val_loss: 0.6175 - val_accuracy: 0.6302\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6619 - val_loss: 0.6171 - val_accuracy: 0.6302\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6678 - val_loss: 0.6166 - val_accuracy: 0.6302\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.6432 - val_loss: 0.6162 - val_accuracy: 0.6302\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6749 - val_loss: 0.6158 - val_accuracy: 0.6302\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.6566 - val_loss: 0.6153 - val_accuracy: 0.6302\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6579 - val_loss: 0.6149 - val_accuracy: 0.6302\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6469 - val_loss: 0.6145 - val_accuracy: 0.6302\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6606 - val_loss: 0.6140 - val_accuracy: 0.6302\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6563 - val_loss: 0.6136 - val_accuracy: 0.6302\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6474 - val_loss: 0.6132 - val_accuracy: 0.6302\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6241 - val_loss: 0.6127 - val_accuracy: 0.6302\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6633 - val_loss: 0.6123 - val_accuracy: 0.6354\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6525 - val_loss: 0.6118 - val_accuracy: 0.6354\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6650 - val_loss: 0.6114 - val_accuracy: 0.6354\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6827 - val_loss: 0.6109 - val_accuracy: 0.6354\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6592 - val_loss: 0.6105 - val_accuracy: 0.6458\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.6519 - val_loss: 0.6100 - val_accuracy: 0.6406\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6544 - val_loss: 0.6096 - val_accuracy: 0.6458\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6614 - val_loss: 0.6091 - val_accuracy: 0.6458\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6699 - val_loss: 0.6087 - val_accuracy: 0.6562\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.6926 - val_loss: 0.6082 - val_accuracy: 0.6562\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.6752 - val_loss: 0.6077 - val_accuracy: 0.6562\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.6771 - val_loss: 0.6073 - val_accuracy: 0.6562\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6515 - val_loss: 0.6068 - val_accuracy: 0.6562\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.6972 - val_loss: 0.6063 - val_accuracy: 0.6562\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6804 - val_loss: 0.6059 - val_accuracy: 0.6615\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.6827 - val_loss: 0.6054 - val_accuracy: 0.6562\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.6821 - val_loss: 0.6049 - val_accuracy: 0.6562\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.6658 - val_loss: 0.6045 - val_accuracy: 0.6562\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6589 - val_loss: 0.6040 - val_accuracy: 0.6562\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.6835 - val_loss: 0.6035 - val_accuracy: 0.6510\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.6977 - val_loss: 0.6030 - val_accuracy: 0.6510\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6719 - val_loss: 0.6026 - val_accuracy: 0.6510\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7007 - val_loss: 0.6021 - val_accuracy: 0.6510\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.6789 - val_loss: 0.6016 - val_accuracy: 0.6615\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.6693 - val_loss: 0.6012 - val_accuracy: 0.6615\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7014 - val_loss: 0.6007 - val_accuracy: 0.6615\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.6950 - val_loss: 0.6002 - val_accuracy: 0.6615\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6708 - val_loss: 0.5997 - val_accuracy: 0.6615\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.6875 - val_loss: 0.5993 - val_accuracy: 0.6510\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.6925 - val_loss: 0.5988 - val_accuracy: 0.6562\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7219 - val_loss: 0.5983 - val_accuracy: 0.6562\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.6970 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6851 - val_loss: 0.5974 - val_accuracy: 0.6562\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7031 - val_loss: 0.5969 - val_accuracy: 0.6510\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7206 - val_loss: 0.5965 - val_accuracy: 0.6562\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.6995 - val_loss: 0.5960 - val_accuracy: 0.6510\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7161 - val_loss: 0.5956 - val_accuracy: 0.6458\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7183 - val_loss: 0.5951 - val_accuracy: 0.6458\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7045 - val_loss: 0.5946 - val_accuracy: 0.6458\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7275 - val_loss: 0.5942 - val_accuracy: 0.6510\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7089 - val_loss: 0.5937 - val_accuracy: 0.6510\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7023 - val_loss: 0.5933 - val_accuracy: 0.6510\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7172 - val_loss: 0.5928 - val_accuracy: 0.6510\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7562 - val_loss: 0.5924 - val_accuracy: 0.6510\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7132 - val_loss: 0.5918 - val_accuracy: 0.6510\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7167 - val_loss: 0.5914 - val_accuracy: 0.6562\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7252 - val_loss: 0.5909 - val_accuracy: 0.6562\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7358 - val_loss: 0.5905 - val_accuracy: 0.6510\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7278 - val_loss: 0.5900 - val_accuracy: 0.6510\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7246 - val_loss: 0.5896 - val_accuracy: 0.6458\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.6988 - val_loss: 0.5891 - val_accuracy: 0.6458\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7147 - val_loss: 0.5887 - val_accuracy: 0.6458\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6953 - val_loss: 0.5882 - val_accuracy: 0.6406\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7428 - val_loss: 0.5879 - val_accuracy: 0.6458\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7096 - val_loss: 0.5874 - val_accuracy: 0.6458\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7442 - val_loss: 0.5869 - val_accuracy: 0.6458\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7205 - val_loss: 0.5865 - val_accuracy: 0.6562\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7238 - val_loss: 0.5860 - val_accuracy: 0.6510\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7417 - val_loss: 0.5856 - val_accuracy: 0.6510\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.6562\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7276 - val_loss: 0.5848 - val_accuracy: 0.6615\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7014 - val_loss: 0.5843 - val_accuracy: 0.6615\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7521 - val_loss: 0.5840 - val_accuracy: 0.6615\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7410 - val_loss: 0.5835 - val_accuracy: 0.6615\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7496 - val_loss: 0.5832 - val_accuracy: 0.6562\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7299 - val_loss: 0.5828 - val_accuracy: 0.6615\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7354 - val_loss: 0.5823 - val_accuracy: 0.6615\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7474 - val_loss: 0.5820 - val_accuracy: 0.6562\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7402 - val_loss: 0.5816 - val_accuracy: 0.6562\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7530 - val_loss: 0.5812 - val_accuracy: 0.6562\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7670 - val_loss: 0.5810 - val_accuracy: 0.6510\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7334 - val_loss: 0.5805 - val_accuracy: 0.6510\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7482 - val_loss: 0.5801 - val_accuracy: 0.6510\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7483 - val_loss: 0.5797 - val_accuracy: 0.6510\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7503 - val_loss: 0.5792 - val_accuracy: 0.6510\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7479 - val_loss: 0.5788 - val_accuracy: 0.6510\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7472 - val_loss: 0.5784 - val_accuracy: 0.6562\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7383 - val_loss: 0.5780 - val_accuracy: 0.6615\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7518 - val_loss: 0.5776 - val_accuracy: 0.6667\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7305 - val_loss: 0.5770 - val_accuracy: 0.6615\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7814 - val_loss: 0.5768 - val_accuracy: 0.6667\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7663 - val_loss: 0.5765 - val_accuracy: 0.6667\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7802 - val_loss: 0.5762 - val_accuracy: 0.6667\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7516 - val_loss: 0.5760 - val_accuracy: 0.6615\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7586 - val_loss: 0.5755 - val_accuracy: 0.6615\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7557 - val_loss: 0.5751 - val_accuracy: 0.6615\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7829 - val_loss: 0.5747 - val_accuracy: 0.6615\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7499 - val_loss: 0.5743 - val_accuracy: 0.6615\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7389 - val_loss: 0.5742 - val_accuracy: 0.6667\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7478 - val_loss: 0.5738 - val_accuracy: 0.6719\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7177 - val_loss: 0.5733 - val_accuracy: 0.6719\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7642 - val_loss: 0.5729 - val_accuracy: 0.6719\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7332 - val_loss: 0.5725 - val_accuracy: 0.6667\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7429 - val_loss: 0.5722 - val_accuracy: 0.6719\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7304 - val_loss: 0.5719 - val_accuracy: 0.6719\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7547 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7505 - val_loss: 0.5713 - val_accuracy: 0.6667\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7557 - val_loss: 0.5710 - val_accuracy: 0.6667\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7606 - val_loss: 0.5709 - val_accuracy: 0.6667\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7721 - val_loss: 0.5705 - val_accuracy: 0.6667\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7566 - val_loss: 0.5702 - val_accuracy: 0.6667\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7672 - val_loss: 0.5703 - val_accuracy: 0.6667\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7687 - val_loss: 0.5697 - val_accuracy: 0.6667\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7485 - val_loss: 0.5693 - val_accuracy: 0.6667\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7625 - val_loss: 0.5688 - val_accuracy: 0.6667\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7533 - val_loss: 0.5686 - val_accuracy: 0.6667\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7469 - val_loss: 0.5681 - val_accuracy: 0.6667\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7613 - val_loss: 0.5679 - val_accuracy: 0.6667\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7481 - val_loss: 0.5678 - val_accuracy: 0.6667\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7738 - val_loss: 0.5675 - val_accuracy: 0.6667\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7343 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7759 - val_loss: 0.5668 - val_accuracy: 0.6667\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7757 - val_loss: 0.5667 - val_accuracy: 0.6667\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7787 - val_loss: 0.5663 - val_accuracy: 0.6667\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.6667\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7742 - val_loss: 0.5660 - val_accuracy: 0.6771\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7962 - val_loss: 0.5657 - val_accuracy: 0.6771\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7733 - val_loss: 0.5655 - val_accuracy: 0.6823\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7892 - val_loss: 0.5656 - val_accuracy: 0.6875\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7521 - val_loss: 0.5650 - val_accuracy: 0.6823\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7631 - val_loss: 0.5647 - val_accuracy: 0.6823\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7632 - val_loss: 0.5643 - val_accuracy: 0.6823\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7665 - val_loss: 0.5644 - val_accuracy: 0.6875\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7685 - val_loss: 0.5641 - val_accuracy: 0.6875\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7635 - val_loss: 0.5636 - val_accuracy: 0.6823\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7621 - val_loss: 0.5633 - val_accuracy: 0.6823\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7686 - val_loss: 0.5629 - val_accuracy: 0.6823\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7429 - val_loss: 0.5626 - val_accuracy: 0.6823\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7822 - val_loss: 0.5624 - val_accuracy: 0.6823\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7723 - val_loss: 0.5628 - val_accuracy: 0.6979\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7415 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7450 - val_loss: 0.5617 - val_accuracy: 0.6979\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7583 - val_loss: 0.5618 - val_accuracy: 0.6979\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7580 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7712 - val_loss: 0.5615 - val_accuracy: 0.6927\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7879 - val_loss: 0.5615 - val_accuracy: 0.6927\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7815 - val_loss: 0.5612 - val_accuracy: 0.6927\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7479 - val_loss: 0.5606 - val_accuracy: 0.6927\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7830 - val_loss: 0.5609 - val_accuracy: 0.6927\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7543 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7496 - val_loss: 0.5605 - val_accuracy: 0.6927\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7754 - val_loss: 0.5606 - val_accuracy: 0.6875\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7950 - val_loss: 0.5610 - val_accuracy: 0.6927\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7893 - val_loss: 0.5602 - val_accuracy: 0.6875\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7559 - val_loss: 0.5603 - val_accuracy: 0.6875\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7758 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7664 - val_loss: 0.5601 - val_accuracy: 0.6927\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7420 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7679 - val_loss: 0.5587 - val_accuracy: 0.6875\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7881 - val_loss: 0.5585 - val_accuracy: 0.6875\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7448 - val_loss: 0.5584 - val_accuracy: 0.6875\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7753 - val_loss: 0.5590 - val_accuracy: 0.6875\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7893 - val_loss: 0.5585 - val_accuracy: 0.6875\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7890 - val_loss: 0.5577 - val_accuracy: 0.6875\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7632 - val_loss: 0.5571 - val_accuracy: 0.6927\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7506 - val_loss: 0.5576 - val_accuracy: 0.6875\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7948 - val_loss: 0.5582 - val_accuracy: 0.6875\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7751 - val_loss: 0.5578 - val_accuracy: 0.6875\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7841 - val_loss: 0.5572 - val_accuracy: 0.6823\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7567 - val_loss: 0.5575 - val_accuracy: 0.6875\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7451 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7591 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7582 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7904 - val_loss: 0.5570 - val_accuracy: 0.6875\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7772 - val_loss: 0.5570 - val_accuracy: 0.6875\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7727 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7666 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7809 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7691 - val_loss: 0.5559 - val_accuracy: 0.6875\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7732 - val_loss: 0.5553 - val_accuracy: 0.6823\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7866 - val_loss: 0.5553 - val_accuracy: 0.6823\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7951 - val_loss: 0.5551 - val_accuracy: 0.6823\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7959 - val_loss: 0.5546 - val_accuracy: 0.6823\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7740 - val_loss: 0.5546 - val_accuracy: 0.6823\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7694 - val_loss: 0.5548 - val_accuracy: 0.6875\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8033 - val_loss: 0.5547 - val_accuracy: 0.6875\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7671 - val_loss: 0.5542 - val_accuracy: 0.6823\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7986 - val_loss: 0.5553 - val_accuracy: 0.6927\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7956 - val_loss: 0.5552 - val_accuracy: 0.6927\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7669 - val_loss: 0.5543 - val_accuracy: 0.6875\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7872 - val_loss: 0.5545 - val_accuracy: 0.6927\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7776 - val_loss: 0.5542 - val_accuracy: 0.6927\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8114 - val_loss: 0.5547 - val_accuracy: 0.6927\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7929 - val_loss: 0.5548 - val_accuracy: 0.6927\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7893 - val_loss: 0.5548 - val_accuracy: 0.6927\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7677 - val_loss: 0.5544 - val_accuracy: 0.6927\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7892 - val_loss: 0.5537 - val_accuracy: 0.6927\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7725 - val_loss: 0.5540 - val_accuracy: 0.6927\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7770 - val_loss: 0.5534 - val_accuracy: 0.6927\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7983 - val_loss: 0.5542 - val_accuracy: 0.6927\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7643 - val_loss: 0.5541 - val_accuracy: 0.7031\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.8058 - val_loss: 0.5539 - val_accuracy: 0.7031\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7955 - val_loss: 0.5543 - val_accuracy: 0.7135\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7719 - val_loss: 0.5533 - val_accuracy: 0.6979\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7951 - val_loss: 0.5533 - val_accuracy: 0.7031\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7673 - val_loss: 0.5525 - val_accuracy: 0.6927\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7912 - val_loss: 0.5533 - val_accuracy: 0.7083\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7864 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7883 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7632 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7620 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7774 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7712 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7693 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7694 - val_loss: 0.5527 - val_accuracy: 0.7188\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7910 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7770 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7570 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7839 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7508 - val_loss: 0.5517 - val_accuracy: 0.7135\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7895 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8063 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7991 - val_loss: 0.5534 - val_accuracy: 0.7240\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7528 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7768 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7798 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7842 - val_loss: 0.5527 - val_accuracy: 0.7240\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.8026 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7980 - val_loss: 0.5529 - val_accuracy: 0.7240\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7846 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.8033 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8075 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7894 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8025 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7699 - val_loss: 0.5526 - val_accuracy: 0.7188\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7575 - val_loss: 0.5517 - val_accuracy: 0.7240\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7699 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7804 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7509 - val_loss: 0.5510 - val_accuracy: 0.7240\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7507 - val_loss: 0.5520 - val_accuracy: 0.7188\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7793 - val_loss: 0.5528 - val_accuracy: 0.7188\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7762 - val_loss: 0.5520 - val_accuracy: 0.7188\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7845 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7814 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7741 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7849 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7770 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7641 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7911 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7867 - val_loss: 0.5503 - val_accuracy: 0.7188\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7607 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8132 - val_loss: 0.5515 - val_accuracy: 0.7188\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7662 - val_loss: 0.5516 - val_accuracy: 0.7188\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7649 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7829 - val_loss: 0.5513 - val_accuracy: 0.7188\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7976 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7528 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7789 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7633 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7658 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8154 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7982 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8002 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7693 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7747 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7620 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7803 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7806 - val_loss: 0.5520 - val_accuracy: 0.7188\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7827 - val_loss: 0.5500 - val_accuracy: 0.7188\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8083 - val_loss: 0.5504 - val_accuracy: 0.7188\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7697 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7797 - val_loss: 0.5511 - val_accuracy: 0.7188\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7664 - val_loss: 0.5509 - val_accuracy: 0.7188\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7524 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7648 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7646 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7903 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7736 - val_loss: 0.5508 - val_accuracy: 0.7188\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7694 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7742 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7525 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7766 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8016 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7736 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7748 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7954 - val_loss: 0.5529 - val_accuracy: 0.7188\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7892 - val_loss: 0.5529 - val_accuracy: 0.7188\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7641 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7837 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7441 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7749 - val_loss: 0.5515 - val_accuracy: 0.7188\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7627 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7809 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7754 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7350 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7691 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7858 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7827 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7787 - val_loss: 0.5525 - val_accuracy: 0.7188\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7744 - val_loss: 0.5504 - val_accuracy: 0.7188\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7878 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7796 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7615 - val_loss: 0.5505 - val_accuracy: 0.7188\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7826 - val_loss: 0.5531 - val_accuracy: 0.7188\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7553 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7842 - val_loss: 0.5514 - val_accuracy: 0.7188\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7829 - val_loss: 0.5527 - val_accuracy: 0.7188\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7689 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7600 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7777 - val_loss: 0.5538 - val_accuracy: 0.7188\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7602 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7733 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7589 - val_loss: 0.5510 - val_accuracy: 0.7240\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7609 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7871 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7734 - val_loss: 0.5527 - val_accuracy: 0.7188\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7744 - val_loss: 0.5536 - val_accuracy: 0.7188\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7714 - val_loss: 0.5514 - val_accuracy: 0.7292\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7786 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7748 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7736 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7989 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7902 - val_loss: 0.5547 - val_accuracy: 0.7188\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7683 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7780 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7703 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7560 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7938 - val_loss: 0.5539 - val_accuracy: 0.7240\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7759 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7699 - val_loss: 0.5533 - val_accuracy: 0.7240\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7842 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7692 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7721 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7669 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7700 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7858 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7725 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7595 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7391 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7826 - val_loss: 0.5500 - val_accuracy: 0.7240\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7754 - val_loss: 0.5541 - val_accuracy: 0.7240\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7731 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8062 - val_loss: 0.5535 - val_accuracy: 0.7240\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7765 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7798 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7878 - val_loss: 0.5534 - val_accuracy: 0.7240\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7916 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7936 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7712 - val_loss: 0.5521 - val_accuracy: 0.7240\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7881 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8028 - val_loss: 0.5549 - val_accuracy: 0.7344\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7575 - val_loss: 0.5551 - val_accuracy: 0.7344\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7780 - val_loss: 0.5565 - val_accuracy: 0.7344\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7866 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7733 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7794 - val_loss: 0.5522 - val_accuracy: 0.7240\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7549 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7939 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7477 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7637 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7701 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7802 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7880 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7784 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7723 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7852 - val_loss: 0.5555 - val_accuracy: 0.7344\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7655 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7917 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7770 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7845 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7675 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7737 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7744 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7985 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7942 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7515 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7905 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7666 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7737 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7874 - val_loss: 0.5557 - val_accuracy: 0.7344\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7649 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7725 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7990 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7759 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7925 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7526 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7725 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7762 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7995 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7685 - val_loss: 0.5542 - val_accuracy: 0.7292\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7856 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7934 - val_loss: 0.5547 - val_accuracy: 0.7292\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7657 - val_loss: 0.5542 - val_accuracy: 0.7292\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7756 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7942 - val_loss: 0.5577 - val_accuracy: 0.7240\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7925 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7916 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8046 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7683 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7704 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7885 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7864 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7590 - val_loss: 0.5559 - val_accuracy: 0.7240\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7712 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7810 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7472 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7944 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7654 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7980 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7504 - val_loss: 0.5546 - val_accuracy: 0.7292\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7836 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7712 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7762 - val_loss: 0.5532 - val_accuracy: 0.7344\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7639 - val_loss: 0.5544 - val_accuracy: 0.7292\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7746 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7806 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7686 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7654 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7514 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7995 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7700 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7717 - val_loss: 0.5507 - val_accuracy: 0.7344\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7755 - val_loss: 0.5527 - val_accuracy: 0.7344\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7774 - val_loss: 0.5568 - val_accuracy: 0.7240\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7772 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7603 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7667 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7557 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7734 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7767 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7772 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7822 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7755 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7614 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7854 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7849 - val_loss: 0.5570 - val_accuracy: 0.7240\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7727 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7790 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7861 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7401 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7451 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7788 - val_loss: 0.5541 - val_accuracy: 0.7240\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7974 - val_loss: 0.5596 - val_accuracy: 0.7135\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7792 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7983 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7698 - val_loss: 0.5548 - val_accuracy: 0.7240\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7512 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7837 - val_loss: 0.5545 - val_accuracy: 0.7240\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7677 - val_loss: 0.5570 - val_accuracy: 0.7135\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7723 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7923 - val_loss: 0.5607 - val_accuracy: 0.7031\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7782 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7733 - val_loss: 0.5571 - val_accuracy: 0.7135\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7806 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7679 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7816 - val_loss: 0.5558 - val_accuracy: 0.7188\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7596 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
            "Evaluating on training set...\n",
            "loss=0.4600, accuracy: 77.4306%\n",
            "Evaluating on testing set...\n",
            "loss=0.5577, accuracy: 71.3542%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum Loss : 0.7650\n",
            "\n",
            "Minimum Loss : 0.4606\n",
            "\n",
            "Loss difference : 0.3044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NKSJU3ujeqi8",
        "outputId": "bbec0e5c-a5d2-452e-c458-e4c50b209a1b"
      },
      "source": [
        "# Hyperparameters\r\n",
        "training_epochs = 1000 # Total number of training epochs\r\n",
        "learning_rate = 0.02 # The learning rate\r\n",
        "\r\n",
        "\r\n",
        "# create a model\r\n",
        "def create_model4():\r\n",
        "    model4 = tf.keras.Sequential()\r\n",
        "    # Hidden layer\r\n",
        "    model4.add(tf.keras.layers.Dense(20, input_dim=8,activation='relu'))\r\n",
        "    # Hidden layer 2\r\n",
        "    model4.add(tf.keras.layers.Dense(1, input_dim=8,activation='sigmoid'))\r\n",
        "    # Output layer\r\n",
        "    model4.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    # Compile a model\r\n",
        "    model4.compile(loss='binary_crossentropy', \r\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    return model4\r\n",
        "\r\n",
        "model4 = create_model4()\r\n",
        "model4.summary()\r\n",
        "\r\n",
        "\r\n",
        "results4 = model4.fit(\r\n",
        "    x_tr, y_tr,\r\n",
        "    epochs= training_epochs,\r\n",
        "    validation_data = (x_ts, y_ts),\r\n",
        "    verbose = 1\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Evaluating on training set...\")\r\n",
        "(loss, accuracy) = model4.evaluate(x_tr, y_tr, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "print(\"Evaluating on testing set...\")\r\n",
        "(loss, accuracy) = model4.evaluate(x_ts, y_ts, verbose=0)\r\n",
        "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\r\n",
        "\r\n",
        "\r\n",
        "# summarize history for accuracy\r\n",
        "plt.plot(results4.history['accuracy'])\r\n",
        "plt.plot(results4.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# summarize history for loss\r\n",
        "plt.plot(results4.history['loss'])\r\n",
        "plt.plot(results4.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "max_loss4 = np.max(results4.history['loss'])\r\n",
        "min_loss4 = np.min(results4.history['loss'])\r\n",
        "print(\"Maximum Loss : {:.4f}\".format(max_loss4))\r\n",
        "print(\"\")\r\n",
        "print(\"Minimum Loss : {:.4f}\".format(min_loss4))\r\n",
        "print(\"\")\r\n",
        "print(\"Loss difference : {:.4f}\".format((max_loss4 - min_loss4)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_34 (Dense)             (None, 20)                180       \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 21        \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 203\n",
            "Trainable params: 203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6926 - accuracy: 0.4953 - val_loss: 0.6863 - val_accuracy: 0.6302\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.6554 - val_loss: 0.6800 - val_accuracy: 0.6302\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.6411 - val_loss: 0.6750 - val_accuracy: 0.6302\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6475 - val_loss: 0.6711 - val_accuracy: 0.6302\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6504 - val_loss: 0.6679 - val_accuracy: 0.6302\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6492 - val_loss: 0.6655 - val_accuracy: 0.6302\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6443 - val_loss: 0.6636 - val_accuracy: 0.6302\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6644 - val_loss: 0.6621 - val_accuracy: 0.6302\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6558 - val_loss: 0.6609 - val_accuracy: 0.6302\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6767 - val_loss: 0.6600 - val_accuracy: 0.6302\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6504 - val_loss: 0.6594 - val_accuracy: 0.6302\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6618 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6715 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6466 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6781 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6631 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6526 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6673 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6556 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6602 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6277 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6914 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6622 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6536 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6345 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6438 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6642 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6709 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6583 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6617 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6723 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6415 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6630 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6471 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6346 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6341 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6472 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6645 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6311 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.6708 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6610 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6459 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6516 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6504 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6591 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6564 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6568 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6589 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6735 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6623 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6734 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.6539 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6752 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6561 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6658 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6557 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6551 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6404 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6721 - val_loss: 0.6588 - val_accuracy: 0.6302\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6798 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6395 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6547 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6354 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6482 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6607 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6406 - val_loss: 0.6587 - val_accuracy: 0.6302\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6683 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6530 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6844 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6503 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6613 - val_loss: 0.6586 - val_accuracy: 0.6302\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6452 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6446 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6634 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6759 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6518 - val_loss: 0.6585 - val_accuracy: 0.6302\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6629 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6734 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6606 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6776 - val_loss: 0.6584 - val_accuracy: 0.6302\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6867 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6355 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6843 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.6252 - val_loss: 0.6583 - val_accuracy: 0.6302\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6527 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6534 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6666 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6534 - val_loss: 0.6582 - val_accuracy: 0.6302\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6650 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6656 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6532 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6697 - val_loss: 0.6581 - val_accuracy: 0.6302\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6520 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6322 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6518 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6697 - val_loss: 0.6580 - val_accuracy: 0.6302\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6262 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6657 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6536 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6594 - val_loss: 0.6579 - val_accuracy: 0.6302\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6474 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6461 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6484 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6325 - val_loss: 0.6578 - val_accuracy: 0.6302\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6531 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6647 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6703 - val_loss: 0.6577 - val_accuracy: 0.6302\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6393 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6396 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6500 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6382 - val_loss: 0.6576 - val_accuracy: 0.6302\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6402 - val_loss: 0.6575 - val_accuracy: 0.6302\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6656 - val_loss: 0.6575 - val_accuracy: 0.6302\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6829 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6789 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6462 - val_loss: 0.6574 - val_accuracy: 0.6302\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6708 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6721 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6316 - val_loss: 0.6573 - val_accuracy: 0.6302\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6690 - val_loss: 0.6572 - val_accuracy: 0.6302\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6408 - val_loss: 0.6572 - val_accuracy: 0.6302\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6591 - val_loss: 0.6572 - val_accuracy: 0.6302\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6477 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6713 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6714 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6613 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6542 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6662 - val_loss: 0.6570 - val_accuracy: 0.6302\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6307 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6593 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6362 - val_loss: 0.6569 - val_accuracy: 0.6302\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6620 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6444 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6775 - val_loss: 0.6568 - val_accuracy: 0.6302\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6369 - val_loss: 0.6567 - val_accuracy: 0.6302\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6679 - val_loss: 0.6567 - val_accuracy: 0.6302\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6700 - val_loss: 0.6566 - val_accuracy: 0.6302\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7059 - val_loss: 0.6566 - val_accuracy: 0.6302\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.6883 - val_loss: 0.6565 - val_accuracy: 0.6302\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6490 - val_loss: 0.6565 - val_accuracy: 0.6302\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6642 - val_loss: 0.6565 - val_accuracy: 0.6302\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6558 - val_loss: 0.6564 - val_accuracy: 0.6302\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6851 - val_loss: 0.6564 - val_accuracy: 0.6302\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6344 - val_loss: 0.6563 - val_accuracy: 0.6302\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6426 - val_loss: 0.6563 - val_accuracy: 0.6302\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6337 - val_loss: 0.6563 - val_accuracy: 0.6302\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6741 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6473 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6252 - val_loss: 0.6562 - val_accuracy: 0.6302\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6698 - val_loss: 0.6561 - val_accuracy: 0.6302\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6535 - val_loss: 0.6561 - val_accuracy: 0.6302\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6282 - val_loss: 0.6560 - val_accuracy: 0.6302\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6678 - val_loss: 0.6560 - val_accuracy: 0.6302\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6336 - val_loss: 0.6560 - val_accuracy: 0.6302\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6502 - val_loss: 0.6559 - val_accuracy: 0.6302\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6593 - val_loss: 0.6559 - val_accuracy: 0.6302\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6783 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6515 - val_loss: 0.6558 - val_accuracy: 0.6302\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6647 - val_loss: 0.6557 - val_accuracy: 0.6302\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6520 - val_loss: 0.6557 - val_accuracy: 0.6302\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6482 - val_loss: 0.6556 - val_accuracy: 0.6302\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6367 - val_loss: 0.6556 - val_accuracy: 0.6302\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6587 - val_loss: 0.6555 - val_accuracy: 0.6302\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6592 - val_loss: 0.6555 - val_accuracy: 0.6302\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6591 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6593 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6247 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6807 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.6177 - val_loss: 0.6553 - val_accuracy: 0.6302\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6720 - val_loss: 0.6552 - val_accuracy: 0.6302\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6731 - val_loss: 0.6551 - val_accuracy: 0.6302\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6718 - val_loss: 0.6551 - val_accuracy: 0.6302\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6510 - val_loss: 0.6550 - val_accuracy: 0.6302\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6719 - val_loss: 0.6550 - val_accuracy: 0.6302\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6626 - val_loss: 0.6549 - val_accuracy: 0.6302\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6301 - val_loss: 0.6549 - val_accuracy: 0.6302\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6540 - val_loss: 0.6548 - val_accuracy: 0.6302\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6359 - val_loss: 0.6548 - val_accuracy: 0.6302\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6539 - val_loss: 0.6547 - val_accuracy: 0.6302\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6511 - val_loss: 0.6547 - val_accuracy: 0.6302\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6474 - val_loss: 0.6546 - val_accuracy: 0.6302\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6532 - val_loss: 0.6546 - val_accuracy: 0.6302\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6590 - val_loss: 0.6545 - val_accuracy: 0.6302\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6678 - val_loss: 0.6545 - val_accuracy: 0.6302\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6545 - val_loss: 0.6544 - val_accuracy: 0.6302\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6685 - val_loss: 0.6543 - val_accuracy: 0.6302\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6776 - val_loss: 0.6543 - val_accuracy: 0.6302\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6607 - val_loss: 0.6542 - val_accuracy: 0.6302\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6513 - val_loss: 0.6542 - val_accuracy: 0.6302\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6600 - val_loss: 0.6541 - val_accuracy: 0.6302\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6683 - val_loss: 0.6540 - val_accuracy: 0.6302\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6600 - val_loss: 0.6540 - val_accuracy: 0.6302\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6577 - val_loss: 0.6539 - val_accuracy: 0.6302\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6485 - val_loss: 0.6539 - val_accuracy: 0.6302\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6841 - val_loss: 0.6538 - val_accuracy: 0.6302\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6673 - val_loss: 0.6537 - val_accuracy: 0.6302\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6600 - val_loss: 0.6537 - val_accuracy: 0.6302\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6759 - val_loss: 0.6536 - val_accuracy: 0.6302\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6435 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6539 - val_loss: 0.6535 - val_accuracy: 0.6302\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6645 - val_loss: 0.6534 - val_accuracy: 0.6302\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6599 - val_loss: 0.6533 - val_accuracy: 0.6302\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6822 - val_loss: 0.6533 - val_accuracy: 0.6302\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6661 - val_loss: 0.6532 - val_accuracy: 0.6302\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6454 - val_loss: 0.6531 - val_accuracy: 0.6302\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6836 - val_loss: 0.6531 - val_accuracy: 0.6302\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6683 - val_loss: 0.6530 - val_accuracy: 0.6302\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6647 - val_loss: 0.6529 - val_accuracy: 0.6302\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6441 - val_loss: 0.6529 - val_accuracy: 0.6302\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6625 - val_loss: 0.6528 - val_accuracy: 0.6302\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6357 - val_loss: 0.6528 - val_accuracy: 0.6302\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6741 - val_loss: 0.6527 - val_accuracy: 0.6302\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6462 - val_loss: 0.6526 - val_accuracy: 0.6302\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6611 - val_loss: 0.6525 - val_accuracy: 0.6302\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6605 - val_loss: 0.6525 - val_accuracy: 0.6302\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6728 - val_loss: 0.6524 - val_accuracy: 0.6302\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.6426 - val_loss: 0.6523 - val_accuracy: 0.6302\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6606 - val_loss: 0.6523 - val_accuracy: 0.6302\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6914 - val_loss: 0.6522 - val_accuracy: 0.6302\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6657 - val_loss: 0.6521 - val_accuracy: 0.6302\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6310 - val_loss: 0.6520 - val_accuracy: 0.6302\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6492 - val_loss: 0.6520 - val_accuracy: 0.6302\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6571 - val_loss: 0.6519 - val_accuracy: 0.6302\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6529 - val_loss: 0.6518 - val_accuracy: 0.6302\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6765 - val_loss: 0.6517 - val_accuracy: 0.6302\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6426 - val_loss: 0.6517 - val_accuracy: 0.6302\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6626 - val_loss: 0.6516 - val_accuracy: 0.6302\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7046 - val_loss: 0.6515 - val_accuracy: 0.6302\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6585 - val_loss: 0.6514 - val_accuracy: 0.6302\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6889 - val_loss: 0.6513 - val_accuracy: 0.6302\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6669 - val_loss: 0.6512 - val_accuracy: 0.6302\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6186 - val_loss: 0.6512 - val_accuracy: 0.6302\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6655 - val_loss: 0.6511 - val_accuracy: 0.6302\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6421 - val_loss: 0.6510 - val_accuracy: 0.6302\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6492 - val_loss: 0.6509 - val_accuracy: 0.6302\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6791 - val_loss: 0.6508 - val_accuracy: 0.6302\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6486 - val_loss: 0.6507 - val_accuracy: 0.6302\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6598 - val_loss: 0.6506 - val_accuracy: 0.6302\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6507 - val_loss: 0.6506 - val_accuracy: 0.6302\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6530 - val_loss: 0.6505 - val_accuracy: 0.6302\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6526 - val_loss: 0.6504 - val_accuracy: 0.6302\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6374 - val_loss: 0.6503 - val_accuracy: 0.6302\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6844 - val_loss: 0.6502 - val_accuracy: 0.6302\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6645 - val_loss: 0.6501 - val_accuracy: 0.6302\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6619 - val_loss: 0.6500 - val_accuracy: 0.6302\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6452 - val_loss: 0.6499 - val_accuracy: 0.6302\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6499 - val_loss: 0.6498 - val_accuracy: 0.6302\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6365 - val_loss: 0.6497 - val_accuracy: 0.6302\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6784 - val_loss: 0.6496 - val_accuracy: 0.6302\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6657 - val_loss: 0.6495 - val_accuracy: 0.6302\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6547 - val_loss: 0.6494 - val_accuracy: 0.6302\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6534 - val_loss: 0.6493 - val_accuracy: 0.6302\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6689 - val_loss: 0.6492 - val_accuracy: 0.6302\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6551 - val_loss: 0.6491 - val_accuracy: 0.6302\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6584 - val_loss: 0.6490 - val_accuracy: 0.6302\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6375 - val_loss: 0.6489 - val_accuracy: 0.6302\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6642 - val_loss: 0.6488 - val_accuracy: 0.6302\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6548 - val_loss: 0.6487 - val_accuracy: 0.6302\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6708 - val_loss: 0.6486 - val_accuracy: 0.6302\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6609 - val_loss: 0.6485 - val_accuracy: 0.6302\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6684 - val_loss: 0.6484 - val_accuracy: 0.6302\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6682 - val_loss: 0.6483 - val_accuracy: 0.6302\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6393 - val_loss: 0.6482 - val_accuracy: 0.6302\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6488 - val_loss: 0.6480 - val_accuracy: 0.6302\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6643 - val_loss: 0.6479 - val_accuracy: 0.6302\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6609 - val_loss: 0.6478 - val_accuracy: 0.6302\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6801 - val_loss: 0.6477 - val_accuracy: 0.6302\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6525 - val_loss: 0.6476 - val_accuracy: 0.6302\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6375 - val_loss: 0.6475 - val_accuracy: 0.6302\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6579 - val_loss: 0.6473 - val_accuracy: 0.6302\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6552 - val_loss: 0.6472 - val_accuracy: 0.6302\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6370 - val_loss: 0.6471 - val_accuracy: 0.6302\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6540 - val_loss: 0.6470 - val_accuracy: 0.6302\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6430 - val_loss: 0.6468 - val_accuracy: 0.6302\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6458 - val_loss: 0.6467 - val_accuracy: 0.6302\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6475 - val_loss: 0.6466 - val_accuracy: 0.6302\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6487 - val_loss: 0.6464 - val_accuracy: 0.6302\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6857 - val_loss: 0.6463 - val_accuracy: 0.6302\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6859 - val_loss: 0.6462 - val_accuracy: 0.6302\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6524 - val_loss: 0.6460 - val_accuracy: 0.6302\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6588 - val_loss: 0.6459 - val_accuracy: 0.6302\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6523 - val_loss: 0.6457 - val_accuracy: 0.6302\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6623 - val_loss: 0.6456 - val_accuracy: 0.6302\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6344 - val_loss: 0.6454 - val_accuracy: 0.6302\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6705 - val_loss: 0.6453 - val_accuracy: 0.6302\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6543 - val_loss: 0.6451 - val_accuracy: 0.6302\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.6761 - val_loss: 0.6450 - val_accuracy: 0.6302\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6554 - val_loss: 0.6448 - val_accuracy: 0.6302\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6587 - val_loss: 0.6446 - val_accuracy: 0.6302\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6640 - val_loss: 0.6445 - val_accuracy: 0.6302\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6726 - val_loss: 0.6443 - val_accuracy: 0.6302\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6468 - val_loss: 0.6441 - val_accuracy: 0.6302\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6527 - val_loss: 0.6440 - val_accuracy: 0.6302\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6774 - val_loss: 0.6438 - val_accuracy: 0.6302\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6352 - val_loss: 0.6436 - val_accuracy: 0.6302\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6601 - val_loss: 0.6434 - val_accuracy: 0.6302\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6740 - val_loss: 0.6432 - val_accuracy: 0.6302\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6713 - val_loss: 0.6431 - val_accuracy: 0.6302\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6561 - val_loss: 0.6429 - val_accuracy: 0.6302\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6526 - val_loss: 0.6427 - val_accuracy: 0.6302\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6391 - val_loss: 0.6425 - val_accuracy: 0.6302\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.6618 - val_loss: 0.6423 - val_accuracy: 0.6302\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.6627 - val_loss: 0.6421 - val_accuracy: 0.6302\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6595 - val_loss: 0.6419 - val_accuracy: 0.6302\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6560 - val_loss: 0.6417 - val_accuracy: 0.6302\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6324 - val_loss: 0.6416 - val_accuracy: 0.6302\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6630 - val_loss: 0.6414 - val_accuracy: 0.6302\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6474 - val_loss: 0.6411 - val_accuracy: 0.6302\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.6534 - val_loss: 0.6409 - val_accuracy: 0.6302\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6429 - val_loss: 0.6407 - val_accuracy: 0.6302\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6747 - val_loss: 0.6405 - val_accuracy: 0.6302\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6190 - val_loss: 0.6403 - val_accuracy: 0.6302\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6627 - val_loss: 0.6401 - val_accuracy: 0.6302\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6319 - val_loss: 0.6399 - val_accuracy: 0.6302\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6210 - val_loss: 0.6397 - val_accuracy: 0.6302\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6685 - val_loss: 0.6395 - val_accuracy: 0.6302\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6295 - val_loss: 0.6392 - val_accuracy: 0.6302\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.6871 - val_loss: 0.6390 - val_accuracy: 0.6302\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6371 - val_loss: 0.6388 - val_accuracy: 0.6302\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6709 - val_loss: 0.6386 - val_accuracy: 0.6302\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6368 - val_loss: 0.6383 - val_accuracy: 0.6302\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6908 - val_loss: 0.6381 - val_accuracy: 0.6302\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6427 - val_loss: 0.6378 - val_accuracy: 0.6302\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6346 - val_loss: 0.6376 - val_accuracy: 0.6302\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6518 - val_loss: 0.6374 - val_accuracy: 0.6302\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6808 - val_loss: 0.6371 - val_accuracy: 0.6302\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6612 - val_loss: 0.6369 - val_accuracy: 0.6302\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6609 - val_loss: 0.6366 - val_accuracy: 0.6302\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6649 - val_loss: 0.6363 - val_accuracy: 0.6302\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6414 - val_loss: 0.6361 - val_accuracy: 0.6302\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6217 - val_loss: 0.6358 - val_accuracy: 0.6302\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6734 - val_loss: 0.6356 - val_accuracy: 0.6302\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6782 - val_loss: 0.6353 - val_accuracy: 0.6302\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.6690 - val_loss: 0.6350 - val_accuracy: 0.6302\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6312 - val_loss: 0.6348 - val_accuracy: 0.6302\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6645 - val_loss: 0.6345 - val_accuracy: 0.6302\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6613 - val_loss: 0.6342 - val_accuracy: 0.6302\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.6508 - val_loss: 0.6339 - val_accuracy: 0.6302\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6318 - val_loss: 0.6337 - val_accuracy: 0.6302\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.6801 - val_loss: 0.6334 - val_accuracy: 0.6302\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6288 - val_loss: 0.6331 - val_accuracy: 0.6302\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6645 - val_loss: 0.6328 - val_accuracy: 0.6302\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.6682 - val_loss: 0.6325 - val_accuracy: 0.6302\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6629 - val_loss: 0.6322 - val_accuracy: 0.6302\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.6761 - val_loss: 0.6319 - val_accuracy: 0.6302\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6516 - val_loss: 0.6316 - val_accuracy: 0.6302\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6658 - val_loss: 0.6313 - val_accuracy: 0.6302\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6085 - val_loss: 0.6310 - val_accuracy: 0.6302\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6794 - val_loss: 0.6307 - val_accuracy: 0.6302\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6712 - val_loss: 0.6303 - val_accuracy: 0.6302\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6642 - val_loss: 0.6300 - val_accuracy: 0.6302\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6128 - val_loss: 0.6297 - val_accuracy: 0.6302\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.6727 - val_loss: 0.6294 - val_accuracy: 0.6302\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6841 - val_loss: 0.6290 - val_accuracy: 0.6302\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6464 - val_loss: 0.6287 - val_accuracy: 0.6302\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6727 - val_loss: 0.6284 - val_accuracy: 0.6302\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.6796 - val_loss: 0.6280 - val_accuracy: 0.6302\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7013 - val_loss: 0.6277 - val_accuracy: 0.6302\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6559 - val_loss: 0.6273 - val_accuracy: 0.6302\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6718 - val_loss: 0.6270 - val_accuracy: 0.6302\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.6821 - val_loss: 0.6266 - val_accuracy: 0.6302\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6738 - val_loss: 0.6263 - val_accuracy: 0.6302\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6287 - val_loss: 0.6259 - val_accuracy: 0.6302\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6456 - val_loss: 0.6256 - val_accuracy: 0.6302\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6472 - val_loss: 0.6252 - val_accuracy: 0.6302\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6659 - val_loss: 0.6249 - val_accuracy: 0.6302\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6967 - val_loss: 0.6245 - val_accuracy: 0.6302\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6225 - val_loss: 0.6241 - val_accuracy: 0.6302\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6286 - val_loss: 0.6237 - val_accuracy: 0.6302\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6356 - val_loss: 0.6234 - val_accuracy: 0.6302\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6427 - val_loss: 0.6230 - val_accuracy: 0.6302\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6473 - val_loss: 0.6226 - val_accuracy: 0.6302\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6580 - val_loss: 0.6222 - val_accuracy: 0.6302\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6294 - val_loss: 0.6218 - val_accuracy: 0.6302\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6623 - val_loss: 0.6214 - val_accuracy: 0.6302\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6251 - val_loss: 0.6210 - val_accuracy: 0.6302\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6606 - val_loss: 0.6206 - val_accuracy: 0.6302\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6471 - val_loss: 0.6202 - val_accuracy: 0.6302\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6480 - val_loss: 0.6198 - val_accuracy: 0.6302\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.6956 - val_loss: 0.6194 - val_accuracy: 0.6302\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.6562 - val_loss: 0.6190 - val_accuracy: 0.6302\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.6356 - val_loss: 0.6186 - val_accuracy: 0.6302\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.6563 - val_loss: 0.6181 - val_accuracy: 0.6302\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.6751 - val_loss: 0.6177 - val_accuracy: 0.6302\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6505 - val_loss: 0.6173 - val_accuracy: 0.6302\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6431 - val_loss: 0.6168 - val_accuracy: 0.6302\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6697 - val_loss: 0.6164 - val_accuracy: 0.6302\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.6701 - val_loss: 0.6160 - val_accuracy: 0.6302\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6546 - val_loss: 0.6155 - val_accuracy: 0.6302\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.6619 - val_loss: 0.6151 - val_accuracy: 0.6302\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6506 - val_loss: 0.6147 - val_accuracy: 0.6302\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.6544 - val_loss: 0.6142 - val_accuracy: 0.6302\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6581 - val_loss: 0.6138 - val_accuracy: 0.6302\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6620 - val_loss: 0.6133 - val_accuracy: 0.6302\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.6707 - val_loss: 0.6129 - val_accuracy: 0.6302\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6453 - val_loss: 0.6124 - val_accuracy: 0.6302\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.6945 - val_loss: 0.6120 - val_accuracy: 0.6302\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6446 - val_loss: 0.6115 - val_accuracy: 0.6302\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.6604 - val_loss: 0.6110 - val_accuracy: 0.6302\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6340 - val_loss: 0.6106 - val_accuracy: 0.6302\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.6691 - val_loss: 0.6101 - val_accuracy: 0.6302\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.6629 - val_loss: 0.6096 - val_accuracy: 0.6302\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.6635 - val_loss: 0.6092 - val_accuracy: 0.6302\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6567 - val_loss: 0.6087 - val_accuracy: 0.6302\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6598 - val_loss: 0.6082 - val_accuracy: 0.6302\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.6949 - val_loss: 0.6078 - val_accuracy: 0.6302\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.6579 - val_loss: 0.6073 - val_accuracy: 0.6302\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.6796 - val_loss: 0.6068 - val_accuracy: 0.6302\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.6538 - val_loss: 0.6063 - val_accuracy: 0.6302\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.6485 - val_loss: 0.6058 - val_accuracy: 0.6302\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6487 - val_loss: 0.6053 - val_accuracy: 0.6302\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.6673 - val_loss: 0.6049 - val_accuracy: 0.6302\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.6698 - val_loss: 0.6044 - val_accuracy: 0.6302\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.6660 - val_loss: 0.6040 - val_accuracy: 0.6354\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6574 - val_loss: 0.6035 - val_accuracy: 0.6354\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.6413 - val_loss: 0.6030 - val_accuracy: 0.6354\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.6568 - val_loss: 0.6025 - val_accuracy: 0.6354\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.6618 - val_loss: 0.6020 - val_accuracy: 0.6354\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.6755 - val_loss: 0.6015 - val_accuracy: 0.6354\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.6483 - val_loss: 0.6010 - val_accuracy: 0.6354\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.6628 - val_loss: 0.6005 - val_accuracy: 0.6354\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.6584 - val_loss: 0.6000 - val_accuracy: 0.6354\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.6770 - val_loss: 0.5996 - val_accuracy: 0.6406\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.6393 - val_loss: 0.5991 - val_accuracy: 0.6406\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.6574 - val_loss: 0.5986 - val_accuracy: 0.6458\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.6708 - val_loss: 0.5981 - val_accuracy: 0.6458\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.6644 - val_loss: 0.5976 - val_accuracy: 0.6458\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6593 - val_loss: 0.5972 - val_accuracy: 0.6458\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.6796 - val_loss: 0.5967 - val_accuracy: 0.6458\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6615 - val_loss: 0.5962 - val_accuracy: 0.6510\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.6507 - val_loss: 0.5957 - val_accuracy: 0.6615\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.6715 - val_loss: 0.5952 - val_accuracy: 0.6615\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.6491 - val_loss: 0.5947 - val_accuracy: 0.6667\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.6745 - val_loss: 0.5943 - val_accuracy: 0.6615\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.6813 - val_loss: 0.5938 - val_accuracy: 0.6615\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6580 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.6865 - val_loss: 0.5929 - val_accuracy: 0.6667\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.6931 - val_loss: 0.5924 - val_accuracy: 0.6771\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.6679 - val_loss: 0.5919 - val_accuracy: 0.6771\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.6723 - val_loss: 0.5914 - val_accuracy: 0.6771\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.6797 - val_loss: 0.5909 - val_accuracy: 0.6771\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7226 - val_loss: 0.5905 - val_accuracy: 0.6771\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.6779 - val_loss: 0.5900 - val_accuracy: 0.6771\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.6915 - val_loss: 0.5895 - val_accuracy: 0.6771\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.6992 - val_loss: 0.5890 - val_accuracy: 0.6771\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.6647 - val_loss: 0.5885 - val_accuracy: 0.6771\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.6924 - val_loss: 0.5880 - val_accuracy: 0.6771\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7023 - val_loss: 0.5876 - val_accuracy: 0.6771\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7012 - val_loss: 0.5872 - val_accuracy: 0.6719\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.6975 - val_loss: 0.5867 - val_accuracy: 0.6719\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.6949 - val_loss: 0.5862 - val_accuracy: 0.6719\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7027 - val_loss: 0.5857 - val_accuracy: 0.6823\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.6734 - val_loss: 0.5853 - val_accuracy: 0.6823\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7240 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7276 - val_loss: 0.5845 - val_accuracy: 0.6771\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7299 - val_loss: 0.5842 - val_accuracy: 0.6823\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7115 - val_loss: 0.5837 - val_accuracy: 0.6875\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7087 - val_loss: 0.5833 - val_accuracy: 0.6823\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7016 - val_loss: 0.5829 - val_accuracy: 0.6771\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7049 - val_loss: 0.5824 - val_accuracy: 0.6771\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7325 - val_loss: 0.5820 - val_accuracy: 0.6771\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7003 - val_loss: 0.5812 - val_accuracy: 0.6771\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7117 - val_loss: 0.5808 - val_accuracy: 0.6771\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.6949 - val_loss: 0.5804 - val_accuracy: 0.6823\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7236 - val_loss: 0.5800 - val_accuracy: 0.6771\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7076 - val_loss: 0.5796 - val_accuracy: 0.6875\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7347 - val_loss: 0.5792 - val_accuracy: 0.6875\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7334 - val_loss: 0.5789 - val_accuracy: 0.6875\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7130 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7311 - val_loss: 0.5779 - val_accuracy: 0.6927\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7374 - val_loss: 0.5775 - val_accuracy: 0.6927\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7357 - val_loss: 0.5771 - val_accuracy: 0.6875\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7228 - val_loss: 0.5767 - val_accuracy: 0.6771\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7306 - val_loss: 0.5762 - val_accuracy: 0.6771\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7615 - val_loss: 0.5759 - val_accuracy: 0.6771\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7470 - val_loss: 0.5755 - val_accuracy: 0.6823\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7600 - val_loss: 0.5752 - val_accuracy: 0.6823\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7375 - val_loss: 0.5749 - val_accuracy: 0.6823\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7423 - val_loss: 0.5747 - val_accuracy: 0.6771\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7599 - val_loss: 0.5742 - val_accuracy: 0.6771\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7590 - val_loss: 0.5738 - val_accuracy: 0.6771\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7701 - val_loss: 0.5734 - val_accuracy: 0.6771\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7410 - val_loss: 0.5730 - val_accuracy: 0.6719\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7766 - val_loss: 0.5726 - val_accuracy: 0.6719\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7466 - val_loss: 0.5722 - val_accuracy: 0.6771\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7235 - val_loss: 0.5716 - val_accuracy: 0.6771\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7605 - val_loss: 0.5714 - val_accuracy: 0.6823\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7668 - val_loss: 0.5712 - val_accuracy: 0.6823\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7636 - val_loss: 0.5709 - val_accuracy: 0.6823\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7704 - val_loss: 0.5706 - val_accuracy: 0.6771\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7402 - val_loss: 0.5700 - val_accuracy: 0.6771\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7514 - val_loss: 0.5696 - val_accuracy: 0.6771\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7562 - val_loss: 0.5692 - val_accuracy: 0.6823\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.6823\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7429 - val_loss: 0.5684 - val_accuracy: 0.6823\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7506 - val_loss: 0.5679 - val_accuracy: 0.6875\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7744 - val_loss: 0.5677 - val_accuracy: 0.6927\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7900 - val_loss: 0.5674 - val_accuracy: 0.6927\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7683 - val_loss: 0.5673 - val_accuracy: 0.6927\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7923 - val_loss: 0.5666 - val_accuracy: 0.6927\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7763 - val_loss: 0.5667 - val_accuracy: 0.6927\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7834 - val_loss: 0.5661 - val_accuracy: 0.6927\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7554 - val_loss: 0.5658 - val_accuracy: 0.6979\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7841 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7735 - val_loss: 0.5654 - val_accuracy: 0.6875\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7590 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7447 - val_loss: 0.5646 - val_accuracy: 0.6875\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7891 - val_loss: 0.5647 - val_accuracy: 0.6875\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7860 - val_loss: 0.5639 - val_accuracy: 0.6875\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7677 - val_loss: 0.5635 - val_accuracy: 0.6875\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7720 - val_loss: 0.5633 - val_accuracy: 0.6875\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7788 - val_loss: 0.5630 - val_accuracy: 0.6875\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7423 - val_loss: 0.5627 - val_accuracy: 0.6875\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7848 - val_loss: 0.5623 - val_accuracy: 0.6875\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7871 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7703 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7443 - val_loss: 0.5617 - val_accuracy: 0.6927\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7336 - val_loss: 0.5610 - val_accuracy: 0.6927\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7725 - val_loss: 0.5608 - val_accuracy: 0.6927\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7718 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7469 - val_loss: 0.5601 - val_accuracy: 0.6927\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7368 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7837 - val_loss: 0.5597 - val_accuracy: 0.6875\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7794 - val_loss: 0.5596 - val_accuracy: 0.6875\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7634 - val_loss: 0.5596 - val_accuracy: 0.6979\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7922 - val_loss: 0.5596 - val_accuracy: 0.6979\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7797 - val_loss: 0.5593 - val_accuracy: 0.6979\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7787 - val_loss: 0.5590 - val_accuracy: 0.6979\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7701 - val_loss: 0.5585 - val_accuracy: 0.6979\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7727 - val_loss: 0.5582 - val_accuracy: 0.6979\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7725 - val_loss: 0.5583 - val_accuracy: 0.6979\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7727 - val_loss: 0.5579 - val_accuracy: 0.6979\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7476 - val_loss: 0.5574 - val_accuracy: 0.6979\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8073 - val_loss: 0.5580 - val_accuracy: 0.6927\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7811 - val_loss: 0.5576 - val_accuracy: 0.6927\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7941 - val_loss: 0.5569 - val_accuracy: 0.6927\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7638 - val_loss: 0.5566 - val_accuracy: 0.6927\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7661 - val_loss: 0.5564 - val_accuracy: 0.6979\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7991 - val_loss: 0.5564 - val_accuracy: 0.6979\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6979\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7665 - val_loss: 0.5552 - val_accuracy: 0.6979\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7911 - val_loss: 0.5560 - val_accuracy: 0.6927\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7832 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7801 - val_loss: 0.5557 - val_accuracy: 0.6875\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7799 - val_loss: 0.5550 - val_accuracy: 0.6927\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7710 - val_loss: 0.5547 - val_accuracy: 0.6927\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7637 - val_loss: 0.5545 - val_accuracy: 0.6927\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7856 - val_loss: 0.5546 - val_accuracy: 0.6875\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7784 - val_loss: 0.5548 - val_accuracy: 0.6875\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.8048 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.8076 - val_loss: 0.5549 - val_accuracy: 0.6823\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7687 - val_loss: 0.5545 - val_accuracy: 0.6823\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7720 - val_loss: 0.5541 - val_accuracy: 0.6823\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7639 - val_loss: 0.5537 - val_accuracy: 0.6823\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7656 - val_loss: 0.5533 - val_accuracy: 0.6875\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7926 - val_loss: 0.5535 - val_accuracy: 0.6771\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7659 - val_loss: 0.5528 - val_accuracy: 0.6823\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.5532 - val_accuracy: 0.6771\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7968 - val_loss: 0.5534 - val_accuracy: 0.6771\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7782 - val_loss: 0.5535 - val_accuracy: 0.6771\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7882 - val_loss: 0.5528 - val_accuracy: 0.6771\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7831 - val_loss: 0.5525 - val_accuracy: 0.6771\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8020 - val_loss: 0.5530 - val_accuracy: 0.6771\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7912 - val_loss: 0.5531 - val_accuracy: 0.6823\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7980 - val_loss: 0.5530 - val_accuracy: 0.6823\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7621 - val_loss: 0.5516 - val_accuracy: 0.6771\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7864 - val_loss: 0.5517 - val_accuracy: 0.6771\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7623 - val_loss: 0.5511 - val_accuracy: 0.6771\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7948 - val_loss: 0.5514 - val_accuracy: 0.6823\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7769 - val_loss: 0.5509 - val_accuracy: 0.6823\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7634 - val_loss: 0.5504 - val_accuracy: 0.6771\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7860 - val_loss: 0.5506 - val_accuracy: 0.6823\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7702 - val_loss: 0.5507 - val_accuracy: 0.6823\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7778 - val_loss: 0.5503 - val_accuracy: 0.6875\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7695 - val_loss: 0.5499 - val_accuracy: 0.6875\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7772 - val_loss: 0.5500 - val_accuracy: 0.6875\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7742 - val_loss: 0.5497 - val_accuracy: 0.6875\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.8054 - val_loss: 0.5496 - val_accuracy: 0.6875\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7637 - val_loss: 0.5491 - val_accuracy: 0.6875\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.8017 - val_loss: 0.5497 - val_accuracy: 0.6875\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7635 - val_loss: 0.5493 - val_accuracy: 0.6875\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7910 - val_loss: 0.5503 - val_accuracy: 0.6927\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8138 - val_loss: 0.5511 - val_accuracy: 0.6979\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.8087 - val_loss: 0.5511 - val_accuracy: 0.6979\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7649 - val_loss: 0.5499 - val_accuracy: 0.6927\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7738 - val_loss: 0.5498 - val_accuracy: 0.6927\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7709 - val_loss: 0.5495 - val_accuracy: 0.6927\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7831 - val_loss: 0.5499 - val_accuracy: 0.6979\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7987 - val_loss: 0.5498 - val_accuracy: 0.6979\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7936 - val_loss: 0.5500 - val_accuracy: 0.6979\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7742 - val_loss: 0.5489 - val_accuracy: 0.6979\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7789 - val_loss: 0.5483 - val_accuracy: 0.6927\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8037 - val_loss: 0.5489 - val_accuracy: 0.6979\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8202 - val_loss: 0.5492 - val_accuracy: 0.6979\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7906 - val_loss: 0.5492 - val_accuracy: 0.6979\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7820 - val_loss: 0.5497 - val_accuracy: 0.7031\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7820 - val_loss: 0.5489 - val_accuracy: 0.6979\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7864 - val_loss: 0.5483 - val_accuracy: 0.6979\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7637 - val_loss: 0.5479 - val_accuracy: 0.6979\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7759 - val_loss: 0.5475 - val_accuracy: 0.6979\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7962 - val_loss: 0.5477 - val_accuracy: 0.6979\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7790 - val_loss: 0.5474 - val_accuracy: 0.6979\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7857 - val_loss: 0.5471 - val_accuracy: 0.6979\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.8004 - val_loss: 0.5474 - val_accuracy: 0.6979\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7697 - val_loss: 0.5468 - val_accuracy: 0.6979\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7817 - val_loss: 0.5474 - val_accuracy: 0.7031\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7631 - val_loss: 0.5464 - val_accuracy: 0.6979\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8015 - val_loss: 0.5474 - val_accuracy: 0.7031\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7675 - val_loss: 0.5476 - val_accuracy: 0.7083\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7725 - val_loss: 0.5469 - val_accuracy: 0.7031\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8004 - val_loss: 0.5483 - val_accuracy: 0.7083\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7725 - val_loss: 0.5477 - val_accuracy: 0.7083\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7999 - val_loss: 0.5486 - val_accuracy: 0.7135\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7685 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7780 - val_loss: 0.5475 - val_accuracy: 0.7083\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7707 - val_loss: 0.5464 - val_accuracy: 0.7083\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7845 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7849 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7939 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7973 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7853 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7629 - val_loss: 0.5471 - val_accuracy: 0.7083\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7969 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7837 - val_loss: 0.5474 - val_accuracy: 0.7188\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7632 - val_loss: 0.5463 - val_accuracy: 0.7083\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7822 - val_loss: 0.5451 - val_accuracy: 0.7083\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8052 - val_loss: 0.5462 - val_accuracy: 0.7083\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7771 - val_loss: 0.5466 - val_accuracy: 0.7083\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7698 - val_loss: 0.5470 - val_accuracy: 0.7135\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7845 - val_loss: 0.5466 - val_accuracy: 0.7135\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7935 - val_loss: 0.5474 - val_accuracy: 0.7135\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7887 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.8056 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7498 - val_loss: 0.5463 - val_accuracy: 0.7135\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7554 - val_loss: 0.5458 - val_accuracy: 0.7083\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7698 - val_loss: 0.5452 - val_accuracy: 0.7031\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7572 - val_loss: 0.5462 - val_accuracy: 0.7135\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7927 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7824 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7763 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7745 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7468 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8101 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7688 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7697 - val_loss: 0.5458 - val_accuracy: 0.7135\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7771 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7856 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7644 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7756 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7818 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8020 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7999 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7906 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7605 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7739 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7649 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7754 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7907 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7798 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7619 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7733 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7502 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7987 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7836 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7750 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7573 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7620 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8183 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7737 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7939 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7765 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7647 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7545 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7824 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7384 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7492 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7824 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7780 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7930 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8086 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7741 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7628 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7867 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7643 - val_loss: 0.5474 - val_accuracy: 0.7188\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7879 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7729 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8025 - val_loss: 0.5486 - val_accuracy: 0.7188\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7914 - val_loss: 0.5479 - val_accuracy: 0.7188\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7536 - val_loss: 0.5479 - val_accuracy: 0.7188\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7777 - val_loss: 0.5472 - val_accuracy: 0.7188\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7927 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7972 - val_loss: 0.5512 - val_accuracy: 0.7135\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7517 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7874 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7850 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7774 - val_loss: 0.5462 - val_accuracy: 0.7188\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7525 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7864 - val_loss: 0.5472 - val_accuracy: 0.7188\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7907 - val_loss: 0.5481 - val_accuracy: 0.7135\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7987 - val_loss: 0.5488 - val_accuracy: 0.7135\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7864 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7747 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7748 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7816 - val_loss: 0.5477 - val_accuracy: 0.7135\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7626 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7869 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8032 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7871 - val_loss: 0.5508 - val_accuracy: 0.7188\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7686 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7436 - val_loss: 0.5511 - val_accuracy: 0.7188\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7669 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7545 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8132 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7445 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7598 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7845 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7647 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7725 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7880 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7707 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7777 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7756 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8070 - val_loss: 0.5506 - val_accuracy: 0.7188\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7839 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7523 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7757 - val_loss: 0.5456 - val_accuracy: 0.7240\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7724 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7791 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7618 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7727 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8012 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7802 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7615 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8034 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7849 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7742 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7660 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7671 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7779 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7695 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7510 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7728 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7978 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7759 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8034 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7569 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7741 - val_loss: 0.5519 - val_accuracy: 0.7292\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7611 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7978 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8031 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7533 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7763 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7615 - val_loss: 0.5502 - val_accuracy: 0.7292\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7529 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7816 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8090 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8173 - val_loss: 0.5500 - val_accuracy: 0.7292\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7585 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7820 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7768 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7595 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7833 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7911 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5548 - val_accuracy: 0.7188\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7705 - val_loss: 0.5508 - val_accuracy: 0.7292\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7577 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7814 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7797 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7705 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7844 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7699 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7817 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7619 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7948 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7825 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7704 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7765 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8040 - val_loss: 0.5514 - val_accuracy: 0.7344\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8034 - val_loss: 0.5501 - val_accuracy: 0.7344\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8024 - val_loss: 0.5539 - val_accuracy: 0.7188\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7810 - val_loss: 0.5549 - val_accuracy: 0.7188\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7714 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7796 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7714 - val_loss: 0.5505 - val_accuracy: 0.7344\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8169 - val_loss: 0.5540 - val_accuracy: 0.7188\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8164 - val_loss: 0.5538 - val_accuracy: 0.7188\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7804 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8272 - val_loss: 0.5525 - val_accuracy: 0.7188\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7960 - val_loss: 0.5563 - val_accuracy: 0.7083\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7734 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7801 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7763 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7563 - val_loss: 0.5506 - val_accuracy: 0.7292\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7677 - val_loss: 0.5513 - val_accuracy: 0.7188\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8002 - val_loss: 0.5514 - val_accuracy: 0.7188\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8074 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8023 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7765 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7786 - val_loss: 0.5560 - val_accuracy: 0.7083\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7662 - val_loss: 0.5543 - val_accuracy: 0.7135\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7831 - val_loss: 0.5548 - val_accuracy: 0.7135\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7772 - val_loss: 0.5501 - val_accuracy: 0.7188\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7827 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7570 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7748 - val_loss: 0.5488 - val_accuracy: 0.7292\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7921 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7804 - val_loss: 0.5537 - val_accuracy: 0.7135\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7596 - val_loss: 0.5545 - val_accuracy: 0.7135\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7836 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7842 - val_loss: 0.5551 - val_accuracy: 0.7135\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7738 - val_loss: 0.5540 - val_accuracy: 0.7135\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7973 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7644 - val_loss: 0.5596 - val_accuracy: 0.7031\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5574 - val_accuracy: 0.7031\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7715 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7612 - val_loss: 0.5533 - val_accuracy: 0.7135\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7984 - val_loss: 0.5517 - val_accuracy: 0.7135\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.5559 - val_accuracy: 0.7135\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7292 - val_loss: 0.5541 - val_accuracy: 0.7135\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7891 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7843 - val_loss: 0.5530 - val_accuracy: 0.7135\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7792 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7871 - val_loss: 0.5550 - val_accuracy: 0.7135\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7927 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7607 - val_loss: 0.5512 - val_accuracy: 0.7135\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7978 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7870 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7910 - val_loss: 0.5555 - val_accuracy: 0.7135\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7621 - val_loss: 0.5542 - val_accuracy: 0.7135\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7754 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7654 - val_loss: 0.5541 - val_accuracy: 0.7135\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7788 - val_loss: 0.5543 - val_accuracy: 0.7135\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5538 - val_accuracy: 0.7135\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7667 - val_loss: 0.5577 - val_accuracy: 0.7031\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7644 - val_loss: 0.5532 - val_accuracy: 0.7135\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8082 - val_loss: 0.5566 - val_accuracy: 0.7031\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7567 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7725 - val_loss: 0.5593 - val_accuracy: 0.7031\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7804 - val_loss: 0.5573 - val_accuracy: 0.7031\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8041 - val_loss: 0.5620 - val_accuracy: 0.6979\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7655 - val_loss: 0.5520 - val_accuracy: 0.7135\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7430 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7753 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7965 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7410 - val_loss: 0.5548 - val_accuracy: 0.7135\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7853 - val_loss: 0.5566 - val_accuracy: 0.7031\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7423 - val_loss: 0.5524 - val_accuracy: 0.7135\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7809 - val_loss: 0.5524 - val_accuracy: 0.7135\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7942 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7832 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7710 - val_loss: 0.5534 - val_accuracy: 0.7135\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5547 - val_accuracy: 0.7083\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7656 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7677 - val_loss: 0.5543 - val_accuracy: 0.7083\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7906 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8038 - val_loss: 0.5609 - val_accuracy: 0.6927\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7581 - val_loss: 0.5590 - val_accuracy: 0.6979\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7896 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7600 - val_loss: 0.5588 - val_accuracy: 0.6979\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7784 - val_loss: 0.5570 - val_accuracy: 0.7031\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7649 - val_loss: 0.5530 - val_accuracy: 0.7135\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7734 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7456 - val_loss: 0.5557 - val_accuracy: 0.7083\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7806 - val_loss: 0.5534 - val_accuracy: 0.7135\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7635 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7685 - val_loss: 0.5566 - val_accuracy: 0.7031\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7752 - val_loss: 0.5630 - val_accuracy: 0.6979\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7884 - val_loss: 0.5561 - val_accuracy: 0.7083\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7653 - val_loss: 0.5509 - val_accuracy: 0.7135\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7647 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7933 - val_loss: 0.5586 - val_accuracy: 0.6979\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7883 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.8009 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7609 - val_loss: 0.5582 - val_accuracy: 0.6979\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7895 - val_loss: 0.5612 - val_accuracy: 0.6927\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7560 - val_loss: 0.5560 - val_accuracy: 0.7083\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7827 - val_loss: 0.5583 - val_accuracy: 0.6979\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7622 - val_loss: 0.5595 - val_accuracy: 0.6927\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7893 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7858 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8079 - val_loss: 0.5586 - val_accuracy: 0.6979\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7896 - val_loss: 0.5591 - val_accuracy: 0.6927\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7855 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7852 - val_loss: 0.5583 - val_accuracy: 0.6979\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7816 - val_loss: 0.5645 - val_accuracy: 0.6927\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7723 - val_loss: 0.5605 - val_accuracy: 0.6927\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7721 - val_loss: 0.5571 - val_accuracy: 0.6979\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7973 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7794 - val_loss: 0.5585 - val_accuracy: 0.6979\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7715 - val_loss: 0.5550 - val_accuracy: 0.7135\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7687 - val_loss: 0.5547 - val_accuracy: 0.7135\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7982 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8157 - val_loss: 0.5603 - val_accuracy: 0.6927\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7658 - val_loss: 0.5546 - val_accuracy: 0.7135\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7638 - val_loss: 0.5533 - val_accuracy: 0.7135\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7700 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8066 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7906 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7749 - val_loss: 0.5577 - val_accuracy: 0.7031\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7784 - val_loss: 0.5537 - val_accuracy: 0.7135\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7666 - val_loss: 0.5573 - val_accuracy: 0.7083\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7600 - val_loss: 0.5600 - val_accuracy: 0.6927\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7622 - val_loss: 0.5569 - val_accuracy: 0.7083\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5585 - val_accuracy: 0.6979\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7880 - val_loss: 0.5578 - val_accuracy: 0.7031\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7573 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7683 - val_loss: 0.5547 - val_accuracy: 0.7135\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7659 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7679 - val_loss: 0.5605 - val_accuracy: 0.6979\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7668 - val_loss: 0.5612 - val_accuracy: 0.6979\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7940 - val_loss: 0.5589 - val_accuracy: 0.6979\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7908 - val_loss: 0.5608 - val_accuracy: 0.6979\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7781 - val_loss: 0.5626 - val_accuracy: 0.6979\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7769 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7727 - val_loss: 0.5560 - val_accuracy: 0.7083\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7864 - val_loss: 0.5636 - val_accuracy: 0.6927\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7751 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7751 - val_loss: 0.5580 - val_accuracy: 0.7031\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7763 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7866 - val_loss: 0.5534 - val_accuracy: 0.7135\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7702 - val_loss: 0.5582 - val_accuracy: 0.6979\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7887 - val_loss: 0.5581 - val_accuracy: 0.6979\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7826 - val_loss: 0.5570 - val_accuracy: 0.7083\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7600 - val_loss: 0.5574 - val_accuracy: 0.7083\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7570 - val_loss: 0.5590 - val_accuracy: 0.6979\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7705 - val_loss: 0.5560 - val_accuracy: 0.7031\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7976 - val_loss: 0.5611 - val_accuracy: 0.6979\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7803 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7831 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7858 - val_loss: 0.5676 - val_accuracy: 0.6979\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7933 - val_loss: 0.5628 - val_accuracy: 0.6979\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7582 - val_loss: 0.5625 - val_accuracy: 0.6979\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7828 - val_loss: 0.5669 - val_accuracy: 0.6979\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7947 - val_loss: 0.5619 - val_accuracy: 0.6979\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7964 - val_loss: 0.5599 - val_accuracy: 0.6979\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7566 - val_loss: 0.5574 - val_accuracy: 0.7083\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7931 - val_loss: 0.5608 - val_accuracy: 0.6979\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7605 - val_loss: 0.5593 - val_accuracy: 0.6979\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7942 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7802 - val_loss: 0.5624 - val_accuracy: 0.6979\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7926 - val_loss: 0.5573 - val_accuracy: 0.7083\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7705 - val_loss: 0.5605 - val_accuracy: 0.6979\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7996 - val_loss: 0.5617 - val_accuracy: 0.6979\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8000 - val_loss: 0.5604 - val_accuracy: 0.6979\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7961 - val_loss: 0.5615 - val_accuracy: 0.6979\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7557 - val_loss: 0.5620 - val_accuracy: 0.6979\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7818 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7775 - val_loss: 0.5582 - val_accuracy: 0.7031\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7846 - val_loss: 0.5612 - val_accuracy: 0.6979\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7770 - val_loss: 0.5597 - val_accuracy: 0.6979\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.5601 - val_accuracy: 0.6979\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7511 - val_loss: 0.5580 - val_accuracy: 0.7031\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7933 - val_loss: 0.5585 - val_accuracy: 0.7031\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7762 - val_loss: 0.5620 - val_accuracy: 0.6979\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7912 - val_loss: 0.5622 - val_accuracy: 0.6979\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7798 - val_loss: 0.5548 - val_accuracy: 0.7083\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7836 - val_loss: 0.5631 - val_accuracy: 0.6979\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7995 - val_loss: 0.5594 - val_accuracy: 0.6979\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7693 - val_loss: 0.5619 - val_accuracy: 0.6979\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7649 - val_loss: 0.5589 - val_accuracy: 0.6979\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7757 - val_loss: 0.5598 - val_accuracy: 0.6979\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7483 - val_loss: 0.5587 - val_accuracy: 0.7031\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7862 - val_loss: 0.5656 - val_accuracy: 0.6979\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7862 - val_loss: 0.5639 - val_accuracy: 0.6979\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5616 - val_accuracy: 0.6979\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7527 - val_loss: 0.5581 - val_accuracy: 0.7031\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7930 - val_loss: 0.5625 - val_accuracy: 0.6979\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7955 - val_loss: 0.5600 - val_accuracy: 0.6979\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8005 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7796 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7944 - val_loss: 0.5616 - val_accuracy: 0.6979\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7811 - val_loss: 0.5572 - val_accuracy: 0.7031\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7667 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7741 - val_loss: 0.5618 - val_accuracy: 0.6979\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7826 - val_loss: 0.5620 - val_accuracy: 0.6979\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7855 - val_loss: 0.5648 - val_accuracy: 0.6979\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7849 - val_loss: 0.5638 - val_accuracy: 0.6979\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7573 - val_loss: 0.5635 - val_accuracy: 0.6979\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7949 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7763 - val_loss: 0.5618 - val_accuracy: 0.6979\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7642 - val_loss: 0.5611 - val_accuracy: 0.6979\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8174 - val_loss: 0.5697 - val_accuracy: 0.6979\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7710 - val_loss: 0.5643 - val_accuracy: 0.6979\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7846 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7891 - val_loss: 0.5632 - val_accuracy: 0.6979\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7678 - val_loss: 0.5622 - val_accuracy: 0.6979\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7911 - val_loss: 0.5648 - val_accuracy: 0.6979\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8093 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7782 - val_loss: 0.5630 - val_accuracy: 0.6979\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7831 - val_loss: 0.5655 - val_accuracy: 0.6979\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7964 - val_loss: 0.5670 - val_accuracy: 0.6979\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7718 - val_loss: 0.5625 - val_accuracy: 0.6979\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7596 - val_loss: 0.5566 - val_accuracy: 0.7083\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7999 - val_loss: 0.5660 - val_accuracy: 0.6979\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7561 - val_loss: 0.5625 - val_accuracy: 0.6979\n",
            "Evaluating on training set...\n",
            "loss=0.4546, accuracy: 77.9514%\n",
            "Evaluating on testing set...\n",
            "loss=0.5625, accuracy: 69.7917%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum Loss : 0.6899\n",
            "\n",
            "Minimum Loss : 0.4555\n",
            "\n",
            "Loss difference : 0.2345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkkny-b3hv2b"
      },
      "source": [
        "Guardamos los modelos de nuestro ejercicio en formato h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDA5hRAX4887"
      },
      "source": [
        "model.save('diabetes.h5', save_format= 'h5')\r\n",
        "model1.save('diabetes1.h5', save_format= 'h5')\r\n",
        "model2.save('diabetes2.h5', save_format= 'h5')\r\n",
        "model3.save('diabetes3.h5', save_format= 'h5')\r\n",
        "model4.save('diabetes4.h5', save_format= 'h5')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvW7t6P5ep3f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}